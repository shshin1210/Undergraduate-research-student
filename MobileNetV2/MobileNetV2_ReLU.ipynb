{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2' if torch.cuda.is_available() else 'cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 30 23:46:16 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\r\n",
      "| N/A   34C    P0    63W / 300W |     10MiB / 32480MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\r\n",
      "| N/A   44C    P0   154W / 300W |  32473MiB / 32480MiB |     26%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:07.0 Off |                  Off |\r\n",
      "| N/A   48C    P0    65W / 300W |     10MiB / 32480MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1     99580      C   python                                     32463MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding =4), #cifar 10 image size : 32x32\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './data', train=True, \n",
    "                download= True, transform = transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = './data', train = False,\n",
    "                download=True, transform= transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=96,\n",
    "                                          shuffle = True, num_workers = 2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=96,\n",
    "                                         shuffle =True, num_workers =2)\n",
    "\n",
    "#num_workers =2 인지 4인지 or batch_size test의 경우는 왜 100인지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''MobileNetV2 in PyTorch.\n",
    "See the paper \"Inverted Residuals and Linear Bottlenecks:\n",
    "Mobile Networks for Classification, Detection and Segmentation\" for more details.\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''expand + depthwise + pointwise'''\n",
    "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
    "        super(Block, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "        planes = expansion * in_planes\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, groups=planes, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride == 1 and in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = out + self.shortcut(x) if self.stride==1 else out\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    # (expansion, out_planes, num_blocks, stride)\n",
    "    cfg = [(1,  16, 1, 1),\n",
    "           (6,  24, 2, 1),  # NOTE: change stride 2 -> 1 for CIFAR10\n",
    "           (6,  32, 3, 2),\n",
    "           (6,  64, 4, 2),\n",
    "           (6,  96, 3, 1),\n",
    "           (6, 160, 3, 2),\n",
    "           (6, 320, 1, 1)]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # NOTE: change conv1 stride 2 -> 1 for CIFAR10\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32)\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.linear = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for expansion, out_planes, num_blocks, stride in self.cfg:\n",
    "            strides = [stride] + [1]*(num_blocks-1)\n",
    "            for stride in strides:\n",
    "                layers.append(Block(in_planes, out_planes, expansion, stride))\n",
    "                in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        # NOTE: change pooling kernel_size 7 -> 4 for CIFAR10\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = MobileNetV2()\n",
    "    x = torch.randn(2,3,32,32)\n",
    "    y = net(x)\n",
    "    print(y.size())\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MobileNetV2()\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda:2':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "learning_rate = 0.045\n",
    "file_name = 'resnet18_cifar10.pt'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.00004)\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list=[]\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        benign_outputs = net(inputs)\n",
    "        loss = criterion(benign_outputs, targets)#예측값과 실제 타깃값\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = benign_outputs.max(1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current benign train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "            print('Current benign train loss:', loss.item())\n",
    "\n",
    "    print('\\nTotal benign train accuarcy:', 100. * correct / total)\n",
    "    print('Total benign train loss:', train_loss)\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        total += targets.size(0)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss += criterion(outputs, targets).item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    accuracy_list.append(100. * correct / total)\n",
    "    print('\\nTest accuarcy:', 100. * correct / total)\n",
    "    loss_list.append(loss)\n",
    "    print('Test average loss:', loss / total)    \n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved!')\n",
    "\n",
    "\n",
    "        \n",
    "#learning rate를 바꾸기\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = param_group['lr']\n",
    "        if epoch <=200 and epoch != 0:\n",
    "            param_group['lr'] = lr * 0.98\n",
    "        print(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045\n",
      "\n",
      "[ Train epoch: 0 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12181440740823746\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.16026674211025238\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20729242265224457\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09199470281600952\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.19292093813419342\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13697528839111328\n",
      "\n",
      "Total benign train accuarcy: 94.074\n",
      "Total benign train loss: 85.43001103401184\n",
      "\n",
      "[ Test epoch: 0 ]\n",
      "\n",
      "Test accuarcy: 88.76\n",
      "Test average loss: 0.004110706500709057\n",
      "Model Saved!\n",
      "0.0441\n",
      "\n",
      "[ Train epoch: 1 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15310746431350708\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06670426577329636\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.148801788687706\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13914379477500916\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.20124536752700806\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0855327844619751\n",
      "\n",
      "Total benign train accuarcy: 94.31\n",
      "Total benign train loss: 84.02580412104726\n",
      "\n",
      "[ Test epoch: 1 ]\n",
      "\n",
      "Test accuarcy: 89.73\n",
      "Test average loss: 0.0037209360152482985\n",
      "Model Saved!\n",
      "0.043218\n",
      "\n",
      "[ Train epoch: 2 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1593131572008133\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19968338310718536\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.3400242328643799\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08374039083719254\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.11408079415559769\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.04486696794629097\n",
      "\n",
      "Total benign train accuarcy: 94.518\n",
      "Total benign train loss: 80.46872065588832\n",
      "\n",
      "[ Test epoch: 2 ]\n",
      "\n",
      "Test accuarcy: 89.33\n",
      "Test average loss: 0.004046197205036879\n",
      "Model Saved!\n",
      "0.04235364\n",
      "\n",
      "[ Train epoch: 3 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.11936116218566895\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1514693647623062\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.23189790546894073\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1081731915473938\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.12844327092170715\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.20800870656967163\n",
      "\n",
      "Total benign train accuarcy: 94.812\n",
      "Total benign train loss: 74.68405086919665\n",
      "\n",
      "[ Test epoch: 3 ]\n",
      "\n",
      "Test accuarcy: 89.7\n",
      "Test average loss: 0.0037034049935638904\n",
      "Model Saved!\n",
      "0.0415065672\n",
      "\n",
      "[ Train epoch: 4 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1231355369091034\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.11753403395414352\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.13852769136428833\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19164596498012543\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10488060861825943\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2743009030818939\n",
      "\n",
      "Total benign train accuarcy: 95.178\n",
      "Total benign train loss: 71.37814169749618\n",
      "\n",
      "[ Test epoch: 4 ]\n",
      "\n",
      "Test accuarcy: 89.18\n",
      "Test average loss: 0.0038154160760343076\n",
      "Model Saved!\n",
      "0.040676435856\n",
      "\n",
      "[ Train epoch: 5 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.13880623877048492\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05790296569466591\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0778682604432106\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1876932978630066\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08178933709859848\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.22113411128520966\n",
      "\n",
      "Total benign train accuarcy: 95.31\n",
      "Total benign train loss: 68.2127966824919\n",
      "\n",
      "[ Test epoch: 5 ]\n",
      "\n",
      "Test accuarcy: 90.22\n",
      "Test average loss: 0.0037812667779624463\n",
      "Model Saved!\n",
      "0.039862907138879994\n",
      "\n",
      "[ Train epoch: 6 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05818171799182892\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08421319723129272\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.11690043658018112\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06242133304476738\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.19331537187099457\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.13432051241397858\n",
      "\n",
      "Total benign train accuarcy: 95.588\n",
      "Total benign train loss: 64.60533240623772\n",
      "\n",
      "[ Test epoch: 6 ]\n",
      "\n",
      "Test accuarcy: 88.91\n",
      "Test average loss: 0.004200433173775673\n",
      "Model Saved!\n",
      "0.039065648996102396\n",
      "\n",
      "[ Train epoch: 7 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14409996569156647\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05299881473183632\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0621081106364727\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.13395707309246063\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1631554812192917\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19283080101013184\n",
      "\n",
      "Total benign train accuarcy: 95.942\n",
      "Total benign train loss: 59.730394705198705\n",
      "\n",
      "[ Test epoch: 7 ]\n",
      "\n",
      "Test accuarcy: 90.12\n",
      "Test average loss: 0.0036637444987893107\n",
      "Model Saved!\n",
      "0.03828433601618035\n",
      "\n",
      "[ Train epoch: 8 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08377765864133835\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.13837572932243347\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06665313988924026\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05832527577877045\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03133677318692207\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1603449434041977\n",
      "\n",
      "Total benign train accuarcy: 95.866\n",
      "Total benign train loss: 59.552813624963164\n",
      "\n",
      "[ Test epoch: 8 ]\n",
      "\n",
      "Test accuarcy: 90.35\n",
      "Test average loss: 0.0037847618490457536\n",
      "Model Saved!\n",
      "0.03751864929585674\n",
      "\n",
      "[ Train epoch: 9 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.08313684165477753\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.058172982186079025\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.059372738003730774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10700217634439468\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10580110549926758\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.20154203474521637\n",
      "\n",
      "Total benign train accuarcy: 96.184\n",
      "Total benign train loss: 56.28060010261834\n",
      "\n",
      "[ Test epoch: 9 ]\n",
      "\n",
      "Test accuarcy: 90.47\n",
      "Test average loss: 0.0036819783177226783\n",
      "Model Saved!\n",
      "0.036768276309939604\n",
      "\n",
      "[ Train epoch: 10 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06543894112110138\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03400811925530434\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1204095408320427\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.08708876371383667\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.10177687555551529\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07518457621335983\n",
      "\n",
      "Total benign train accuarcy: 96.37\n",
      "Total benign train loss: 53.08304489124566\n",
      "\n",
      "[ Test epoch: 10 ]\n",
      "\n",
      "Test accuarcy: 90.28\n",
      "Test average loss: 0.003674093832820654\n",
      "Model Saved!\n",
      "0.03603291078374081\n",
      "\n",
      "[ Train epoch: 11 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04522944986820221\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.018701186403632164\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.14566656947135925\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05546341463923454\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08320989459753036\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.11829584091901779\n",
      "\n",
      "Total benign train accuarcy: 96.45\n",
      "Total benign train loss: 51.347884982824326\n",
      "\n",
      "[ Test epoch: 11 ]\n",
      "\n",
      "Test accuarcy: 89.97\n",
      "Test average loss: 0.00374613054394722\n",
      "Model Saved!\n",
      "0.03531225256806599\n",
      "\n",
      "[ Train epoch: 12 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1152549684047699\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05671176314353943\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.028572112321853638\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04510645568370819\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07877693325281143\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.16785883903503418\n",
      "\n",
      "Total benign train accuarcy: 96.634\n",
      "Total benign train loss: 49.37047685496509\n",
      "\n",
      "[ Test epoch: 12 ]\n",
      "\n",
      "Test accuarcy: 90.58\n",
      "Test average loss: 0.00375774648450315\n",
      "Model Saved!\n",
      "0.03460600751670467\n",
      "\n",
      "[ Train epoch: 13 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.048806484788656235\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.10397585481405258\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14670349657535553\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06609781831502914\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08345665782690048\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07200765609741211\n",
      "\n",
      "Total benign train accuarcy: 96.874\n",
      "Total benign train loss: 46.596344056073576\n",
      "\n",
      "[ Test epoch: 13 ]\n",
      "\n",
      "Test accuarcy: 90.48\n",
      "Test average loss: 0.0038086190901696682\n",
      "Model Saved!\n",
      "0.033913887366370576\n",
      "\n",
      "[ Train epoch: 14 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.16341117024421692\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.050866108387708664\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.0629277378320694\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06349596381187439\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02337435632944107\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1131804883480072\n",
      "\n",
      "Total benign train accuarcy: 97.064\n",
      "Total benign train loss: 43.435021260753274\n",
      "\n",
      "[ Test epoch: 14 ]\n",
      "\n",
      "Test accuarcy: 90.48\n",
      "Test average loss: 0.0037423855189234016\n",
      "Model Saved!\n",
      "0.03323560961904316\n",
      "\n",
      "[ Train epoch: 15 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024916723370552063\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01932583935558796\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09751243144273758\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.15325412154197693\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04063649848103523\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06332720071077347\n",
      "\n",
      "Total benign train accuarcy: 97.228\n",
      "Total benign train loss: 41.75282758381218\n",
      "\n",
      "[ Test epoch: 15 ]\n",
      "\n",
      "Test accuarcy: 91.02\n",
      "Test average loss: 0.0037131073981523516\n",
      "Model Saved!\n",
      "0.0325708974266623\n",
      "\n",
      "[ Train epoch: 16 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04774416610598564\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04258275032043457\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1184280589222908\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11064320057630539\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06842755526304245\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.11869489401578903\n",
      "\n",
      "Total benign train accuarcy: 97.338\n",
      "Total benign train loss: 39.58178895898163\n",
      "\n",
      "[ Test epoch: 16 ]\n",
      "\n",
      "Test accuarcy: 90.94\n",
      "Test average loss: 0.0038712368458509445\n",
      "Model Saved!\n",
      "0.03191947947812905\n",
      "\n",
      "[ Train epoch: 17 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.07432931661605835\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06436903029680252\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.026897162199020386\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09127797931432724\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03632323071360588\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.026878992095589638\n",
      "\n",
      "Total benign train accuarcy: 97.464\n",
      "Total benign train loss: 37.450538620352745\n",
      "\n",
      "[ Test epoch: 17 ]\n",
      "\n",
      "Test accuarcy: 90.5\n",
      "Test average loss: 0.004056346359848976\n",
      "Model Saved!\n",
      "0.03128108988856647\n",
      "\n",
      "[ Train epoch: 18 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.07096127420663834\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.0820479616522789\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07339465618133545\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04640309140086174\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024280918762087822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09180846810340881\n",
      "\n",
      "Total benign train accuarcy: 97.416\n",
      "Total benign train loss: 36.982431260403246\n",
      "\n",
      "[ Test epoch: 18 ]\n",
      "\n",
      "Test accuarcy: 91.44\n",
      "Test average loss: 0.0037514359042048456\n",
      "Model Saved!\n",
      "0.030655468090795137\n",
      "\n",
      "[ Train epoch: 19 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09743189066648483\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.030450664460659027\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.039341866970062256\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04920513927936554\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.15110887587070465\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08438459783792496\n",
      "\n",
      "Total benign train accuarcy: 97.744\n",
      "Total benign train loss: 35.01454872684553\n",
      "\n",
      "[ Test epoch: 19 ]\n",
      "\n",
      "Test accuarcy: 90.99\n",
      "Test average loss: 0.0037633226208388807\n",
      "Model Saved!\n",
      "0.030042358728979233\n",
      "\n",
      "[ Train epoch: 20 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04185405746102333\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08455836027860641\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.045588865876197815\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04594731703400612\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0649893656373024\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0472952276468277\n",
      "\n",
      "Total benign train accuarcy: 97.716\n",
      "Total benign train loss: 34.21871767239645\n",
      "\n",
      "[ Test epoch: 20 ]\n",
      "\n",
      "Test accuarcy: 91.23\n",
      "Test average loss: 0.0036498919151723387\n",
      "Model Saved!\n",
      "0.029441511554399648\n",
      "\n",
      "[ Train epoch: 21 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0329538956284523\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06561683863401413\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03808171674609184\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05404968187212944\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06128430366516113\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022921347990632057\n",
      "\n",
      "Total benign train accuarcy: 97.808\n",
      "Total benign train loss: 32.06509473640472\n",
      "\n",
      "[ Test epoch: 21 ]\n",
      "\n",
      "Test accuarcy: 91.32\n",
      "Test average loss: 0.003773505461215973\n",
      "Model Saved!\n",
      "0.028852681323311653\n",
      "\n",
      "[ Train epoch: 22 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00914416927844286\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01916920207440853\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03730171546339989\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07149926573038101\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06318720430135727\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06941338628530502\n",
      "\n",
      "Total benign train accuarcy: 97.866\n",
      "Total benign train loss: 30.643902599811554\n",
      "\n",
      "[ Test epoch: 22 ]\n",
      "\n",
      "Test accuarcy: 90.89\n",
      "Test average loss: 0.003978529212623835\n",
      "Model Saved!\n",
      "0.02827562769684542\n",
      "\n",
      "[ Train epoch: 23 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03574034944176674\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08023231476545334\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0365494005382061\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016132408753037453\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10593871027231216\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.031178118661046028\n",
      "\n",
      "Total benign train accuarcy: 97.98\n",
      "Total benign train loss: 30.32323843240738\n",
      "\n",
      "[ Test epoch: 23 ]\n",
      "\n",
      "Test accuarcy: 91.0\n",
      "Test average loss: 0.0037113638285081836\n",
      "Model Saved!\n",
      "0.027710115142908512\n",
      "\n",
      "[ Train epoch: 24 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05677787587046623\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02890045940876007\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01901881955564022\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07989867031574249\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1272624135017395\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009831971488893032\n",
      "\n",
      "Total benign train accuarcy: 98.154\n",
      "Total benign train loss: 28.14373859553598\n",
      "\n",
      "[ Test epoch: 24 ]\n",
      "\n",
      "Test accuarcy: 91.31\n",
      "Test average loss: 0.003914575089514255\n",
      "Model Saved!\n",
      "0.027155912840050343\n",
      "\n",
      "[ Train epoch: 25 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06237907335162163\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07566039264202118\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05519986152648926\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05062195658683777\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06326000392436981\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07386257499456406\n",
      "\n",
      "Total benign train accuarcy: 98.212\n",
      "Total benign train loss: 26.710560902953148\n",
      "\n",
      "[ Test epoch: 25 ]\n",
      "\n",
      "Test accuarcy: 91.69\n",
      "Test average loss: 0.0038068326111882927\n",
      "Model Saved!\n",
      "0.026612794583249336\n",
      "\n",
      "[ Train epoch: 26 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07155890017747879\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.09113243967294693\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1356232911348343\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09177529811859131\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.027428528293967247\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.048904579132795334\n",
      "\n",
      "Total benign train accuarcy: 98.228\n",
      "Total benign train loss: 25.6692118847277\n",
      "\n",
      "[ Test epoch: 26 ]\n",
      "\n",
      "Test accuarcy: 92.06\n",
      "Test average loss: 0.0036310469172894954\n",
      "Model Saved!\n",
      "0.02608053869158435\n",
      "\n",
      "[ Train epoch: 27 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02220442332327366\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03279384598135948\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0922001376748085\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08022449165582657\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03705389052629471\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01585785485804081\n",
      "\n",
      "Total benign train accuarcy: 98.38\n",
      "Total benign train loss: 24.37101964862086\n",
      "\n",
      "[ Test epoch: 27 ]\n",
      "\n",
      "Test accuarcy: 91.41\n",
      "Test average loss: 0.0038372210097499192\n",
      "Model Saved!\n",
      "0.02555892791775266\n",
      "\n",
      "[ Train epoch: 28 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013641554862260818\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05484873056411743\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09528184682130814\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05191151797771454\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0760631188750267\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.09608709067106247\n",
      "\n",
      "Total benign train accuarcy: 98.45\n",
      "Total benign train loss: 22.706815694924444\n",
      "\n",
      "[ Test epoch: 28 ]\n",
      "\n",
      "Test accuarcy: 91.06\n",
      "Test average loss: 0.004249825502187014\n",
      "Model Saved!\n",
      "0.025047749359397607\n",
      "\n",
      "[ Train epoch: 29 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.047656770795583725\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.023976624011993408\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06947711110115051\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.047196630388498306\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.09805323928594589\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.022871674969792366\n",
      "\n",
      "Total benign train accuarcy: 98.366\n",
      "Total benign train loss: 24.77860112558119\n",
      "\n",
      "[ Test epoch: 29 ]\n",
      "\n",
      "Test accuarcy: 91.9\n",
      "Test average loss: 0.0036988217487931253\n",
      "Model Saved!\n",
      "0.024546794372209652\n",
      "\n",
      "[ Train epoch: 30 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010052850469946861\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04270566627383232\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.037616975605487823\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10403889417648315\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07089390605688095\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04192766547203064\n",
      "\n",
      "Total benign train accuarcy: 98.648\n",
      "Total benign train loss: 20.759213133715093\n",
      "\n",
      "[ Test epoch: 30 ]\n",
      "\n",
      "Test accuarcy: 91.71\n",
      "Test average loss: 0.003868750908970833\n",
      "Model Saved!\n",
      "0.02405585848476546\n",
      "\n",
      "[ Train epoch: 31 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009988104924559593\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02959008701145649\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018281564116477966\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02688511461019516\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04126424714922905\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01605376787483692\n",
      "\n",
      "Total benign train accuarcy: 98.72\n",
      "Total benign train loss: 19.03097012557555\n",
      "\n",
      "[ Test epoch: 31 ]\n",
      "\n",
      "Test accuarcy: 91.81\n",
      "Test average loss: 0.003909567359834909\n",
      "Model Saved!\n",
      "0.02357474131507015\n",
      "\n",
      "[ Train epoch: 32 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07043308764696121\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02957538701593876\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.029577836394309998\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04398227855563164\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01796693168580532\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012982495129108429\n",
      "\n",
      "Total benign train accuarcy: 98.696\n",
      "Total benign train loss: 19.86484707146883\n",
      "\n",
      "[ Test epoch: 32 ]\n",
      "\n",
      "Test accuarcy: 91.63\n",
      "Test average loss: 0.0039049644263694063\n",
      "Model Saved!\n",
      "0.023103246488768745\n",
      "\n",
      "[ Train epoch: 33 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09146372228860855\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.030007511377334595\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012539658695459366\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013034439645707607\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.029020292684435844\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.019183238968253136\n",
      "\n",
      "Total benign train accuarcy: 98.906\n",
      "Total benign train loss: 17.035531249828637\n",
      "\n",
      "[ Test epoch: 33 ]\n",
      "\n",
      "Test accuarcy: 91.82\n",
      "Test average loss: 0.00382249586712569\n",
      "Model Saved!\n",
      "0.02264118155899337\n",
      "\n",
      "[ Train epoch: 34 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013863075524568558\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024973278865218163\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004347379319369793\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.025333739817142487\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03636176139116287\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.026876376941800117\n",
      "\n",
      "Total benign train accuarcy: 99.01\n",
      "Total benign train loss: 14.782334299059585\n",
      "\n",
      "[ Test epoch: 34 ]\n",
      "\n",
      "Test accuarcy: 91.9\n",
      "Test average loss: 0.0038181776136159895\n",
      "Model Saved!\n",
      "0.022188357927813502\n",
      "\n",
      "[ Train epoch: 35 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02084580808877945\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01555976364761591\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.1228744387626648\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03682154789566994\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0787651464343071\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04204070568084717\n",
      "\n",
      "Total benign train accuarcy: 99.004\n",
      "Total benign train loss: 15.162984396563843\n",
      "\n",
      "[ Test epoch: 35 ]\n",
      "\n",
      "Test accuarcy: 91.93\n",
      "Test average loss: 0.0037918142761103808\n",
      "Model Saved!\n",
      "0.021744590769257232\n",
      "\n",
      "[ Train epoch: 36 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0034910698886960745\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.102909155189991\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06465340405702591\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11964550614356995\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.012510903179645538\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07833284139633179\n",
      "\n",
      "Total benign train accuarcy: 98.996\n",
      "Total benign train loss: 15.383693491457961\n",
      "\n",
      "[ Test epoch: 36 ]\n",
      "\n",
      "Test accuarcy: 92.36\n",
      "Test average loss: 0.003732856482081115\n",
      "Model Saved!\n",
      "0.021309698953872087\n",
      "\n",
      "[ Train epoch: 37 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001117920852266252\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009557320736348629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.025857364758849144\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016517160460352898\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04058303311467171\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.012887123972177505\n",
      "\n",
      "Total benign train accuarcy: 98.96\n",
      "Total benign train loss: 15.096883516642265\n",
      "\n",
      "[ Test epoch: 37 ]\n",
      "\n",
      "Test accuarcy: 92.08\n",
      "Test average loss: 0.00390546750202775\n",
      "Model Saved!\n",
      "0.020883504974794645\n",
      "\n",
      "[ Train epoch: 38 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02714863419532776\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02835533767938614\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014553218148648739\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.019653068855404854\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0648818239569664\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013795118778944016\n",
      "\n",
      "Total benign train accuarcy: 99.038\n",
      "Total benign train loss: 14.101896965643391\n",
      "\n",
      "[ Test epoch: 38 ]\n",
      "\n",
      "Test accuarcy: 92.03\n",
      "Test average loss: 0.004153240270912647\n",
      "Model Saved!\n",
      "0.020465834875298752\n",
      "\n",
      "[ Train epoch: 39 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.051221802830696106\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00667197210714221\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003037395654246211\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03308640420436859\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014495089650154114\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03405794873833656\n",
      "\n",
      "Total benign train accuarcy: 99.004\n",
      "Total benign train loss: 14.293364470708184\n",
      "\n",
      "[ Test epoch: 39 ]\n",
      "\n",
      "Test accuarcy: 92.14\n",
      "Test average loss: 0.003927685482800007\n",
      "Model Saved!\n",
      "0.020056518177792776\n",
      "\n",
      "[ Train epoch: 40 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011103344149887562\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02674953080713749\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01615203730762005\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02266058512032032\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.042604874819517136\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024296173825860023\n",
      "\n",
      "Total benign train accuarcy: 99.108\n",
      "Total benign train loss: 12.805113226087997\n",
      "\n",
      "[ Test epoch: 40 ]\n",
      "\n",
      "Test accuarcy: 92.09\n",
      "Test average loss: 0.003929763186816126\n",
      "Model Saved!\n",
      "0.01965538781423692\n",
      "\n",
      "[ Train epoch: 41 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.021984746679663658\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.019140079617500305\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.022288048639893532\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01901884935796261\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.015207279473543167\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011813178658485413\n",
      "\n",
      "Total benign train accuarcy: 99.198\n",
      "Total benign train loss: 11.980157978541683\n",
      "\n",
      "[ Test epoch: 41 ]\n",
      "\n",
      "Test accuarcy: 91.97\n",
      "Test average loss: 0.00406972628813237\n",
      "Model Saved!\n",
      "0.01926228005795218\n",
      "\n",
      "[ Train epoch: 42 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013877492165192962\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.053966667503118515\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02430613897740841\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.03778474032878876\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.057298045605421066\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.019315723329782486\n",
      "\n",
      "Total benign train accuarcy: 99.18\n",
      "Total benign train loss: 12.39494724146789\n",
      "\n",
      "[ Test epoch: 42 ]\n",
      "\n",
      "Test accuarcy: 91.99\n",
      "Test average loss: 0.0041286889083683494\n",
      "Model Saved!\n",
      "0.018877034456793135\n",
      "\n",
      "[ Train epoch: 43 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0036924248561263084\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012606794945895672\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.013058462180197239\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017908718436956406\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003963334020227194\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008844505995512009\n",
      "\n",
      "Total benign train accuarcy: 99.246\n",
      "Total benign train loss: 11.411934880947229\n",
      "\n",
      "[ Test epoch: 43 ]\n",
      "\n",
      "Test accuarcy: 92.12\n",
      "Test average loss: 0.003980410359147936\n",
      "Model Saved!\n",
      "0.018499493767657273\n",
      "\n",
      "[ Train epoch: 44 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020977256819605827\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05395987257361412\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003286876482889056\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03885994479060173\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04092421755194664\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0033939785789698362\n",
      "\n",
      "Total benign train accuarcy: 99.31\n",
      "Total benign train loss: 10.396624729561154\n",
      "\n",
      "[ Test epoch: 44 ]\n",
      "\n",
      "Test accuarcy: 92.34\n",
      "Test average loss: 0.004061286960542202\n",
      "Model Saved!\n",
      "0.018129503892304128\n",
      "\n",
      "[ Train epoch: 45 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03139401227235794\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05490222945809364\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017118478193879128\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0033787523861974478\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004617959260940552\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016525941900908947\n",
      "\n",
      "Total benign train accuarcy: 99.372\n",
      "Total benign train loss: 10.314890508336248\n",
      "\n",
      "[ Test epoch: 45 ]\n",
      "\n",
      "Test accuarcy: 92.27\n",
      "Test average loss: 0.0038436235934495924\n",
      "Model Saved!\n",
      "0.017766913814458045\n",
      "\n",
      "[ Train epoch: 46 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004117083735764027\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04570949450135231\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006796089466661215\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03210980072617531\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.018001394346356392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.06475571542978287\n",
      "\n",
      "Total benign train accuarcy: 99.364\n",
      "Total benign train loss: 10.044435775489546\n",
      "\n",
      "[ Test epoch: 46 ]\n",
      "\n",
      "Test accuarcy: 92.18\n",
      "Test average loss: 0.004003754096478224\n",
      "Model Saved!\n",
      "0.017411575538168883\n",
      "\n",
      "[ Train epoch: 47 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05499648675322533\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020986783783882856\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003832103917375207\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.026113025844097137\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008796031586825848\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04619499668478966\n",
      "\n",
      "Total benign train accuarcy: 99.436\n",
      "Total benign train loss: 8.818880183505826\n",
      "\n",
      "[ Test epoch: 47 ]\n",
      "\n",
      "Test accuarcy: 92.53\n",
      "Test average loss: 0.003980703537212684\n",
      "Model Saved!\n",
      "0.017063344027405506\n",
      "\n",
      "[ Train epoch: 48 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014946910552680492\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022806236520409584\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018314410001039505\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005353992804884911\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007075711037032306\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006986318156123161\n",
      "\n",
      "Total benign train accuarcy: 99.41\n",
      "Total benign train loss: 8.895963065355318\n",
      "\n",
      "[ Test epoch: 48 ]\n",
      "\n",
      "Test accuarcy: 92.31\n",
      "Test average loss: 0.004112778466194868\n",
      "Model Saved!\n",
      "0.016722077146857396\n",
      "\n",
      "[ Train epoch: 49 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.019364798441529274\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03971391171216965\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0038700008299201727\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00853129755705595\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0042526922188699245\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.021895503625273705\n",
      "\n",
      "Total benign train accuarcy: 99.48\n",
      "Total benign train loss: 8.296793632034678\n",
      "\n",
      "[ Test epoch: 49 ]\n",
      "\n",
      "Test accuarcy: 92.27\n",
      "Test average loss: 0.004039776508556679\n",
      "Model Saved!\n",
      "0.016387635603920248\n",
      "\n",
      "[ Train epoch: 50 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03459162637591362\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020960593596100807\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02398216910660267\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01886250451207161\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01579437218606472\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024622393772006035\n",
      "\n",
      "Total benign train accuarcy: 99.378\n",
      "Total benign train loss: 8.964576090540504\n",
      "\n",
      "[ Test epoch: 50 ]\n",
      "\n",
      "Test accuarcy: 92.48\n",
      "Test average loss: 0.003943855290859937\n",
      "Model Saved!\n",
      "0.016059882891841844\n",
      "\n",
      "[ Train epoch: 51 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0039387173019349575\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004808055702596903\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004726373124867678\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.025539517402648926\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05470209941267967\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014968694187700748\n",
      "\n",
      "Total benign train accuarcy: 99.498\n",
      "Total benign train loss: 7.8654387410206255\n",
      "\n",
      "[ Test epoch: 51 ]\n",
      "\n",
      "Test accuarcy: 92.25\n",
      "Test average loss: 0.004118896893411874\n",
      "Model Saved!\n",
      "0.01573868523400501\n",
      "\n",
      "[ Train epoch: 52 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011793899349868298\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012074771337211132\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.025802306830883026\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002918297192081809\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03756945952773094\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002082674065604806\n",
      "\n",
      "Total benign train accuarcy: 99.54\n",
      "Total benign train loss: 7.293195703154197\n",
      "\n",
      "[ Test epoch: 52 ]\n",
      "\n",
      "Test accuarcy: 92.6\n",
      "Test average loss: 0.0038910795051604508\n",
      "Model Saved!\n",
      "0.015423911529324909\n",
      "\n",
      "[ Train epoch: 53 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006188984960317612\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.011339634656906128\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004948948044329882\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008066619746387005\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00948242750018835\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0037407574709504843\n",
      "\n",
      "Total benign train accuarcy: 99.53\n",
      "Total benign train loss: 7.382748350530164\n",
      "\n",
      "[ Test epoch: 53 ]\n",
      "\n",
      "Test accuarcy: 92.6\n",
      "Test average loss: 0.00397521354239434\n",
      "Model Saved!\n",
      "0.01511543329873841\n",
      "\n",
      "[ Train epoch: 54 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003626420861110091\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013254055520519614\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02577710896730423\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019139964133501053\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.027576027438044548\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016292748041450977\n",
      "\n",
      "Total benign train accuarcy: 99.592\n",
      "Total benign train loss: 6.495232811837923\n",
      "\n",
      "[ Test epoch: 54 ]\n",
      "\n",
      "Test accuarcy: 92.69\n",
      "Test average loss: 0.003964594585821032\n",
      "Model Saved!\n",
      "0.014813124632763642\n",
      "\n",
      "[ Train epoch: 55 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017136939568445086\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006785692181438208\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014951189048588276\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002877010963857174\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00531821558251977\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01819615624845028\n",
      "\n",
      "Total benign train accuarcy: 99.622\n",
      "Total benign train loss: 5.888164467047318\n",
      "\n",
      "[ Test epoch: 55 ]\n",
      "\n",
      "Test accuarcy: 92.58\n",
      "Test average loss: 0.0039867904722690585\n",
      "Model Saved!\n",
      "0.01451686214010837\n",
      "\n",
      "[ Train epoch: 56 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001389654353260994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004525338765233755\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013000813778489828\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.022944509983062744\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007262818980962038\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013196165673434734\n",
      "\n",
      "Total benign train accuarcy: 99.666\n",
      "Total benign train loss: 5.19800885670702\n",
      "\n",
      "[ Test epoch: 56 ]\n",
      "\n",
      "Test accuarcy: 92.46\n",
      "Test average loss: 0.004225151510909199\n",
      "Model Saved!\n",
      "0.014226524897306202\n",
      "\n",
      "[ Train epoch: 57 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004023184534162283\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01739252172410488\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010274284286424518\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001706975046545267\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0068003530614078045\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006004333961755037\n",
      "\n",
      "Total benign train accuarcy: 99.698\n",
      "Total benign train loss: 5.074451656284509\n",
      "\n",
      "[ Test epoch: 57 ]\n",
      "\n",
      "Test accuarcy: 92.72\n",
      "Test average loss: 0.0038388358492404224\n",
      "Model Saved!\n",
      "0.013941994399360077\n",
      "\n",
      "[ Train epoch: 58 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009621987119317055\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008558960631489754\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018982187611982226\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012345696799457073\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0041846358217298985\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001020533498376608\n",
      "\n",
      "Total benign train accuarcy: 99.63\n",
      "Total benign train loss: 5.673530160667724\n",
      "\n",
      "[ Test epoch: 58 ]\n",
      "\n",
      "Test accuarcy: 92.69\n",
      "Test average loss: 0.003908281178027391\n",
      "Model Saved!\n",
      "0.013663154511372875\n",
      "\n",
      "[ Train epoch: 59 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0048913550563156605\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020772756543010473\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.029993442818522453\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006454785820096731\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03416050970554352\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003363575553521514\n",
      "\n",
      "Total benign train accuarcy: 99.684\n",
      "Total benign train loss: 5.163883181186975\n",
      "\n",
      "[ Test epoch: 59 ]\n",
      "\n",
      "Test accuarcy: 92.5\n",
      "Test average loss: 0.004035861057788134\n",
      "Model Saved!\n",
      "0.013389891421145416\n",
      "\n",
      "[ Train epoch: 60 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00293808919377625\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006867214571684599\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0035828512627631426\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003848321211989969\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010967377573251724\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0032150570768862963\n",
      "\n",
      "Total benign train accuarcy: 99.706\n",
      "Total benign train loss: 4.748554338963004\n",
      "\n",
      "[ Test epoch: 60 ]\n",
      "\n",
      "Test accuarcy: 92.71\n",
      "Test average loss: 0.004088444193359465\n",
      "Model Saved!\n",
      "0.013122093592722508\n",
      "\n",
      "[ Train epoch: 61 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019269176991656423\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025679960381239653\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005313830450177193\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012592577375471592\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010647729504853487\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.008460135199129581\n",
      "\n",
      "Total benign train accuarcy: 99.634\n",
      "Total benign train loss: 5.046480053351843\n",
      "\n",
      "[ Test epoch: 61 ]\n",
      "\n",
      "Test accuarcy: 92.79\n",
      "Test average loss: 0.0039838632576167585\n",
      "Model Saved!\n",
      "0.012859651720868058\n",
      "\n",
      "[ Train epoch: 62 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027405573055148125\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020690402016043663\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.04045320674777031\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00429182406514883\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007077719550579786\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04006006568670273\n",
      "\n",
      "Total benign train accuarcy: 99.68\n",
      "Total benign train loss: 4.8432132898888085\n",
      "\n",
      "[ Test epoch: 62 ]\n",
      "\n",
      "Test accuarcy: 92.51\n",
      "Test average loss: 0.004014931391336722\n",
      "Model Saved!\n",
      "0.012602458686450697\n",
      "\n",
      "[ Train epoch: 63 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0060982429422438145\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004314411198720336\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004286167968530208\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.041128020733594894\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030172942206263542\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011618426069617271\n",
      "\n",
      "Total benign train accuarcy: 99.744\n",
      "Total benign train loss: 4.273561735331896\n",
      "\n",
      "[ Test epoch: 63 ]\n",
      "\n",
      "Test accuarcy: 92.81\n",
      "Test average loss: 0.004049205845221877\n",
      "Model Saved!\n",
      "0.012350409512721683\n",
      "\n",
      "[ Train epoch: 64 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0026106599252671003\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031174607574939728\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00037372836959548295\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.009387698024511337\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004427000880241394\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016593458130955696\n",
      "\n",
      "Total benign train accuarcy: 99.816\n",
      "Total benign train loss: 3.4557460990690743\n",
      "\n",
      "[ Test epoch: 64 ]\n",
      "\n",
      "Test accuarcy: 92.79\n",
      "Test average loss: 0.00402052704654634\n",
      "Model Saved!\n",
      "0.012103401322467249\n",
      "\n",
      "[ Train epoch: 65 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006779924151487648\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01703418605029583\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.010812517255544662\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007585994899272919\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05694663152098656\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018568994477391243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign train accuarcy: 99.756\n",
      "Total benign train loss: 4.04239557654364\n",
      "\n",
      "[ Test epoch: 65 ]\n",
      "\n",
      "Test accuarcy: 92.97\n",
      "Test average loss: 0.003992071582376957\n",
      "Model Saved!\n",
      "0.011861333296017903\n",
      "\n",
      "[ Train epoch: 66 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021968751680105925\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.025478936731815338\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011532088974490762\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025840681046247482\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013956948183476925\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0056444257497787476\n",
      "\n",
      "Total benign train accuarcy: 99.816\n",
      "Total benign train loss: 3.293106449265906\n",
      "\n",
      "[ Test epoch: 66 ]\n",
      "\n",
      "Test accuarcy: 92.72\n",
      "Test average loss: 0.0040834524750709535\n",
      "Model Saved!\n",
      "0.011624106630097544\n",
      "\n",
      "[ Train epoch: 67 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013998086797073483\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012428927002474666\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013537337072193623\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00216662441380322\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001415751758031547\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.016059717163443565\n",
      "\n",
      "Total benign train accuarcy: 99.824\n",
      "Total benign train loss: 2.9596235289791366\n",
      "\n",
      "[ Test epoch: 67 ]\n",
      "\n",
      "Test accuarcy: 92.63\n",
      "Test average loss: 0.00412716389670968\n",
      "Model Saved!\n",
      "0.011391624497495593\n",
      "\n",
      "[ Train epoch: 68 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004305594600737095\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002471464453265071\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002868538722395897\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011097324080765247\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0037779994308948517\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00034443187178112566\n",
      "\n",
      "Total benign train accuarcy: 99.814\n",
      "Total benign train loss: 3.2504893846271443\n",
      "\n",
      "[ Test epoch: 68 ]\n",
      "\n",
      "Test accuarcy: 92.86\n",
      "Test average loss: 0.0041049851469695565\n",
      "Model Saved!\n",
      "0.011163792007545682\n",
      "\n",
      "[ Train epoch: 69 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.013348438777029514\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009420726564712822\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018131202086806297\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006560139823704958\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010291916551068425\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007237933459691703\n",
      "\n",
      "Total benign train accuarcy: 99.882\n",
      "Total benign train loss: 2.3921224218865973\n",
      "\n",
      "[ Test epoch: 69 ]\n",
      "\n",
      "Test accuarcy: 92.93\n",
      "Test average loss: 0.003963524828664958\n",
      "Model Saved!\n",
      "0.010940516167394767\n",
      "\n",
      "[ Train epoch: 70 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011147629702463746\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.028966277837753296\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.027744730934500694\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018800821853801608\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006517768371850252\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.012988395057618618\n",
      "\n",
      "Total benign train accuarcy: 99.844\n",
      "Total benign train loss: 2.7051091263929266\n",
      "\n",
      "[ Test epoch: 70 ]\n",
      "\n",
      "Test accuarcy: 92.59\n",
      "Test average loss: 0.004062443474680186\n",
      "Model Saved!\n",
      "0.010721705844046872\n",
      "\n",
      "[ Train epoch: 71 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005724058137275279\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003005138598382473\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006688220892101526\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013848106609657407\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025306378956884146\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00122869573533535\n",
      "\n",
      "Total benign train accuarcy: 99.846\n",
      "Total benign train loss: 2.7821761767554563\n",
      "\n",
      "[ Test epoch: 71 ]\n",
      "\n",
      "Test accuarcy: 92.77\n",
      "Test average loss: 0.004139321872591972\n",
      "Model Saved!\n",
      "0.010507271727165934\n",
      "\n",
      "[ Train epoch: 72 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008996276301331818\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.040319591760635376\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0032851637806743383\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02182590775191784\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008788176928646863\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001614864799194038\n",
      "\n",
      "Total benign train accuarcy: 99.84\n",
      "Total benign train loss: 2.570649547742505\n",
      "\n",
      "[ Test epoch: 72 ]\n",
      "\n",
      "Test accuarcy: 92.57\n",
      "Test average loss: 0.0041910569798201324\n",
      "Model Saved!\n",
      "0.010297126292622616\n",
      "\n",
      "[ Train epoch: 73 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030980363953858614\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008757503237575293\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007222573738545179\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024416446685791016\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023132425267249346\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003501919563859701\n",
      "\n",
      "Total benign train accuarcy: 99.864\n",
      "Total benign train loss: 2.3438263633725\n",
      "\n",
      "[ Test epoch: 73 ]\n",
      "\n",
      "Test accuarcy: 92.77\n",
      "Test average loss: 0.003995310424268246\n",
      "Model Saved!\n",
      "0.010091183766770163\n",
      "\n",
      "[ Train epoch: 74 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007753735408186913\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006858794949948788\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009482029709033668\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007113155443221331\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00576151954010129\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002909459872171283\n",
      "\n",
      "Total benign train accuarcy: 99.866\n",
      "Total benign train loss: 2.2620030380894605\n",
      "\n",
      "[ Test epoch: 74 ]\n",
      "\n",
      "Test accuarcy: 92.9\n",
      "Test average loss: 0.003928062214329839\n",
      "Model Saved!\n",
      "0.009889360091434759\n",
      "\n",
      "[ Train epoch: 75 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00044333632104098797\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005011624889448285\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008694327436387539\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014425195986405015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011066625593230128\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00027491964283399284\n",
      "\n",
      "Total benign train accuarcy: 99.878\n",
      "Total benign train loss: 2.2344528723733674\n",
      "\n",
      "[ Test epoch: 75 ]\n",
      "\n",
      "Test accuarcy: 92.86\n",
      "Test average loss: 0.004052780837193131\n",
      "Model Saved!\n",
      "0.009691572889606063\n",
      "\n",
      "[ Train epoch: 76 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009365772712044418\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001915140077471733\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018106860807165504\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001206968809128739\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001051499741151929\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003259693505242467\n",
      "\n",
      "Total benign train accuarcy: 99.84\n",
      "Total benign train loss: 2.7191660130738455\n",
      "\n",
      "[ Test epoch: 76 ]\n",
      "\n",
      "Test accuarcy: 92.92\n",
      "Test average loss: 0.003974802471465682\n",
      "Model Saved!\n",
      "0.009497741431813941\n",
      "\n",
      "[ Train epoch: 77 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00028940499760210514\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002525154850445688\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002977586118504405\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005156188271939754\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024531581439077854\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002143417252227664\n",
      "\n",
      "Total benign train accuarcy: 99.89\n",
      "Total benign train loss: 1.9535090555073111\n",
      "\n",
      "[ Test epoch: 77 ]\n",
      "\n",
      "Test accuarcy: 93.05\n",
      "Test average loss: 0.003966607007198036\n",
      "Model Saved!\n",
      "0.009307786603177663\n",
      "\n",
      "[ Train epoch: 78 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.026447542011737823\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00011165886098751798\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016156467609107494\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001145056332461536\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00021919784194324166\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003713778452947736\n",
      "\n",
      "Total benign train accuarcy: 99.898\n",
      "Total benign train loss: 2.0155013189360034\n",
      "\n",
      "[ Test epoch: 78 ]\n",
      "\n",
      "Test accuarcy: 92.98\n",
      "Test average loss: 0.004001493395864963\n",
      "Model Saved!\n",
      "0.009121630871114108\n",
      "\n",
      "[ Train epoch: 79 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01011569332331419\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002361607039347291\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005397358909249306\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001165553112514317\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001924655050970614\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000470547383883968\n",
      "\n",
      "Total benign train accuarcy: 99.884\n",
      "Total benign train loss: 2.010314032289898\n",
      "\n",
      "[ Test epoch: 79 ]\n",
      "\n",
      "Test accuarcy: 93.13\n",
      "Test average loss: 0.004046520795114339\n",
      "Model Saved!\n",
      "0.008939198253691825\n",
      "\n",
      "[ Train epoch: 80 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015340737299993634\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005192806129343808\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000904484186321497\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004360271152108908\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013797975843772292\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007136142812669277\n",
      "\n",
      "Total benign train accuarcy: 99.9\n",
      "Total benign train loss: 1.751384942297591\n",
      "\n",
      "[ Test epoch: 80 ]\n",
      "\n",
      "Test accuarcy: 92.96\n",
      "Test average loss: 0.004128433137014508\n",
      "Model Saved!\n",
      "0.008760414288617988\n",
      "\n",
      "[ Train epoch: 81 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019321924773976207\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006861695437692106\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003819086996372789\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00027030185447074473\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005383042152971029\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002132527297362685\n",
      "\n",
      "Total benign train accuarcy: 99.888\n",
      "Total benign train loss: 1.8813439659570577\n",
      "\n",
      "[ Test epoch: 81 ]\n",
      "\n",
      "Test accuarcy: 93.16\n",
      "Test average loss: 0.004128515656292439\n",
      "Model Saved!\n",
      "0.008585206002845628\n",
      "\n",
      "[ Train epoch: 82 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016389712691307068\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001536114956252277\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009727533324621618\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008750761044211686\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019188743317499757\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02041834034025669\n",
      "\n",
      "Total benign train accuarcy: 99.92\n",
      "Total benign train loss: 1.7351890005666064\n",
      "\n",
      "[ Test epoch: 82 ]\n",
      "\n",
      "Test accuarcy: 93.06\n",
      "Test average loss: 0.00406185755841434\n",
      "Model Saved!\n",
      "0.008413501882788716\n",
      "\n",
      "[ Train epoch: 83 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002693558344617486\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00035573277273215353\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000326466717524454\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00017324382497463375\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0026143586728721857\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005967019242234528\n",
      "\n",
      "Total benign train accuarcy: 99.934\n",
      "Total benign train loss: 1.4811715389987512\n",
      "\n",
      "[ Test epoch: 83 ]\n",
      "\n",
      "Test accuarcy: 92.9\n",
      "Test average loss: 0.004075024901307188\n",
      "Model Saved!\n",
      "0.008245231845132941\n",
      "\n",
      "[ Train epoch: 84 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003145934082567692\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014279818860813975\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004421834892127663\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000331228511640802\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006244231481105089\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0063334316946566105\n",
      "\n",
      "Total benign train accuarcy: 99.902\n",
      "Total benign train loss: 1.582586996621103\n",
      "\n",
      "[ Test epoch: 84 ]\n",
      "\n",
      "Test accuarcy: 93.04\n",
      "Test average loss: 0.004161303567700088\n",
      "Model Saved!\n",
      "0.008080327208230282\n",
      "\n",
      "[ Train epoch: 85 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002748351253103465\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007473889272660017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001415417791577056\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0038750178646296263\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00012116798461647704\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023940876126289368\n",
      "\n",
      "Total benign train accuarcy: 99.926\n",
      "Total benign train loss: 1.5393921275026514\n",
      "\n",
      "[ Test epoch: 85 ]\n",
      "\n",
      "Test accuarcy: 93.11\n",
      "Test average loss: 0.004107859111018479\n",
      "Model Saved!\n",
      "0.007918720664065676\n",
      "\n",
      "[ Train epoch: 86 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0036062358412891626\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002398018492385745\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000587361166253686\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008698184392414987\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002029473427683115\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001552270259708166\n",
      "\n",
      "Total benign train accuarcy: 99.962\n",
      "Total benign train loss: 1.1640643611171981\n",
      "\n",
      "[ Test epoch: 86 ]\n",
      "\n",
      "Test accuarcy: 93.26\n",
      "Test average loss: 0.00410020975843072\n",
      "Model Saved!\n",
      "0.0077603462507843625\n",
      "\n",
      "[ Train epoch: 87 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 9.78993994067423e-05\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003149140626192093\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006218538037501276\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000590227369684726\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005893792258575559\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00251952582038939\n",
      "\n",
      "Total benign train accuarcy: 99.93\n",
      "Total benign train loss: 1.3396706403691496\n",
      "\n",
      "[ Test epoch: 87 ]\n",
      "\n",
      "Test accuarcy: 93.1\n",
      "Test average loss: 0.004035335757944267\n",
      "Model Saved!\n",
      "0.007605139325768675\n",
      "\n",
      "[ Train epoch: 88 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003647385456133634\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002259312430396676\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001191349234431982\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016931338468566537\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00022257409000303596\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005100047565065324\n",
      "\n",
      "Total benign train accuarcy: 99.92\n",
      "Total benign train loss: 1.58574243529074\n",
      "\n",
      "[ Test epoch: 88 ]\n",
      "\n",
      "Test accuarcy: 93.19\n",
      "Test average loss: 0.004066753663809504\n",
      "Model Saved!\n",
      "0.007453036539253301\n",
      "\n",
      "[ Train epoch: 89 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022793954703956842\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018145376816391945\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014309048419818282\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007031592540442944\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000461878371424973\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007495672325603664\n",
      "\n",
      "Total benign train accuarcy: 99.932\n",
      "Total benign train loss: 1.338479267746152\n",
      "\n",
      "[ Test epoch: 89 ]\n",
      "\n",
      "Test accuarcy: 92.94\n",
      "Test average loss: 0.00410276020988822\n",
      "Model Saved!\n",
      "0.007303975808468235\n",
      "\n",
      "[ Train epoch: 90 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008591007790528238\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006987007800489664\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 9.991382103180513e-05\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00021541172463912517\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.016189271584153175\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013664844445884228\n",
      "\n",
      "Total benign train accuarcy: 99.942\n",
      "Total benign train loss: 1.2090598516915634\n",
      "\n",
      "[ Test epoch: 90 ]\n",
      "\n",
      "Test accuarcy: 92.83\n",
      "Test average loss: 0.004068666814267635\n",
      "Model Saved!\n",
      "0.00715789629229887\n",
      "\n",
      "[ Train epoch: 91 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006640928331762552\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018968653166666627\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00016880031034816056\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00034732534550130367\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011997943511232734\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018029807833954692\n",
      "\n",
      "Total benign train accuarcy: 99.96\n",
      "Total benign train loss: 0.9482859625786659\n",
      "\n",
      "[ Test epoch: 91 ]\n",
      "\n",
      "Test accuarcy: 93.22\n",
      "Test average loss: 0.004067707446031272\n",
      "Model Saved!\n",
      "0.007014738366452893\n",
      "\n",
      "[ Train epoch: 92 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001025561010465026\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00025503846700303257\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002760415954980999\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00048784681712277234\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008471229113638401\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006751128821633756\n",
      "\n",
      "Total benign train accuarcy: 99.962\n",
      "Total benign train loss: 0.9651560117054032\n",
      "\n",
      "[ Test epoch: 92 ]\n",
      "\n",
      "Test accuarcy: 92.85\n",
      "Test average loss: 0.0042549712605774405\n",
      "Model Saved!\n",
      "0.006874443599123835\n",
      "\n",
      "[ Train epoch: 93 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014295084401965141\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.016319433227181435\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017213956452906132\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00019015300495084375\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018208179390057921\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002197508467361331\n",
      "\n",
      "Total benign train accuarcy: 99.95\n",
      "Total benign train loss: 1.0324615377321607\n",
      "\n",
      "[ Test epoch: 93 ]\n",
      "\n",
      "Test accuarcy: 93.02\n",
      "Test average loss: 0.004126459382474423\n",
      "Model Saved!\n",
      "0.006736954727141358\n",
      "\n",
      "[ Train epoch: 94 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006213842425495386\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001654173684073612\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004436758754309267\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001791756512830034\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 8.37305560708046e-05\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00015399297990370542\n",
      "\n",
      "Total benign train accuarcy: 99.952\n",
      "Total benign train loss: 1.1058626343292417\n",
      "\n",
      "[ Test epoch: 94 ]\n",
      "\n",
      "Test accuarcy: 93.02\n",
      "Test average loss: 0.003999674900155514\n",
      "Model Saved!\n",
      "0.006602215632598531\n",
      "\n",
      "[ Train epoch: 95 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011285030050203204\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003532063274178654\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001992835896089673\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006059693987481296\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016757580451667309\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.013690323568880558\n",
      "\n",
      "Total benign train accuarcy: 99.972\n",
      "Total benign train loss: 0.827881206292659\n",
      "\n",
      "[ Test epoch: 95 ]\n",
      "\n",
      "Test accuarcy: 93.2\n",
      "Test average loss: 0.0040220388450892645\n",
      "Model Saved!\n",
      "0.00647017131994656\n",
      "\n",
      "[ Train epoch: 96 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00029844578239135444\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002942536666523665\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006032399251125753\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00021754401677753776\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00012404857261572033\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012179916957393289\n",
      "\n",
      "Total benign train accuarcy: 99.962\n",
      "Total benign train loss: 0.8437474721558829\n",
      "\n",
      "[ Test epoch: 96 ]\n",
      "\n",
      "Test accuarcy: 92.97\n",
      "Test average loss: 0.004090684382454492\n",
      "Model Saved!\n",
      "0.006340767893547629\n",
      "\n",
      "[ Train epoch: 97 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001347675104625523\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00012222652730997652\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00015783637354616076\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004186854639556259\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006133182905614376\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.011983983218669891\n",
      "\n",
      "Total benign train accuarcy: 99.952\n",
      "Total benign train loss: 1.0043875899064005\n",
      "\n",
      "[ Test epoch: 97 ]\n",
      "\n",
      "Test accuarcy: 93.01\n",
      "Test average loss: 0.004142058560065925\n",
      "Model Saved!\n",
      "0.006213952535676676\n",
      "\n",
      "[ Train epoch: 98 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005619552102871239\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00012609221448656172\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00413699122145772\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021473546512424946\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004188000748399645\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006714091286994517\n",
      "\n",
      "Total benign train accuarcy: 99.95\n",
      "Total benign train loss: 1.017870388834126\n",
      "\n",
      "[ Test epoch: 98 ]\n",
      "\n",
      "Test accuarcy: 92.9\n",
      "Test average loss: 0.004256042198836804\n",
      "Model Saved!\n",
      "0.006089673484963142\n",
      "\n",
      "[ Train epoch: 99 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00012331157631706446\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005117217660881579\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007138554356060922\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 7.25385980331339e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010812628315761685\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.035593461245298386\n",
      "\n",
      "Total benign train accuarcy: 99.974\n",
      "Total benign train loss: 0.7323725556379941\n",
      "\n",
      "[ Test epoch: 99 ]\n",
      "\n",
      "Test accuarcy: 93.08\n",
      "Test average loss: 0.004063649430219084\n",
      "Model Saved!\n",
      "0.005967880015263879\n",
      "\n",
      "[ Train epoch: 100 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00040518221794627607\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005521757993847132\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001296245725825429\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001524458290077746\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.011985324323177338\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.010831252671778202\n",
      "\n",
      "Total benign train accuarcy: 99.954\n",
      "Total benign train loss: 0.8804039190727053\n",
      "\n",
      "[ Test epoch: 100 ]\n",
      "\n",
      "Test accuarcy: 92.95\n",
      "Test average loss: 0.004121158707141876\n",
      "Model Saved!\n",
      "0.005848522414958601\n",
      "\n",
      "[ Train epoch: 101 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009331554174423218\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000786420947406441\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0035060772206634283\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000142915261676535\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005476285587064922\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00031177292112261057\n",
      "\n",
      "Total benign train accuarcy: 99.95\n",
      "Total benign train loss: 0.924169682450156\n",
      "\n",
      "[ Test epoch: 101 ]\n",
      "\n",
      "Test accuarcy: 93.09\n",
      "Test average loss: 0.004135152886062861\n",
      "Model Saved!\n",
      "0.005731551966659429\n",
      "\n",
      "[ Train epoch: 102 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0033857321832329035\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 3.678061329992488e-05\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007363331969827414\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002770527789834887\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00010302682494511828\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015994937857612967\n",
      "\n",
      "Total benign train accuarcy: 99.96\n",
      "Total benign train loss: 0.8111398672781434\n",
      "\n",
      "[ Test epoch: 102 ]\n",
      "\n",
      "Test accuarcy: 93.2\n",
      "Test average loss: 0.0040297274800715965\n",
      "Model Saved!\n",
      "0.00561692092732624\n",
      "\n",
      "[ Train epoch: 103 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00016039096226450056\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00047587486915290356\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005559814744628966\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00026092352345585823\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003180417697876692\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007237896788865328\n",
      "\n",
      "Total benign train accuarcy: 99.966\n",
      "Total benign train loss: 0.8041453323603491\n",
      "\n",
      "[ Test epoch: 103 ]\n",
      "\n",
      "Test accuarcy: 92.99\n",
      "Test average loss: 0.004127788181230426\n",
      "Model Saved!\n",
      "0.0055045825087797155\n",
      "\n",
      "[ Train epoch: 104 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00024575492716394365\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00017119781114161015\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009700730443000793\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022587210405617952\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006569051765836775\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011363559169694781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign train accuarcy: 99.968\n",
      "Total benign train loss: 0.7653265863255001\n",
      "\n",
      "[ Test epoch: 104 ]\n",
      "\n",
      "Test accuarcy: 92.96\n",
      "Test average loss: 0.00405866172797978\n",
      "Model Saved!\n",
      "0.005394490858604121\n",
      "\n",
      "[ Train epoch: 105 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016431808471679688\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00017934235802385956\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 9.86360537353903e-05\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006573752034455538\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0029055923223495483\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00030045249150134623\n",
      "\n",
      "Total benign train accuarcy: 99.97\n",
      "Total benign train loss: 0.6744416667133919\n",
      "\n",
      "[ Test epoch: 105 ]\n",
      "\n",
      "Test accuarcy: 93.06\n",
      "Test average loss: 0.004218268181383609\n",
      "Model Saved!\n",
      "0.0052866010414320385\n",
      "\n",
      "[ Train epoch: 106 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002681695914361626\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00021011853823438287\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008965221350081265\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 8.995641837827861e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00023823592346161604\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003609267296269536\n",
      "\n",
      "Total benign train accuarcy: 99.986\n",
      "Total benign train loss: 0.6047642289595387\n",
      "\n",
      "[ Test epoch: 106 ]\n",
      "\n",
      "Test accuarcy: 93.17\n",
      "Test average loss: 0.004081524996459484\n",
      "Model Saved!\n",
      "0.005180869020603398\n",
      "\n",
      "[ Train epoch: 107 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003127947566099465\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000782033137511462\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00017834776372183114\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 7.23947086953558e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009238826460205019\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001051564235240221\n",
      "\n",
      "Total benign train accuarcy: 99.982\n",
      "Total benign train loss: 0.6237514306867524\n",
      "\n",
      "[ Test epoch: 107 ]\n",
      "\n",
      "Test accuarcy: 93.1\n",
      "Test average loss: 0.0039745292105711994\n",
      "Model Saved!\n",
      "0.005077251640191329\n",
      "\n",
      "[ Train epoch: 108 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00038521771784871817\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00014726615336257964\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002416122442809865\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008464159327559173\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022823770996183157\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00026334059657528996\n",
      "\n",
      "Total benign train accuarcy: 99.968\n",
      "Total benign train loss: 0.7719022907403996\n",
      "\n",
      "[ Test epoch: 108 ]\n",
      "\n",
      "Test accuarcy: 93.2\n",
      "Test average loss: 0.003980728512572569\n",
      "Model Saved!\n",
      "0.004975706607387503\n",
      "\n",
      "[ Train epoch: 109 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00037521973717957735\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00017795409075915813\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00042736579780466855\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028612231835722923\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003262442769482732\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0033998352009803057\n",
      "\n",
      "Total benign train accuarcy: 99.98\n",
      "Total benign train loss: 0.6260565636785032\n",
      "\n",
      "[ Test epoch: 109 ]\n",
      "\n",
      "Test accuarcy: 93.04\n",
      "Test average loss: 0.004077401431091129\n",
      "Model Saved!\n",
      "0.004876192475239753\n",
      "\n",
      "[ Train epoch: 110 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00036617612931877375\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018977654399350286\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00016396075079683214\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00017255701823160052\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019114548340439796\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001926220575114712\n",
      "\n",
      "Total benign train accuarcy: 99.968\n",
      "Total benign train loss: 0.6884780718937691\n",
      "\n",
      "[ Test epoch: 110 ]\n",
      "\n",
      "Test accuarcy: 93.19\n",
      "Test average loss: 0.003943534802272916\n",
      "Model Saved!\n",
      "0.004778668625734958\n",
      "\n",
      "[ Train epoch: 111 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007276080432347953\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006655660108663142\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009173119906336069\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00016146971029229462\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007866117521189153\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001952477265149355\n",
      "\n",
      "Total benign train accuarcy: 99.964\n",
      "Total benign train loss: 0.7119752213366155\n",
      "\n",
      "[ Test epoch: 111 ]\n",
      "\n",
      "Test accuarcy: 93.27\n",
      "Test average loss: 0.004021704119071365\n",
      "Model Saved!\n",
      "0.004683095253220258\n",
      "\n",
      "[ Train epoch: 112 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00010315204417565838\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006479067960754037\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018720630323514342\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 7.75395892560482e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002783362870104611\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00023174578382167965\n",
      "\n",
      "Total benign train accuarcy: 99.976\n",
      "Total benign train loss: 0.5947029936360195\n",
      "\n",
      "[ Test epoch: 112 ]\n",
      "\n",
      "Test accuarcy: 93.26\n",
      "Test average loss: 0.004010834541171789\n",
      "Model Saved!\n",
      "0.004589433348155853\n",
      "\n",
      "[ Train epoch: 113 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00018127939256373793\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006439584540203214\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005348750273697078\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00023074215278029442\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 5.7415105402469635e-05\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00028910013497807086\n",
      "\n",
      "Total benign train accuarcy: 99.974\n",
      "Total benign train loss: 0.5557953436764365\n",
      "\n",
      "[ Test epoch: 113 ]\n",
      "\n",
      "Test accuarcy: 93.14\n",
      "Test average loss: 0.004100476053357125\n",
      "Model Saved!\n",
      "0.004497644681192735\n",
      "\n",
      "[ Train epoch: 114 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003337981877848506\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021885521709918976\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030628452077507973\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003482913365587592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00013078188931103796\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000756399764213711\n",
      "\n",
      "Total benign train accuarcy: 99.97\n",
      "Total benign train loss: 0.6241519628620154\n",
      "\n",
      "[ Test epoch: 114 ]\n",
      "\n",
      "Test accuarcy: 93.19\n",
      "Test average loss: 0.004087209567427635\n",
      "Model Saved!\n",
      "0.004407691787568881\n",
      "\n",
      "[ Train epoch: 115 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00011562591680558398\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 7.25480931578204e-05\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018356508808210492\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007788295042701066\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00012789775792043656\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005755267920903862\n",
      "\n",
      "Total benign train accuarcy: 99.972\n",
      "Total benign train loss: 0.6449794296204345\n",
      "\n",
      "[ Test epoch: 115 ]\n",
      "\n",
      "Test accuarcy: 93.12\n",
      "Test average loss: 0.004045300842797406\n",
      "Model Saved!\n",
      "0.004319537951817503\n",
      "\n",
      "[ Train epoch: 116 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012154312571510673\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005177845014259219\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030335041228681803\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009772275807335973\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 3.800721242441796e-05\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002580173604656011\n",
      "\n",
      "Total benign train accuarcy: 99.98\n",
      "Total benign train loss: 0.5304659001267282\n",
      "\n",
      "[ Test epoch: 116 ]\n",
      "\n",
      "Test accuarcy: 93.15\n",
      "Test average loss: 0.00405655747577548\n",
      "Model Saved!\n",
      "0.0042331471927811535\n",
      "\n",
      "[ Train epoch: 117 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002267185627715662\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00011123935837531462\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004490842402447015\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005228096270002425\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016366018680855632\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011071701301261783\n",
      "\n",
      "Total benign train accuarcy: 99.986\n",
      "Total benign train loss: 0.5368292543735151\n",
      "\n",
      "[ Test epoch: 117 ]\n",
      "\n",
      "Test accuarcy: 93.17\n",
      "Test average loss: 0.004061218176782132\n",
      "Model Saved!\n",
      "0.00414848424892553\n",
      "\n",
      "[ Train epoch: 118 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003185949462931603\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010028778342530131\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00030497374245896935\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00032019513309933245\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006346033187583089\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00017591095820534974\n",
      "\n",
      "Total benign train accuarcy: 99.982\n",
      "Total benign train loss: 0.509708632260299\n",
      "\n",
      "[ Test epoch: 118 ]\n",
      "\n",
      "Test accuarcy: 93.15\n",
      "Test average loss: 0.003999008038640023\n",
      "Model Saved!\n",
      "0.004065514563947019\n",
      "\n",
      "[ Train epoch: 119 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00036564760375767946\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004350891977082938\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00010898561595240608\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004197859962005168\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002713780850172043\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 3.3897755201905966e-05\n",
      "\n",
      "Total benign train accuarcy: 99.984\n",
      "Total benign train loss: 0.5398024662172247\n",
      "\n",
      "[ Test epoch: 119 ]\n",
      "\n",
      "Test accuarcy: 93.01\n",
      "Test average loss: 0.00408624087870121\n",
      "Model Saved!\n",
      "0.003984204272668079\n",
      "\n",
      "[ Train epoch: 120 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001670156023465097\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002297085156897083\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001390963006997481\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 5.0361024477751926e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00045293045695871115\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008168087806552649\n",
      "\n",
      "Total benign train accuarcy: 99.99\n",
      "Total benign train loss: 0.47281117239253945\n",
      "\n",
      "[ Test epoch: 120 ]\n",
      "\n",
      "Test accuarcy: 93.06\n",
      "Test average loss: 0.004159898874163627\n",
      "Model Saved!\n",
      "0.003904520187214717\n",
      "\n",
      "[ Train epoch: 121 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 6.271584425121546e-05\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000987776555120945\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00042673072312027216\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 6.756674702046439e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003350434126332402\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00022371260274667293\n",
      "\n",
      "Total benign train accuarcy: 99.986\n",
      "Total benign train loss: 0.4696678439358948\n",
      "\n",
      "[ Test epoch: 121 ]\n",
      "\n",
      "Test accuarcy: 93.11\n",
      "Test average loss: 0.004018785264901817\n",
      "Model Saved!\n",
      "0.0038264297834704228\n",
      "\n",
      "[ Train epoch: 122 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004401605110615492\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00013058785407338291\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003309432358946651\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002575911348685622\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005233194096945226\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002514504303690046\n",
      "\n",
      "Total benign train accuarcy: 99.992\n",
      "Total benign train loss: 0.41000680518118315\n",
      "\n",
      "[ Test epoch: 122 ]\n",
      "\n",
      "Test accuarcy: 93.2\n",
      "Test average loss: 0.004092794924043119\n",
      "Model Saved!\n",
      "0.0037499011878010143\n",
      "\n",
      "[ Train epoch: 123 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001411048142472282\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001256614486919716\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004295240214560181\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003088588418904692\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002068785106530413\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002715824171900749\n",
      "\n",
      "Total benign train accuarcy: 99.978\n",
      "Total benign train loss: 0.5278805748039304\n",
      "\n",
      "[ Test epoch: 123 ]\n",
      "\n",
      "Test accuarcy: 93.24\n",
      "Test average loss: 0.004050555530190468\n",
      "Model Saved!\n",
      "0.003674903164044994\n",
      "\n",
      "[ Train epoch: 124 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 4.9274578486802056e-05\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00212088949047029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007805692148394883\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005533341900445521\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 8.468994201393798e-05\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00025035563157871366\n",
      "\n",
      "Total benign train accuarcy: 99.972\n",
      "Total benign train loss: 0.6026331834600569\n",
      "\n",
      "[ Test epoch: 124 ]\n",
      "\n",
      "Test accuarcy: 93.0\n",
      "Test average loss: 0.0041449201576411725\n",
      "Model Saved!\n",
      "0.003601405100764094\n",
      "\n",
      "[ Train epoch: 125 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 9.617264004191384e-05\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008926595910452306\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001824076025513932\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00035729771479964256\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00011382885713828728\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001739009312586859\n",
      "\n",
      "Total benign train accuarcy: 99.974\n",
      "Total benign train loss: 0.5425214196748129\n",
      "\n",
      "[ Test epoch: 125 ]\n",
      "\n",
      "Test accuarcy: 93.13\n",
      "Test average loss: 0.004093044759333133\n",
      "Model Saved!\n",
      "0.003529376998748812\n",
      "\n",
      "[ Train epoch: 126 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00014575672685168684\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00020919986127410084\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 5.347884143702686e-05\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003333655185997486\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00013000695616938174\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006071124807931483\n",
      "\n",
      "Total benign train accuarcy: 99.984\n",
      "Total benign train loss: 0.5219118827972125\n",
      "\n",
      "[ Test epoch: 126 ]\n",
      "\n",
      "Test accuarcy: 93.08\n",
      "Test average loss: 0.004059799235220998\n",
      "Model Saved!\n",
      "0.0034587894587738356\n",
      "\n",
      "[ Train epoch: 127 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001649511541472748\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00033258143230341375\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003653705818578601\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006275740917772055\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003742145199794322\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004460877273231745\n",
      "\n",
      "Total benign train accuarcy: 99.99\n",
      "Total benign train loss: 0.48402010652716854\n",
      "\n",
      "[ Test epoch: 127 ]\n",
      "\n",
      "Test accuarcy: 93.17\n",
      "Test average loss: 0.004154087199270726\n",
      "Model Saved!\n",
      "0.003389613669598359\n",
      "\n",
      "[ Train epoch: 128 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025141402147710323\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001265212777070701\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00022909545805305243\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005661845207214355\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007772495155222714\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00042007307638414204\n",
      "\n",
      "Total benign train accuarcy: 99.978\n",
      "Total benign train loss: 0.4808752114622621\n",
      "\n",
      "[ Test epoch: 128 ]\n",
      "\n",
      "Test accuarcy: 93.32\n",
      "Test average loss: 0.004081575986742973\n",
      "Model Saved!\n",
      "0.003321821396206392\n",
      "\n",
      "[ Train epoch: 129 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 8.007040014490485e-05\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009532488766126335\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00011056217044824734\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005605365731753409\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007503644446842372\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00022252612689044327\n",
      "\n",
      "Total benign train accuarcy: 99.974\n",
      "Total benign train loss: 0.5393902089817857\n",
      "\n",
      "[ Test epoch: 129 ]\n",
      "\n",
      "Test accuarcy: 93.26\n",
      "Test average loss: 0.004082549180462957\n",
      "Model Saved!\n",
      "0.003255384968282264\n",
      "\n",
      "[ Train epoch: 130 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00017814245074987411\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031494491267949343\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00011926495790248737\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003108993696514517\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00026527169393375516\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002603930188342929\n",
      "\n",
      "Total benign train accuarcy: 99.976\n",
      "Total benign train loss: 0.520124430729993\n",
      "\n",
      "[ Test epoch: 130 ]\n",
      "\n",
      "Test accuarcy: 93.15\n",
      "Test average loss: 0.004055674678087234\n",
      "Model Saved!\n",
      "0.0031902772689166186\n",
      "\n",
      "[ Train epoch: 131 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001228939654538408\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000155342961079441\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00013282420695759356\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 9.316030627815053e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002993317029904574\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003367895551491529\n",
      "\n",
      "Total benign train accuarcy: 99.984\n",
      "Total benign train loss: 0.4077511828072602\n",
      "\n",
      "[ Test epoch: 131 ]\n",
      "\n",
      "Test accuarcy: 93.19\n",
      "Test average loss: 0.004030073322914541\n",
      "Model Saved!\n",
      "0.003126471723538286\n",
      "\n",
      "[ Train epoch: 132 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00033819922828115523\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 6.875226245028898e-05\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002457026857882738\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 8.619324216851965e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003218545753043145\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012797076487913728\n",
      "\n",
      "Total benign train accuarcy: 99.98\n",
      "Total benign train loss: 0.45019685427723743\n",
      "\n",
      "[ Test epoch: 132 ]\n",
      "\n",
      "Test accuarcy: 93.15\n",
      "Test average loss: 0.0041567368105053905\n",
      "Model Saved!\n",
      "0.0030639422890675204\n",
      "\n",
      "[ Train epoch: 133 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030183757189661264\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002221956616267562\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002330634306417778\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001877687405794859\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00012788503954652697\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017669000662863255\n",
      "\n",
      "Total benign train accuarcy: 99.986\n",
      "Total benign train loss: 0.4195328480327589\n",
      "\n",
      "[ Test epoch: 133 ]\n",
      "\n",
      "Test accuarcy: 93.19\n",
      "Test average loss: 0.00405428946018219\n",
      "Model Saved!\n",
      "0.00300266344328617\n",
      "\n",
      "[ Train epoch: 134 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002512498525902629\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002670255780685693\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 4.185804209555499e-05\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0057728830724954605\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002948449400719255\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002815220213960856\n",
      "\n",
      "Total benign train accuarcy: 99.986\n",
      "Total benign train loss: 0.4543916994098254\n",
      "\n",
      "[ Test epoch: 134 ]\n",
      "\n",
      "Test accuarcy: 93.13\n",
      "Test average loss: 0.0040367754402755055\n",
      "Model Saved!\n",
      "0.0029426101744204464\n",
      "\n",
      "[ Train epoch: 135 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001553110923850909\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00021821493282914162\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00024177033628802747\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013814247213304043\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007834008429199457\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00045215326827019453\n",
      "\n",
      "Total benign train accuarcy: 99.992\n",
      "Total benign train loss: 0.46155174892555806\n",
      "\n",
      "[ Test epoch: 135 ]\n",
      "\n",
      "Test accuarcy: 93.07\n",
      "Test average loss: 0.0040335251473239625\n",
      "Model Saved!\n",
      "0.0028837579709320373\n",
      "\n",
      "[ Train epoch: 136 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005328978295437992\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00044260951108299196\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00040646581328473985\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 5.0285383622394875e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00028558511985465884\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00016852501721587032\n",
      "\n",
      "Total benign train accuarcy: 99.99\n",
      "Total benign train loss: 0.3633211972010031\n",
      "\n",
      "[ Test epoch: 136 ]\n",
      "\n",
      "Test accuarcy: 93.23\n",
      "Test average loss: 0.004134246626496315\n",
      "Model Saved!\n",
      "0.0028260828115133966\n",
      "\n",
      "[ Train epoch: 137 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004066702676936984\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000534399354364723\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00015550816897302866\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004606622678693384\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013848855160176754\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004927393165417016\n",
      "\n",
      "Total benign train accuarcy: 99.996\n",
      "Total benign train loss: 0.378449671472481\n",
      "\n",
      "[ Test epoch: 137 ]\n",
      "\n",
      "Test accuarcy: 93.19\n",
      "Test average loss: 0.00402430158086645\n",
      "Model Saved!\n",
      "0.0027695611552831286\n",
      "\n",
      "[ Train epoch: 138 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002489574020728469\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00011681600153679028\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00011118653492303565\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00041805082582868636\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017176573164761066\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 4.723381789517589e-05\n",
      "\n",
      "Total benign train accuarcy: 99.986\n",
      "Total benign train loss: 0.41807949177746195\n",
      "\n",
      "[ Test epoch: 138 ]\n",
      "\n",
      "Test accuarcy: 93.12\n",
      "Test average loss: 0.004107721355557442\n",
      "Model Saved!\n",
      "0.002714169932177466\n",
      "\n",
      "[ Train epoch: 139 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00033555409754626453\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00027570597012527287\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01236964762210846\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004115271440241486\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 7.168843148974702e-05\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012839981354773045\n",
      "\n",
      "Total benign train accuarcy: 99.99\n",
      "Total benign train loss: 0.3682090152578894\n",
      "\n",
      "[ Test epoch: 139 ]\n",
      "\n",
      "Test accuarcy: 93.19\n",
      "Test average loss: 0.004030250347219408\n",
      "Model Saved!\n",
      "0.002659886533533917\n",
      "\n",
      "[ Train epoch: 140 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00198700581677258\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 5.0870690756710246e-05\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00020836990734096617\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00044083266402594745\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004436678718775511\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00038744835183024406\n",
      "\n",
      "Total benign train accuarcy: 99.984\n",
      "Total benign train loss: 0.41223150694168\n",
      "\n",
      "[ Test epoch: 140 ]\n",
      "\n",
      "Test accuarcy: 93.25\n",
      "Test average loss: 0.00406700267791748\n",
      "Model Saved!\n",
      "0.0026066888028632384\n",
      "\n",
      "[ Train epoch: 141 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00022788933711126447\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00023297521693166345\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006611475837416947\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00021899807325098664\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002272592973895371\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00031746175955049694\n",
      "\n",
      "Total benign train accuarcy: 99.986\n",
      "Total benign train loss: 0.4001461794596253\n",
      "\n",
      "[ Test epoch: 141 ]\n",
      "\n",
      "Test accuarcy: 93.23\n",
      "Test average loss: 0.00410635183788836\n",
      "Model Saved!\n",
      "0.0025545550268059737\n",
      "\n",
      "[ Train epoch: 142 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005009169690310955\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005216519930399954\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006695722113363445\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 5.5694003094686195e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00019578302453737706\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00012124771456001326\n",
      "\n",
      "Total benign train accuarcy: 99.994\n",
      "Total benign train loss: 0.3568745420107007\n",
      "\n",
      "[ Test epoch: 142 ]\n",
      "\n",
      "Test accuarcy: 93.19\n",
      "Test average loss: 0.004053165951371193\n",
      "Model Saved!\n",
      "0.0025034639262698543\n",
      "\n",
      "[ Train epoch: 143 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00029169293702580035\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00028235322679392993\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 8.823131065582857e-05\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00020843457605224103\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003835414827335626\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 5.938500908087008e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign train accuarcy: 99.998\n",
      "Total benign train loss: 0.31727679089453886\n",
      "\n",
      "[ Test epoch: 143 ]\n",
      "\n",
      "Test accuarcy: 93.37\n",
      "Test average loss: 0.004068326129950583\n",
      "Model Saved!\n",
      "0.0024533946477444573\n",
      "\n",
      "[ Train epoch: 144 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004365095228422433\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002512200444471091\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004950076690874994\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002525474119465798\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002146669285139069\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00016647989104967564\n",
      "\n",
      "Total benign train accuarcy: 99.986\n",
      "Total benign train loss: 0.42196770794907934\n",
      "\n",
      "[ Test epoch: 144 ]\n",
      "\n",
      "Test accuarcy: 93.08\n",
      "Test average loss: 0.004062726192176342\n",
      "Model Saved!\n",
      "0.002404326754789568\n",
      "\n",
      "[ Train epoch: 145 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00018983827612828463\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00011987279140157625\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001828579552238807\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00012868530757259578\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008169224602170289\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00040672835893929005\n",
      "\n",
      "Total benign train accuarcy: 99.99\n",
      "Total benign train loss: 0.3919593489572435\n",
      "\n",
      "[ Test epoch: 145 ]\n",
      "\n",
      "Test accuarcy: 93.17\n",
      "Test average loss: 0.004026967208087444\n",
      "Model Saved!\n",
      "0.0023562402196937765\n",
      "\n",
      "[ Train epoch: 146 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00037370409700088203\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 9.262529783882201e-05\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00016228821186814457\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021036379039287567\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003929338708985597\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 6.018744534230791e-05\n",
      "\n",
      "Total benign train accuarcy: 99.986\n",
      "Total benign train loss: 0.40136722889837984\n",
      "\n",
      "[ Test epoch: 146 ]\n",
      "\n",
      "Test accuarcy: 93.12\n",
      "Test average loss: 0.004094737271592021\n",
      "Model Saved!\n",
      "0.002309115415299901\n",
      "\n",
      "[ Train epoch: 147 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001812132977647707\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001139298765338026\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002238371380371973\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 9.382885036757216e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010698827682062984\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00021018536062911153\n",
      "\n",
      "Total benign train accuarcy: 99.99\n",
      "Total benign train loss: 0.40917576239189657\n",
      "\n",
      "[ Test epoch: 147 ]\n",
      "\n",
      "Test accuarcy: 93.19\n",
      "Test average loss: 0.004087686225399375\n",
      "Model Saved!\n",
      "0.002262933106993903\n",
      "\n",
      "[ Train epoch: 148 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002475849469192326\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002529541670810431\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0288198534399271\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00021705153631046414\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00023107054585125297\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001806729007512331\n",
      "\n",
      "Total benign train accuarcy: 99.992\n",
      "Total benign train loss: 0.3344825128424418\n",
      "\n",
      "[ Test epoch: 148 ]\n",
      "\n",
      "Test accuarcy: 93.23\n",
      "Test average loss: 0.0040520218485966325\n",
      "Model Saved!\n",
      "0.002217674444854025\n",
      "\n",
      "[ Train epoch: 149 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005446669179946184\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00010188805754296482\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 8.303976937895641e-05\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004104980325791985\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010975707555189729\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001882371143437922\n",
      "\n",
      "Total benign train accuarcy: 99.982\n",
      "Total benign train loss: 0.46514685258443933\n",
      "\n",
      "[ Test epoch: 149 ]\n",
      "\n",
      "Test accuarcy: 93.24\n",
      "Test average loss: 0.004014061074587517\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 150):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(0,150)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1) \n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss') \n",
    "plt.plot(epochs,loss_list) \n",
    "plt.subplot(1,2,2) \n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.plot(epochs, accuracy_list) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_sh",
   "language": "python",
   "name": "conda_sh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
