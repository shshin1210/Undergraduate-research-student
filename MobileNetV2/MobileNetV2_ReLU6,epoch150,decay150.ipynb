{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  3 19:42:46 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\r\n",
      "| N/A   33C    P0    37W / 300W |     10MiB / 32480MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\r\n",
      "| N/A   33C    P0    39W / 300W |     10MiB / 32480MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:07.0 Off |                  Off |\r\n",
      "| N/A   56C    P0   188W / 300W |   5733MiB / 32480MiB |     78%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    2    104558      C   /home/ubuntu/anaconda3/envs/sh/bin/python   5723MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding =4), #cifar 10 image size : 32x32\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './data', train=True, \n",
    "                download= True, transform = transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = './data', train = False,\n",
    "                download=True, transform= transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=96,\n",
    "                                          shuffle = True, num_workers = 2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=96,\n",
    "                                         shuffle =True, num_workers =2)\n",
    "\n",
    "#num_workers =2 인지 4인지 or batch_size test의 경우는 왜 100인지?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ReLU6 in Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    '''expand + depthwise + pointwise'''\n",
    "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
    "        super(Block, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "        planes = expansion * in_planes\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, groups=planes, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride == 1 and in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu6(self.bn1(self.conv1(x)))\n",
    "        out = F.relu6(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = out + self.shortcut(x) if self.stride==1 else out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    # (expansion, out_planes, num_blocks, stride)\n",
    "    cfg = [(1,  16, 1, 1),\n",
    "           (6,  24, 2, 1),  # NOTE: change stride 2 -> 1 for CIFAR10\n",
    "           (6,  32, 3, 2),\n",
    "           (6,  64, 4, 2),\n",
    "           (6,  96, 3, 1),\n",
    "           (6, 160, 3, 2),\n",
    "           (6, 320, 1, 1)]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # NOTE: change conv1 stride 2 -> 1 for CIFAR10\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32)\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.linear = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for expansion, out_planes, num_blocks, stride in self.cfg:\n",
    "            strides = [stride] + [1]*(num_blocks-1)\n",
    "            for stride in strides:\n",
    "                layers.append(Block(in_planes, out_planes, expansion, stride))\n",
    "                in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        # NOTE: change pooling kernel_size 7 -> 4 for CIFAR10\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MobileNetV2()\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "learning_rate = 0.045\n",
    "file_name = 'resnet18_cifar10.pt'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.00004)\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list=[]\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        benign_outputs = net(inputs)\n",
    "        loss = criterion(benign_outputs, targets)#예측값과 실제 타깃값\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = benign_outputs.max(1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current benign train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "            print('Current benign train loss:', loss.item())\n",
    "\n",
    "    print('\\nTotal benign train accuarcy:', 100. * correct / total)\n",
    "    print('Total benign train loss:', train_loss)\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        total += targets.size(0)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss += criterion(outputs, targets).item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    accuracy_list.append(100. * correct / total)\n",
    "    print('\\nTest accuarcy:', 100. * correct / total)\n",
    "    loss_list.append(loss)\n",
    "    print('Test average loss:', loss / total)    \n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved!')\n",
    "\n",
    "\n",
    "        \n",
    "#learning rate를 바꾸기\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = param_group['lr']\n",
    "        if epoch <=150 and epoch != 0:\n",
    "            param_group['lr'] = lr * 0.98\n",
    "        print(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045\n",
      "\n",
      "[ Train epoch: 0 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.2119487524032593\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 1.079217553138733\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6458333333333334\n",
      "Current benign train loss: 0.9185301661491394\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.6979166666666666\n",
      "Current benign train loss: 0.8974875807762146\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7291666666666666\n",
      "Current benign train loss: 0.722384512424469\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6864789128303528\n",
      "\n",
      "Total benign train accuarcy: 64.51\n",
      "Total benign train loss: 524.3971230983734\n",
      "\n",
      "[ Test epoch: 0 ]\n",
      "\n",
      "Test accuarcy: 67.2\n",
      "Test average loss: 0.009961682322621346\n",
      "Model Saved!\n",
      "0.0441\n",
      "\n",
      "[ Train epoch: 1 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8020833333333334\n",
      "Current benign train loss: 0.6685884594917297\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6770833333333334\n",
      "Current benign train loss: 0.7596678733825684\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5891218185424805\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7604166666666666\n",
      "Current benign train loss: 0.6366651654243469\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7708333333333334\n",
      "Current benign train loss: 0.7265196442604065\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6577731966972351\n",
      "\n",
      "Total benign train accuarcy: 72.274\n",
      "Total benign train loss: 415.70208409428596\n",
      "\n",
      "[ Test epoch: 1 ]\n",
      "\n",
      "Test accuarcy: 74.02\n",
      "Test average loss: 0.00814120155274868\n",
      "Model Saved!\n",
      "0.043218\n",
      "\n",
      "[ Train epoch: 2 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7272656559944153\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.589732825756073\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7916666666666666\n",
      "Current benign train loss: 0.7737849354743958\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5711937546730042\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5860489010810852\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8020833333333334\n",
      "Current benign train loss: 0.5731166005134583\n",
      "\n",
      "Total benign train accuarcy: 76.722\n",
      "Total benign train loss: 348.1293677687645\n",
      "\n",
      "[ Test epoch: 2 ]\n",
      "\n",
      "Test accuarcy: 76.79\n",
      "Test average loss: 0.007320252630114555\n",
      "Model Saved!\n",
      "0.04235364\n",
      "\n",
      "[ Train epoch: 3 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.6770833333333334\n",
      "Current benign train loss: 0.8551526069641113\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7647847533226013\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.47808441519737244\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.4477386474609375\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.4939459264278412\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8229166666666666\n",
      "Current benign train loss: 0.5028693675994873\n",
      "\n",
      "Total benign train accuarcy: 79.512\n",
      "Total benign train loss: 308.8989952802658\n",
      "\n",
      "[ Test epoch: 3 ]\n",
      "\n",
      "Test accuarcy: 80.6\n",
      "Test average loss: 0.0059231654047966\n",
      "Model Saved!\n",
      "0.0415065672\n",
      "\n",
      "[ Train epoch: 4 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.4594702422618866\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.455247163772583\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8645833333333334\n",
      "Current benign train loss: 0.3837963044643402\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7604166666666666\n",
      "Current benign train loss: 0.5784515738487244\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.5284176468849182\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.4787149131298065\n",
      "\n",
      "Total benign train accuarcy: 81.372\n",
      "Total benign train loss: 278.24145233631134\n",
      "\n",
      "[ Test epoch: 4 ]\n",
      "\n",
      "Test accuarcy: 81.32\n",
      "Test average loss: 0.00583915728777647\n",
      "Model Saved!\n",
      "0.040676435856\n",
      "\n",
      "[ Train epoch: 5 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7916666666666666\n",
      "Current benign train loss: 0.5498684644699097\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.44018813967704773\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.40381917357444763\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8645833333333334\n",
      "Current benign train loss: 0.43561097979545593\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8229166666666666\n",
      "Current benign train loss: 0.5269250273704529\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7395833333333334\n",
      "Current benign train loss: 0.6535466909408569\n",
      "\n",
      "Total benign train accuarcy: 82.97\n",
      "Total benign train loss: 255.98681542277336\n",
      "\n",
      "[ Test epoch: 5 ]\n",
      "\n",
      "Test accuarcy: 82.31\n",
      "Test average loss: 0.005412012687325478\n",
      "Model Saved!\n",
      "0.039862907138879994\n",
      "\n",
      "[ Train epoch: 6 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.42697930335998535\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8229166666666666\n",
      "Current benign train loss: 0.536541759967804\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5071220397949219\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8645833333333334\n",
      "Current benign train loss: 0.4936743676662445\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.3323805034160614\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.4565356969833374\n",
      "\n",
      "Total benign train accuarcy: 84.088\n",
      "Total benign train loss: 237.786254003644\n",
      "\n",
      "[ Test epoch: 6 ]\n",
      "\n",
      "Test accuarcy: 83.92\n",
      "Test average loss: 0.00499352619946003\n",
      "Model Saved!\n",
      "0.039065648996102396\n",
      "\n",
      "[ Train epoch: 7 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8645833333333334\n",
      "Current benign train loss: 0.38807162642478943\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.5247123837471008\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8020833333333334\n",
      "Current benign train loss: 0.49861523509025574\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.3634084463119507\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8229166666666666\n",
      "Current benign train loss: 0.5100651383399963\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3493076264858246\n",
      "\n",
      "Total benign train accuarcy: 85.25\n",
      "Total benign train loss: 223.2612667530775\n",
      "\n",
      "[ Test epoch: 7 ]\n",
      "\n",
      "Test accuarcy: 83.83\n",
      "Test average loss: 0.0051057017356157305\n",
      "Model Saved!\n",
      "0.03828433601618035\n",
      "\n",
      "[ Train epoch: 8 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.24423696100711823\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8020833333333334\n",
      "Current benign train loss: 0.47348037362098694\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.2932272255420685\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.2997577488422394\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.4100715219974518\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.4549414813518524\n",
      "\n",
      "Total benign train accuarcy: 86.242\n",
      "Total benign train loss: 207.490209415555\n",
      "\n",
      "[ Test epoch: 8 ]\n",
      "\n",
      "Test accuarcy: 84.7\n",
      "Test average loss: 0.0048712597653269765\n",
      "Model Saved!\n",
      "0.03751864929585674\n",
      "\n",
      "[ Train epoch: 9 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.23929215967655182\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.3930806815624237\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.33891355991363525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8229166666666666\n",
      "Current benign train loss: 0.5676093697547913\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2480641007423401\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.43760648369789124\n",
      "\n",
      "Total benign train accuarcy: 86.922\n",
      "Total benign train loss: 195.49374368786812\n",
      "\n",
      "[ Test epoch: 9 ]\n",
      "\n",
      "Test accuarcy: 84.9\n",
      "Test average loss: 0.004738012245297432\n",
      "Model Saved!\n",
      "0.036768276309939604\n",
      "\n",
      "[ Train epoch: 10 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.3481258153915405\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7916666666666666\n",
      "Current benign train loss: 0.5216249227523804\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4352787435054779\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4067021906375885\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.34171274304389954\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.35690951347351074\n",
      "\n",
      "Total benign train accuarcy: 87.594\n",
      "Total benign train loss: 185.2467858493328\n",
      "\n",
      "[ Test epoch: 10 ]\n",
      "\n",
      "Test accuarcy: 85.38\n",
      "Test average loss: 0.004539039935171604\n",
      "Model Saved!\n",
      "0.03603291078374081\n",
      "\n",
      "[ Train epoch: 11 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.30732250213623047\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.22982442378997803\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.3179995119571686\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.31340688467025757\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.25314536690711975\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.29276207089424133\n",
      "\n",
      "Total benign train accuarcy: 88.184\n",
      "Total benign train loss: 177.92500561475754\n",
      "\n",
      "[ Test epoch: 11 ]\n",
      "\n",
      "Test accuarcy: 86.61\n",
      "Test average loss: 0.004221888917684555\n",
      "Model Saved!\n",
      "0.03531225256806599\n",
      "\n",
      "[ Train epoch: 12 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.2986138164997101\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.29267826676368713\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.2267470806837082\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.4199870526790619\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.23405976593494415\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.32726985216140747\n",
      "\n",
      "Total benign train accuarcy: 88.774\n",
      "Total benign train loss: 167.51255555450916\n",
      "\n",
      "[ Test epoch: 12 ]\n",
      "\n",
      "Test accuarcy: 86.46\n",
      "Test average loss: 0.004235712227225304\n",
      "Model Saved!\n",
      "0.03460600751670467\n",
      "\n",
      "[ Train epoch: 13 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.19150328636169434\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.20715178549289703\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.24266213178634644\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20097969472408295\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.29127374291419983\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.3096790611743927\n",
      "\n",
      "Total benign train accuarcy: 89.344\n",
      "Total benign train loss: 159.4288132339716\n",
      "\n",
      "[ Test epoch: 13 ]\n",
      "\n",
      "Test accuarcy: 87.16\n",
      "Test average loss: 0.003975455433130264\n",
      "Model Saved!\n",
      "0.033913887366370576\n",
      "\n",
      "[ Train epoch: 14 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.19681189954280853\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3616880178451538\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.33599987626075745\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.32633087038993835\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.2551189064979553\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.16935496032238007\n",
      "\n",
      "Total benign train accuarcy: 89.922\n",
      "Total benign train loss: 149.5226138755679\n",
      "\n",
      "[ Test epoch: 14 ]\n",
      "\n",
      "Test accuarcy: 87.47\n",
      "Test average loss: 0.003980495858192444\n",
      "Model Saved!\n",
      "0.03323560961904316\n",
      "\n",
      "[ Train epoch: 15 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.3688831329345703\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.32594093680381775\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.15492400527000427\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.2832970917224884\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.3364062011241913\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3579498529434204\n",
      "\n",
      "Total benign train accuarcy: 90.278\n",
      "Total benign train loss: 145.15068275481462\n",
      "\n",
      "[ Test epoch: 15 ]\n",
      "\n",
      "Test accuarcy: 87.52\n",
      "Test average loss: 0.003991297160089016\n",
      "Model Saved!\n",
      "0.0325708974266623\n",
      "\n",
      "[ Train epoch: 16 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20583198964595795\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.34128034114837646\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20375294983386993\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2792629599571228\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.2834884226322174\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.223735973238945\n",
      "\n",
      "Total benign train accuarcy: 90.604\n",
      "Total benign train loss: 140.018460303545\n",
      "\n",
      "[ Test epoch: 16 ]\n",
      "\n",
      "Test accuarcy: 87.63\n",
      "Test average loss: 0.003973192410171032\n",
      "Model Saved!\n",
      "0.03191947947812905\n",
      "\n",
      "[ Train epoch: 17 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.20021264255046844\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1976962834596634\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.25008058547973633\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.19452397525310516\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.2957979440689087\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.21763360500335693\n",
      "\n",
      "Total benign train accuarcy: 91.136\n",
      "Total benign train loss: 132.66254131495953\n",
      "\n",
      "[ Test epoch: 17 ]\n",
      "\n",
      "Test accuarcy: 87.96\n",
      "Test average loss: 0.0040183503940701484\n",
      "Model Saved!\n",
      "0.03128108988856647\n",
      "\n",
      "[ Train epoch: 18 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.2339954972267151\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.26409581303596497\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.2660985589027405\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.16781477630138397\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.23370422422885895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8645833333333334\n",
      "Current benign train loss: 0.3282844126224518\n",
      "\n",
      "Total benign train accuarcy: 91.628\n",
      "Total benign train loss: 124.64764079451561\n",
      "\n",
      "[ Test epoch: 18 ]\n",
      "\n",
      "Test accuarcy: 88.55\n",
      "Test average loss: 0.003763842262327671\n",
      "Model Saved!\n",
      "0.030655468090795137\n",
      "\n",
      "[ Train epoch: 19 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09497183561325073\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2124350219964981\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.25135093927383423\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.2824408710002899\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.2927292585372925\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.28549495339393616\n",
      "\n",
      "Total benign train accuarcy: 91.782\n",
      "Total benign train loss: 122.76336595416069\n",
      "\n",
      "[ Test epoch: 19 ]\n",
      "\n",
      "Test accuarcy: 88.49\n",
      "Test average loss: 0.0037694961577653886\n",
      "Model Saved!\n",
      "0.030042358728979233\n",
      "\n",
      "[ Train epoch: 20 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.28553566336631775\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.20881767570972443\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.22019170224666595\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8645833333333334\n",
      "Current benign train loss: 0.3455974757671356\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.19157128036022186\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1359817236661911\n",
      "\n",
      "Total benign train accuarcy: 92.13\n",
      "Total benign train loss: 115.70907057449222\n",
      "\n",
      "[ Test epoch: 20 ]\n",
      "\n",
      "Test accuarcy: 88.62\n",
      "Test average loss: 0.003664294372498989\n",
      "Model Saved!\n",
      "0.029441511554399648\n",
      "\n",
      "[ Train epoch: 21 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.23204296827316284\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.24510037899017334\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2986944019794464\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.21064381301403046\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.18047745525836945\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.17985600233078003\n",
      "\n",
      "Total benign train accuarcy: 92.406\n",
      "Total benign train loss: 112.23115283995867\n",
      "\n",
      "[ Test epoch: 21 ]\n",
      "\n",
      "Test accuarcy: 88.06\n",
      "Test average loss: 0.00398473092764616\n",
      "Model Saved!\n",
      "0.028852681323311653\n",
      "\n",
      "[ Train epoch: 22 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.16449235379695892\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.21016377210617065\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10092870146036148\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.18827897310256958\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.07857365906238556\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.15144680440425873\n",
      "\n",
      "Total benign train accuarcy: 92.912\n",
      "Total benign train loss: 104.28614298254251\n",
      "\n",
      "[ Test epoch: 22 ]\n",
      "\n",
      "Test accuarcy: 88.67\n",
      "Test average loss: 0.0036633346386253833\n",
      "Model Saved!\n",
      "0.02827562769684542\n",
      "\n",
      "[ Train epoch: 23 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.15610714256763458\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.13466475903987885\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.24280089139938354\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.23630094528198242\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08309774845838547\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.19836457073688507\n",
      "\n",
      "Total benign train accuarcy: 92.954\n",
      "Total benign train loss: 101.94666673988104\n",
      "\n",
      "[ Test epoch: 23 ]\n",
      "\n",
      "Test accuarcy: 89.48\n",
      "Test average loss: 0.003491042672097683\n",
      "Model Saved!\n",
      "0.027710115142908512\n",
      "\n",
      "[ Train epoch: 24 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1099264994263649\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.22025616466999054\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.13817957043647766\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.21110832691192627\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.20587493479251862\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19350923597812653\n",
      "\n",
      "Total benign train accuarcy: 93.168\n",
      "Total benign train loss: 101.06161306425929\n",
      "\n",
      "[ Test epoch: 24 ]\n",
      "\n",
      "Test accuarcy: 88.82\n",
      "Test average loss: 0.0037627629466354846\n",
      "Model Saved!\n",
      "0.027155912840050343\n",
      "\n",
      "[ Train epoch: 25 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2767704427242279\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09838655591011047\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1943683624267578\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.11880893260240555\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.10523858666419983\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17649228870868683\n",
      "\n",
      "Total benign train accuarcy: 93.612\n",
      "Total benign train loss: 93.64991104230285\n",
      "\n",
      "[ Test epoch: 25 ]\n",
      "\n",
      "Test accuarcy: 88.73\n",
      "Test average loss: 0.003942285303771496\n",
      "Model Saved!\n",
      "0.026612794583249336\n",
      "\n",
      "[ Train epoch: 26 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.21101273596286774\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.28162142634391785\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13363488018512726\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.21762116253376007\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20065604150295258\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.12715502083301544\n",
      "\n",
      "Total benign train accuarcy: 93.608\n",
      "Total benign train loss: 93.83709862083197\n",
      "\n",
      "[ Test epoch: 26 ]\n",
      "\n",
      "Test accuarcy: 89.01\n",
      "Test average loss: 0.0037866165935993195\n",
      "Model Saved!\n",
      "0.02608053869158435\n",
      "\n",
      "[ Train epoch: 27 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.15756142139434814\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10570824891328812\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.14684315025806427\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.14334942400455475\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.18389087915420532\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.18127566576004028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign train accuarcy: 94.04\n",
      "Total benign train loss: 87.14666257053614\n",
      "\n",
      "[ Test epoch: 27 ]\n",
      "\n",
      "Test accuarcy: 89.79\n",
      "Test average loss: 0.0035993452958762648\n",
      "Model Saved!\n",
      "0.02555892791775266\n",
      "\n",
      "[ Train epoch: 28 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.21355986595153809\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.19247053563594818\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1556994765996933\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18744783103466034\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06682109087705612\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.20440177619457245\n",
      "\n",
      "Total benign train accuarcy: 94.214\n",
      "Total benign train loss: 84.55268259719014\n",
      "\n",
      "[ Test epoch: 28 ]\n",
      "\n",
      "Test accuarcy: 89.71\n",
      "Test average loss: 0.003648322407156229\n",
      "Model Saved!\n",
      "0.025047749359397607\n",
      "\n",
      "[ Train epoch: 29 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1543831080198288\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.11712156981229782\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12026036530733109\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1246739849448204\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.17169220745563507\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1686580330133438\n",
      "\n",
      "Total benign train accuarcy: 94.524\n",
      "Total benign train loss: 81.74623838067055\n",
      "\n",
      "[ Test epoch: 29 ]\n",
      "\n",
      "Test accuarcy: 90.29\n",
      "Test average loss: 0.003551889093965292\n",
      "Model Saved!\n",
      "0.024546794372209652\n",
      "\n",
      "[ Train epoch: 30 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.06728097051382065\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10580558329820633\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16462190449237823\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1843741089105606\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10166024416685104\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1655806452035904\n",
      "\n",
      "Total benign train accuarcy: 94.718\n",
      "Total benign train loss: 77.37112982943654\n",
      "\n",
      "[ Test epoch: 30 ]\n",
      "\n",
      "Test accuarcy: 89.62\n",
      "Test average loss: 0.0036363105319440364\n",
      "Model Saved!\n",
      "0.02405585848476546\n",
      "\n",
      "[ Train epoch: 31 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.058133333921432495\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16571709513664246\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.11379826068878174\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0987820252776146\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10053437203168869\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.15488870441913605\n",
      "\n",
      "Total benign train accuarcy: 94.742\n",
      "Total benign train loss: 76.99798019230366\n",
      "\n",
      "[ Test epoch: 31 ]\n",
      "\n",
      "Test accuarcy: 89.74\n",
      "Test average loss: 0.0035469135858118535\n",
      "Model Saved!\n",
      "0.02357474131507015\n",
      "\n",
      "[ Train epoch: 32 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1823986917734146\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10493525862693787\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10100653767585754\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11845812201499939\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.22089125216007233\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.21117162704467773\n",
      "\n",
      "Total benign train accuarcy: 95.15\n",
      "Total benign train loss: 70.97140529938042\n",
      "\n",
      "[ Test epoch: 32 ]\n",
      "\n",
      "Test accuarcy: 90.13\n",
      "Test average loss: 0.0035961620569229125\n",
      "Model Saved!\n",
      "0.023103246488768745\n",
      "\n",
      "[ Train epoch: 33 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.12661848962306976\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.23848290741443634\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09631949663162231\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1632392853498459\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.13582198321819305\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.2733008563518524\n",
      "\n",
      "Total benign train accuarcy: 95.214\n",
      "Total benign train loss: 68.7437539305538\n",
      "\n",
      "[ Test epoch: 33 ]\n",
      "\n",
      "Test accuarcy: 89.74\n",
      "Test average loss: 0.0038623491473495962\n",
      "Model Saved!\n",
      "0.02264118155899337\n",
      "\n",
      "[ Train epoch: 34 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15668578445911407\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.13631783425807953\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06602715700864792\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.11829181760549545\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2123371958732605\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07822471112012863\n",
      "\n",
      "Total benign train accuarcy: 95.394\n",
      "Total benign train loss: 67.12276263721287\n",
      "\n",
      "[ Test epoch: 34 ]\n",
      "\n",
      "Test accuarcy: 90.15\n",
      "Test average loss: 0.0035436484321951867\n",
      "Model Saved!\n",
      "0.022188357927813502\n",
      "\n",
      "[ Train epoch: 35 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0604756735265255\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1153038963675499\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08707977086305618\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.135914146900177\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.18821506202220917\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.2272288203239441\n",
      "\n",
      "Total benign train accuarcy: 95.516\n",
      "Total benign train loss: 64.63360168598592\n",
      "\n",
      "[ Test epoch: 35 ]\n",
      "\n",
      "Test accuarcy: 89.6\n",
      "Test average loss: 0.003691765232384205\n",
      "Model Saved!\n",
      "0.021744590769257232\n",
      "\n",
      "[ Train epoch: 36 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07265201956033707\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.11096072942018509\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09769580513238907\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.35975512862205505\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09557055681943893\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04780508950352669\n",
      "\n",
      "Total benign train accuarcy: 95.726\n",
      "Total benign train loss: 61.79526096023619\n",
      "\n",
      "[ Test epoch: 36 ]\n",
      "\n",
      "Test accuarcy: 89.52\n",
      "Test average loss: 0.003964721052348613\n",
      "Model Saved!\n",
      "0.021309698953872087\n",
      "\n",
      "[ Train epoch: 37 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.023538559675216675\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10241109132766724\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05998862907290459\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.14259259402751923\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1315733790397644\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1073390543460846\n",
      "\n",
      "Total benign train accuarcy: 96.002\n",
      "Total benign train loss: 57.975896993651986\n",
      "\n",
      "[ Test epoch: 37 ]\n",
      "\n",
      "Test accuarcy: 90.19\n",
      "Test average loss: 0.0037788264788687228\n",
      "Model Saved!\n",
      "0.020883504974794645\n",
      "\n",
      "[ Train epoch: 38 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03912303224205971\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07479628920555115\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09007895737886429\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05184264853596687\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.11709782481193542\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08961793780326843\n",
      "\n",
      "Total benign train accuarcy: 95.952\n",
      "Total benign train loss: 57.75057997740805\n",
      "\n",
      "[ Test epoch: 38 ]\n",
      "\n",
      "Test accuarcy: 89.81\n",
      "Test average loss: 0.0039925968497991566\n",
      "Model Saved!\n",
      "0.020465834875298752\n",
      "\n",
      "[ Train epoch: 39 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.13168902695178986\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05362555384635925\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.11842221766710281\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10829722881317139\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.16721753776073456\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.12336215376853943\n",
      "\n",
      "Total benign train accuarcy: 96.304\n",
      "Total benign train loss: 53.92587327212095\n",
      "\n",
      "[ Test epoch: 39 ]\n",
      "\n",
      "Test accuarcy: 90.84\n",
      "Test average loss: 0.003511295945197344\n",
      "Model Saved!\n",
      "0.020056518177792776\n",
      "\n",
      "[ Train epoch: 40 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.10111690312623978\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04182916507124901\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08133096247911453\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06346295028924942\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07270797342061996\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05638357996940613\n",
      "\n",
      "Total benign train accuarcy: 96.42\n",
      "Total benign train loss: 51.83659958280623\n",
      "\n",
      "[ Test epoch: 40 ]\n",
      "\n",
      "Test accuarcy: 90.54\n",
      "Test average loss: 0.0037522772919386625\n",
      "Model Saved!\n",
      "0.01965538781423692\n",
      "\n",
      "[ Train epoch: 41 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.042595162987709045\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.19685381650924683\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.14846396446228027\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.17269589006900787\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.057209908962249756\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05654541775584221\n",
      "\n",
      "Total benign train accuarcy: 96.524\n",
      "Total benign train loss: 50.49288507550955\n",
      "\n",
      "[ Test epoch: 41 ]\n",
      "\n",
      "Test accuarcy: 90.22\n",
      "Test average loss: 0.00408099449723959\n",
      "Model Saved!\n",
      "0.01926228005795218\n",
      "\n",
      "[ Train epoch: 42 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07270565629005432\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.13290226459503174\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03199795261025429\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.04651936888694763\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18629956245422363\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.09656382352113724\n",
      "\n",
      "Total benign train accuarcy: 96.618\n",
      "Total benign train loss: 49.77257805224508\n",
      "\n",
      "[ Test epoch: 42 ]\n",
      "\n",
      "Test accuarcy: 90.44\n",
      "Test average loss: 0.003911965385079384\n",
      "Model Saved!\n",
      "0.018877034456793135\n",
      "\n",
      "[ Train epoch: 43 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10291304439306259\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11585992574691772\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06218923255801201\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.040274638682603836\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05367038771510124\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07022002339363098\n",
      "\n",
      "Total benign train accuarcy: 96.668\n",
      "Total benign train loss: 48.507558348588645\n",
      "\n",
      "[ Test epoch: 43 ]\n",
      "\n",
      "Test accuarcy: 89.78\n",
      "Test average loss: 0.004159835763275623\n",
      "Model Saved!\n",
      "0.018499493767657273\n",
      "\n",
      "[ Train epoch: 44 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.11933460086584091\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.12996375560760498\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08677753806114197\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07572349160909653\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07913056761026382\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12902922928333282\n",
      "\n",
      "Total benign train accuarcy: 96.972\n",
      "Total benign train loss: 43.87056565005332\n",
      "\n",
      "[ Test epoch: 44 ]\n",
      "\n",
      "Test accuarcy: 90.47\n",
      "Test average loss: 0.0038554687321186065\n",
      "Model Saved!\n",
      "0.018129503892304128\n",
      "\n",
      "[ Train epoch: 45 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06913470476865768\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.147531196475029\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0599953718483448\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.030414128676056862\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.09130322933197021\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07407499104738235\n",
      "\n",
      "Total benign train accuarcy: 96.99\n",
      "Total benign train loss: 44.08049175981432\n",
      "\n",
      "[ Test epoch: 45 ]\n",
      "\n",
      "Test accuarcy: 90.65\n",
      "Test average loss: 0.0038724035024642945\n",
      "Model Saved!\n",
      "0.017766913814458045\n",
      "\n",
      "[ Train epoch: 46 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.08499161154031754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.028823859989643097\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.06733528524637222\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.058777082711458206\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09122852236032486\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.124196857213974\n",
      "\n",
      "Total benign train accuarcy: 97.09\n",
      "Total benign train loss: 42.85078625846654\n",
      "\n",
      "[ Test epoch: 46 ]\n",
      "\n",
      "Test accuarcy: 90.84\n",
      "Test average loss: 0.003765044614672661\n",
      "Model Saved!\n",
      "0.017411575538168883\n",
      "\n",
      "[ Train epoch: 47 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04821548983454704\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.08559566736221313\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.12005751579999924\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.053007762879133224\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1794327348470688\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07454707473516464\n",
      "\n",
      "Total benign train accuarcy: 97.202\n",
      "Total benign train loss: 40.58377852384001\n",
      "\n",
      "[ Test epoch: 47 ]\n",
      "\n",
      "Test accuarcy: 90.53\n",
      "Test average loss: 0.0038391689352691174\n",
      "Model Saved!\n",
      "0.017063344027405506\n",
      "\n",
      "[ Train epoch: 48 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06997846812009811\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04929262772202492\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.11767589300870895\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.08185376971960068\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.059225793927907944\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09507027268409729\n",
      "\n",
      "Total benign train accuarcy: 97.394\n",
      "Total benign train loss: 38.275700891856104\n",
      "\n",
      "[ Test epoch: 48 ]\n",
      "\n",
      "Test accuarcy: 91.12\n",
      "Test average loss: 0.003811836688965559\n",
      "Model Saved!\n",
      "0.016722077146857396\n",
      "\n",
      "[ Train epoch: 49 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03815680369734764\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016675615683197975\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.019798848778009415\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07015649974346161\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.08131663501262665\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04281752184033394\n",
      "\n",
      "Total benign train accuarcy: 97.486\n",
      "Total benign train loss: 36.268160928506404\n",
      "\n",
      "[ Test epoch: 49 ]\n",
      "\n",
      "Test accuarcy: 90.63\n",
      "Test average loss: 0.003996389872580767\n",
      "Model Saved!\n",
      "0.016387635603920248\n",
      "\n",
      "[ Train epoch: 50 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04428898170590401\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0378732830286026\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1732427477836609\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08375677466392517\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07290040701627731\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13410718739032745\n",
      "\n",
      "Total benign train accuarcy: 97.51\n",
      "Total benign train loss: 35.652348157949746\n",
      "\n",
      "[ Test epoch: 50 ]\n",
      "\n",
      "Test accuarcy: 90.61\n",
      "Test average loss: 0.004079884271323681\n",
      "Model Saved!\n",
      "0.016059882891841844\n",
      "\n",
      "[ Train epoch: 51 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.14224377274513245\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.04959264397621155\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05316847190260887\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.13209082186222076\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.021239718422293663\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.07690861076116562\n",
      "\n",
      "Total benign train accuarcy: 97.644\n",
      "Total benign train loss: 34.835147441364825\n",
      "\n",
      "[ Test epoch: 51 ]\n",
      "\n",
      "Test accuarcy: 90.97\n",
      "Test average loss: 0.00392966822385788\n",
      "Model Saved!\n",
      "0.01573868523400501\n",
      "\n",
      "[ Train epoch: 52 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11226842552423477\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03916524350643158\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05082480236887932\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09378206729888916\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07757654041051865\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.028442835435271263\n",
      "\n",
      "Total benign train accuarcy: 97.828\n",
      "Total benign train loss: 32.00771905714646\n",
      "\n",
      "[ Test epoch: 52 ]\n",
      "\n",
      "Test accuarcy: 90.62\n",
      "Test average loss: 0.004080322989821434\n",
      "Model Saved!\n",
      "0.015423911529324909\n",
      "\n",
      "[ Train epoch: 53 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04696974530816078\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08611229807138443\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.054961103945970535\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05487578734755516\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.051726844161748886\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04876364395022392\n",
      "\n",
      "Total benign train accuarcy: 97.836\n",
      "Total benign train loss: 31.330298592336476\n",
      "\n",
      "[ Test epoch: 53 ]\n",
      "\n",
      "Test accuarcy: 91.06\n",
      "Test average loss: 0.003920064356178045\n",
      "Model Saved!\n",
      "0.01511543329873841\n",
      "\n",
      "[ Train epoch: 54 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.03948355093598366\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09122266620397568\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05051521584391594\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02669038437306881\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.05885378643870354\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10479318350553513\n",
      "\n",
      "Total benign train accuarcy: 98.052\n",
      "Total benign train loss: 28.92392658535391\n",
      "\n",
      "[ Test epoch: 54 ]\n",
      "\n",
      "Test accuarcy: 90.96\n",
      "Test average loss: 0.00408091402053833\n",
      "Model Saved!\n",
      "0.014813124632763642\n",
      "\n",
      "[ Train epoch: 55 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020356081426143646\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05415801331400871\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03258085995912552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.11388357728719711\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.044970203191041946\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09109821915626526\n",
      "\n",
      "Total benign train accuarcy: 98.076\n",
      "Total benign train loss: 28.911976650357246\n",
      "\n",
      "[ Test epoch: 55 ]\n",
      "\n",
      "Test accuarcy: 91.33\n",
      "Test average loss: 0.003939397075772286\n",
      "Model Saved!\n",
      "0.01451686214010837\n",
      "\n",
      "[ Train epoch: 56 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0076452940702438354\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.039424918591976166\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.1413918137550354\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10369063168764114\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04431604966521263\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.039971526712179184\n",
      "\n",
      "Total benign train accuarcy: 98.084\n",
      "Total benign train loss: 27.772648133337498\n",
      "\n",
      "[ Test epoch: 56 ]\n",
      "\n",
      "Test accuarcy: 90.99\n",
      "Test average loss: 0.004160067418962717\n",
      "Model Saved!\n",
      "0.014226524897306202\n",
      "\n",
      "[ Train epoch: 57 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020635467022657394\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09728199988603592\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.016968972980976105\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07587196677923203\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07242657989263535\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06369470804929733\n",
      "\n",
      "Total benign train accuarcy: 98.25\n",
      "Total benign train loss: 25.555503205396235\n",
      "\n",
      "[ Test epoch: 57 ]\n",
      "\n",
      "Test accuarcy: 91.28\n",
      "Test average loss: 0.003991382285952568\n",
      "Model Saved!\n",
      "0.013941994399360077\n",
      "\n",
      "[ Train epoch: 58 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02812962792813778\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.042583879083395004\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018125537782907486\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0351090170443058\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06060216948390007\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07070519775152206\n",
      "\n",
      "Total benign train accuarcy: 98.186\n",
      "Total benign train loss: 26.23307146737352\n",
      "\n",
      "[ Test epoch: 58 ]\n",
      "\n",
      "Test accuarcy: 91.06\n",
      "Test average loss: 0.004113779775053263\n",
      "Model Saved!\n",
      "0.013663154511372875\n",
      "\n",
      "[ Train epoch: 59 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0663839802145958\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04393121972680092\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07156572490930557\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.06618926674127579\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09978779405355453\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018201807513833046\n",
      "\n",
      "Total benign train accuarcy: 98.426\n",
      "Total benign train loss: 23.638064806116745\n",
      "\n",
      "[ Test epoch: 59 ]\n",
      "\n",
      "Test accuarcy: 91.13\n",
      "Test average loss: 0.004028193354606628\n",
      "Model Saved!\n",
      "0.013389891421145416\n",
      "\n",
      "[ Train epoch: 60 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.025812240317463875\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.033233530819416046\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02837562747299671\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.051456306129693985\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04117550700902939\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04295037314295769\n",
      "\n",
      "Total benign train accuarcy: 98.486\n",
      "Total benign train loss: 22.465631869854406\n",
      "\n",
      "[ Test epoch: 60 ]\n",
      "\n",
      "Test accuarcy: 91.08\n",
      "Test average loss: 0.004034304739395157\n",
      "Model Saved!\n",
      "0.013122093592722508\n",
      "\n",
      "[ Train epoch: 61 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.046970468014478683\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03378090262413025\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06020703911781311\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10721439123153687\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01821132004261017\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.034827347844839096\n",
      "\n",
      "Total benign train accuarcy: 98.56\n",
      "Total benign train loss: 21.950584531296045\n",
      "\n",
      "[ Test epoch: 61 ]\n",
      "\n",
      "Test accuarcy: 91.31\n",
      "Test average loss: 0.00391882793456316\n",
      "Model Saved!\n",
      "0.012859651720868058\n",
      "\n",
      "[ Train epoch: 62 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03946094587445259\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.026002882048487663\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01864870823919773\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.019605984911322594\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1342363804578781\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09009542316198349\n",
      "\n",
      "Total benign train accuarcy: 98.644\n",
      "Total benign train loss: 20.220458107767627\n",
      "\n",
      "[ Test epoch: 62 ]\n",
      "\n",
      "Test accuarcy: 91.58\n",
      "Test average loss: 0.004001388046145439\n",
      "Model Saved!\n",
      "0.012602458686450697\n",
      "\n",
      "[ Train epoch: 63 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06357944756746292\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06264343857765198\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.015758337453007698\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.09967458993196487\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.08825627714395523\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.046713050454854965\n",
      "\n",
      "Total benign train accuarcy: 98.678\n",
      "Total benign train loss: 20.07109703461174\n",
      "\n",
      "[ Test epoch: 63 ]\n",
      "\n",
      "Test accuarcy: 91.35\n",
      "Test average loss: 0.004161182594031561\n",
      "Model Saved!\n",
      "0.012350409512721683\n",
      "\n",
      "[ Train epoch: 64 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.040921155363321304\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04729500412940979\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08171866089105606\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.019271649420261383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008395032025873661\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03687495365738869\n",
      "\n",
      "Total benign train accuarcy: 98.642\n",
      "Total benign train loss: 19.837728417711332\n",
      "\n",
      "[ Test epoch: 64 ]\n",
      "\n",
      "Test accuarcy: 91.05\n",
      "Test average loss: 0.004081977932155132\n",
      "Model Saved!\n",
      "0.012103401322467249\n",
      "\n",
      "[ Train epoch: 65 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06662490963935852\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.042090948671102524\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010778497904539108\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.015065975487232208\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07254648208618164\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.053870830684900284\n",
      "\n",
      "Total benign train accuarcy: 98.766\n",
      "Total benign train loss: 18.277219189330935\n",
      "\n",
      "[ Test epoch: 65 ]\n",
      "\n",
      "Test accuarcy: 91.59\n",
      "Test average loss: 0.003973180650174618\n",
      "Model Saved!\n",
      "0.011861333296017903\n",
      "\n",
      "[ Train epoch: 66 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.04066937789320946\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006199894938617945\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05070952698588371\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.013580255210399628\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.0804726704955101\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05929145589470863\n",
      "\n",
      "Total benign train accuarcy: 98.89\n",
      "Total benign train loss: 16.62411621073261\n",
      "\n",
      "[ Test epoch: 66 ]\n",
      "\n",
      "Test accuarcy: 91.72\n",
      "Test average loss: 0.0040706156603991985\n",
      "Model Saved!\n",
      "0.011624106630097544\n",
      "\n",
      "[ Train epoch: 67 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.051000576466321945\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05158121883869171\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012957590632140636\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04190756380558014\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01689331792294979\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08546728640794754\n",
      "\n",
      "Total benign train accuarcy: 98.902\n",
      "Total benign train loss: 16.270713885314763\n",
      "\n",
      "[ Test epoch: 67 ]\n",
      "\n",
      "Test accuarcy: 91.2\n",
      "Test average loss: 0.004291206673160196\n",
      "Model Saved!\n",
      "0.011391624497495593\n",
      "\n",
      "[ Train epoch: 68 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03613248094916344\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03841858729720116\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024508158676326275\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016350507736206055\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.029814371839165688\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022063469514250755\n",
      "\n",
      "Total benign train accuarcy: 98.838\n",
      "Total benign train loss: 17.66162203263957\n",
      "\n",
      "[ Test epoch: 68 ]\n",
      "\n",
      "Test accuarcy: 91.35\n",
      "Test average loss: 0.004200980585068464\n",
      "Model Saved!\n",
      "0.011163792007545682\n",
      "\n",
      "[ Train epoch: 69 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.10507854074239731\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03859490901231766\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01286389585584402\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011602071113884449\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024856803938746452\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.020645974203944206\n",
      "\n",
      "Total benign train accuarcy: 98.98\n",
      "Total benign train loss: 15.37252982793143\n",
      "\n",
      "[ Test epoch: 69 ]\n",
      "\n",
      "Test accuarcy: 91.48\n",
      "Test average loss: 0.004163753142207861\n",
      "Model Saved!\n",
      "0.010940516167394767\n",
      "\n",
      "[ Train epoch: 70 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0032336993608623743\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.030841900035738945\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010624855756759644\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07635261863470078\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014050398953258991\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.035014208406209946\n",
      "\n",
      "Total benign train accuarcy: 99.066\n",
      "Total benign train loss: 14.006181645207107\n",
      "\n",
      "[ Test epoch: 70 ]\n",
      "\n",
      "Test accuarcy: 91.48\n",
      "Test average loss: 0.00425726769566536\n",
      "Model Saved!\n",
      "0.010721705844046872\n",
      "\n",
      "[ Train epoch: 71 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018832532688975334\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02920474298298359\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013398679904639721\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03778780624270439\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013833082281053066\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007554571609944105\n",
      "\n",
      "Total benign train accuarcy: 98.954\n",
      "Total benign train loss: 15.465912578976713\n",
      "\n",
      "[ Test epoch: 71 ]\n",
      "\n",
      "Test accuarcy: 91.51\n",
      "Test average loss: 0.004329597315192222\n",
      "Model Saved!\n",
      "0.010507271727165934\n",
      "\n",
      "[ Train epoch: 72 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.021467378363013268\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02925572544336319\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017872609198093414\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02182190679013729\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0454719178378582\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.038152456283569336\n",
      "\n",
      "Total benign train accuarcy: 99.026\n",
      "Total benign train loss: 14.346404218988027\n",
      "\n",
      "[ Test epoch: 72 ]\n",
      "\n",
      "Test accuarcy: 91.56\n",
      "Test average loss: 0.004186239728331566\n",
      "Model Saved!\n",
      "0.010297126292622616\n",
      "\n",
      "[ Train epoch: 73 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.021605735644698143\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03990538790822029\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02426408976316452\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005543635692447424\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05072825029492378\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0216104444116354\n",
      "\n",
      "Total benign train accuarcy: 99.21\n",
      "Total benign train loss: 12.03648730518762\n",
      "\n",
      "[ Test epoch: 73 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuarcy: 91.49\n",
      "Test average loss: 0.0041621376603841785\n",
      "Model Saved!\n",
      "0.010091183766770163\n",
      "\n",
      "[ Train epoch: 74 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010605682618916035\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.020423466339707375\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008586443960666656\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021319950465112925\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017973707290366292\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015348400920629501\n",
      "\n",
      "Total benign train accuarcy: 99.254\n",
      "Total benign train loss: 11.835653096903116\n",
      "\n",
      "[ Test epoch: 74 ]\n",
      "\n",
      "Test accuarcy: 91.63\n",
      "Test average loss: 0.0042736962389200925\n",
      "Model Saved!\n",
      "0.009889360091434759\n",
      "\n",
      "[ Train epoch: 75 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03254164010286331\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010589311830699444\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.016337672248482704\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.025834115222096443\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.037592630833387375\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01868821680545807\n",
      "\n",
      "Total benign train accuarcy: 99.238\n",
      "Total benign train loss: 11.690251345396973\n",
      "\n",
      "[ Test epoch: 75 ]\n",
      "\n",
      "Test accuarcy: 91.29\n",
      "Test average loss: 0.004463811630755663\n",
      "Model Saved!\n",
      "0.009691572889606063\n",
      "\n",
      "[ Train epoch: 76 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005687936674803495\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01929544471204281\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02743607573211193\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.011662442237138748\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006053528282791376\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010366289876401424\n",
      "\n",
      "Total benign train accuarcy: 99.364\n",
      "Total benign train loss: 10.20413507160265\n",
      "\n",
      "[ Test epoch: 76 ]\n",
      "\n",
      "Test accuarcy: 91.68\n",
      "Test average loss: 0.0043636063829064365\n",
      "Model Saved!\n",
      "0.009497741431813941\n",
      "\n",
      "[ Train epoch: 77 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01761559583246708\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03677046298980713\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005280461627990007\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03827538341283798\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002882329048588872\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02852913737297058\n",
      "\n",
      "Total benign train accuarcy: 99.29\n",
      "Total benign train loss: 10.673297094443114\n",
      "\n",
      "[ Test epoch: 77 ]\n",
      "\n",
      "Test accuarcy: 91.66\n",
      "Test average loss: 0.004324565788637847\n",
      "Model Saved!\n",
      "0.009307786603177663\n",
      "\n",
      "[ Train epoch: 78 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.031095564365386963\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.019517453387379646\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03333352878689766\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014749045483767986\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006973013281822205\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02011267840862274\n",
      "\n",
      "Total benign train accuarcy: 99.256\n",
      "Total benign train loss: 11.121177967521362\n",
      "\n",
      "[ Test epoch: 78 ]\n",
      "\n",
      "Test accuarcy: 91.42\n",
      "Test average loss: 0.004358432899042964\n",
      "Model Saved!\n",
      "0.009121630871114108\n",
      "\n",
      "[ Train epoch: 79 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001199002261273563\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01615341380238533\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03423527628183365\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024819672107696533\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.030484994873404503\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005785524845123291\n",
      "\n",
      "Total benign train accuarcy: 99.282\n",
      "Total benign train loss: 10.715950735961087\n",
      "\n",
      "[ Test epoch: 79 ]\n",
      "\n",
      "Test accuarcy: 91.56\n",
      "Test average loss: 0.00440412182956934\n",
      "Model Saved!\n",
      "0.008939198253691825\n",
      "\n",
      "[ Train epoch: 80 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01770341396331787\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.015615618787705898\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009930066764354706\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002277994528412819\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.028168758377432823\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007860465906560421\n",
      "\n",
      "Total benign train accuarcy: 99.382\n",
      "Total benign train loss: 9.346540845523123\n",
      "\n",
      "[ Test epoch: 80 ]\n",
      "\n",
      "Test accuarcy: 91.97\n",
      "Test average loss: 0.004343870295956731\n",
      "Model Saved!\n",
      "0.008760414288617988\n",
      "\n",
      "[ Train epoch: 81 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02884436957538128\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002659112447872758\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.0509842187166214\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.023419305682182312\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007180304732173681\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010944684036076069\n",
      "\n",
      "Total benign train accuarcy: 99.302\n",
      "Total benign train loss: 10.159154243970988\n",
      "\n",
      "[ Test epoch: 81 ]\n",
      "\n",
      "Test accuarcy: 91.51\n",
      "Test average loss: 0.004534571004286408\n",
      "Model Saved!\n",
      "0.008585206002845628\n",
      "\n",
      "[ Train epoch: 82 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01687469333410263\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020016172900795937\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017038365826010704\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011162581853568554\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02736610919237137\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0221345666795969\n",
      "\n",
      "Total benign train accuarcy: 99.398\n",
      "Total benign train loss: 9.089112039888278\n",
      "\n",
      "[ Test epoch: 82 ]\n",
      "\n",
      "Test accuarcy: 92.07\n",
      "Test average loss: 0.004161441476712935\n",
      "Model Saved!\n",
      "0.008413501882788716\n",
      "\n",
      "[ Train epoch: 83 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002223965944722295\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004729350563138723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.026571139693260193\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006530238781124353\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013807420618832111\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02012876234948635\n",
      "\n",
      "Total benign train accuarcy: 99.472\n",
      "Total benign train loss: 8.107478418474784\n",
      "\n",
      "[ Test epoch: 83 ]\n",
      "\n",
      "Test accuarcy: 91.78\n",
      "Test average loss: 0.004532506875693798\n",
      "Model Saved!\n",
      "0.008245231845132941\n",
      "\n",
      "[ Train epoch: 84 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03577309474349022\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020574767142534256\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031403573229908943\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020427359268069267\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014105595648288727\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00455801747739315\n",
      "\n",
      "Total benign train accuarcy: 99.514\n",
      "Total benign train loss: 7.563094652752625\n",
      "\n",
      "[ Test epoch: 84 ]\n",
      "\n",
      "Test accuarcy: 91.69\n",
      "Test average loss: 0.0045493197306990625\n",
      "Model Saved!\n",
      "0.008080327208230282\n",
      "\n",
      "[ Train epoch: 85 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021906616166234016\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0074739642441272736\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02560999244451523\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04592345282435417\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.009453666396439075\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005050545558333397\n",
      "\n",
      "Total benign train accuarcy: 99.492\n",
      "Total benign train loss: 7.802016051515238\n",
      "\n",
      "[ Test epoch: 85 ]\n",
      "\n",
      "Test accuarcy: 91.83\n",
      "Test average loss: 0.0044996648535132406\n",
      "Model Saved!\n",
      "0.007918720664065676\n",
      "\n",
      "[ Train epoch: 86 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012407618574798107\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003867947729304433\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00883545819669962\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007423095870763063\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004101864527910948\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0032462505623698235\n",
      "\n",
      "Total benign train accuarcy: 99.474\n",
      "Total benign train loss: 8.043334038637113\n",
      "\n",
      "[ Test epoch: 86 ]\n",
      "\n",
      "Test accuarcy: 91.6\n",
      "Test average loss: 0.00459403265863657\n",
      "Model Saved!\n",
      "0.0077603462507843625\n",
      "\n",
      "[ Train epoch: 87 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009228027425706387\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0062914579175412655\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011964960722252727\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018288685008883476\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01894368603825569\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.026539357379078865\n",
      "\n",
      "Total benign train accuarcy: 99.556\n",
      "Total benign train loss: 7.343224677722901\n",
      "\n",
      "[ Test epoch: 87 ]\n",
      "\n",
      "Test accuarcy: 91.91\n",
      "Test average loss: 0.004292458723345771\n",
      "Model Saved!\n",
      "0.007605139325768675\n",
      "\n",
      "[ Train epoch: 88 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006497781723737717\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0055153206922113895\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005907576065510511\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011227999348193407\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.027284249663352966\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014190238900482655\n",
      "\n",
      "Total benign train accuarcy: 99.55\n",
      "Total benign train loss: 6.880012675363105\n",
      "\n",
      "[ Test epoch: 88 ]\n",
      "\n",
      "Test accuarcy: 91.95\n",
      "Test average loss: 0.004517962209507823\n",
      "Model Saved!\n",
      "0.007453036539253301\n",
      "\n",
      "[ Train epoch: 89 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.010476079769432545\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004643012071028352\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02763734757900238\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031647474970668554\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009024053812026978\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.013658261857926846\n",
      "\n",
      "Total benign train accuarcy: 99.594\n",
      "Total benign train loss: 6.113920776944724\n",
      "\n",
      "[ Test epoch: 89 ]\n",
      "\n",
      "Test accuarcy: 91.8\n",
      "Test average loss: 0.00448419082313776\n",
      "Model Saved!\n",
      "0.007303975808468235\n",
      "\n",
      "[ Train epoch: 90 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02653711475431919\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02355439029633999\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010080994106829166\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003625946817919612\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013631337322294712\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.015680046752095222\n",
      "\n",
      "Total benign train accuarcy: 99.59\n",
      "Total benign train loss: 6.459441987826722\n",
      "\n",
      "[ Test epoch: 90 ]\n",
      "\n",
      "Test accuarcy: 91.87\n",
      "Test average loss: 0.004481769214197994\n",
      "Model Saved!\n",
      "0.00715789629229887\n",
      "\n",
      "[ Train epoch: 91 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014703698456287384\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018097950145602226\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.013544793240725994\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00045261261402629316\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.008636776357889175\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0067281159572303295\n",
      "\n",
      "Total benign train accuarcy: 99.602\n",
      "Total benign train loss: 6.31807722702797\n",
      "\n",
      "[ Test epoch: 91 ]\n",
      "\n",
      "Test accuarcy: 91.82\n",
      "Test average loss: 0.004433554836735129\n",
      "Model Saved!\n",
      "0.007014738366452893\n",
      "\n",
      "[ Train epoch: 92 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004577502608299255\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.028251998126506805\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0038546135183423758\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022741348948329687\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023739647585898638\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009189661941491067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign train accuarcy: 99.622\n",
      "Total benign train loss: 5.886361912838765\n",
      "\n",
      "[ Test epoch: 92 ]\n",
      "\n",
      "Test accuarcy: 91.99\n",
      "Test average loss: 0.004402651178953238\n",
      "Model Saved!\n",
      "0.006874443599123835\n",
      "\n",
      "[ Train epoch: 93 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020608436316251755\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00643227668479085\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004542241804301739\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005501250270754099\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003381019225344062\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0058264113031327724\n",
      "\n",
      "Total benign train accuarcy: 99.592\n",
      "Total benign train loss: 6.425844911747845\n",
      "\n",
      "[ Test epoch: 93 ]\n",
      "\n",
      "Test accuarcy: 92.01\n",
      "Test average loss: 0.004420208383351564\n",
      "Model Saved!\n",
      "0.006736954727141358\n",
      "\n",
      "[ Train epoch: 94 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020090045407414436\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0026121276896446943\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022968065459281206\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020194554701447487\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02648569457232952\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011514887446537614\n",
      "\n",
      "Total benign train accuarcy: 99.69\n",
      "Total benign train loss: 5.068311661030748\n",
      "\n",
      "[ Test epoch: 94 ]\n",
      "\n",
      "Test accuarcy: 92.15\n",
      "Test average loss: 0.004418962306901812\n",
      "Model Saved!\n",
      "0.006602215632598531\n",
      "\n",
      "[ Train epoch: 95 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027639714535325766\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007441773544996977\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01088251918554306\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003233527997508645\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.049467965960502625\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0035151876509189606\n",
      "\n",
      "Total benign train accuarcy: 99.696\n",
      "Total benign train loss: 4.936214669432957\n",
      "\n",
      "[ Test epoch: 95 ]\n",
      "\n",
      "Test accuarcy: 92.06\n",
      "Test average loss: 0.0044579450570046905\n",
      "Model Saved!\n",
      "0.00647017131994656\n",
      "\n",
      "[ Train epoch: 96 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.015431839041411877\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00822626706212759\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02185760624706745\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002564341528341174\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008484635036438704\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017106490209698677\n",
      "\n",
      "Total benign train accuarcy: 99.646\n",
      "Total benign train loss: 5.465878073693602\n",
      "\n",
      "[ Test epoch: 96 ]\n",
      "\n",
      "Test accuarcy: 92.0\n",
      "Test average loss: 0.004650997188687325\n",
      "Model Saved!\n",
      "0.006340767893547629\n",
      "\n",
      "[ Train epoch: 97 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021903198212385178\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002169522223994136\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010505167301744223\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00030022006831131876\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02642618678510189\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020436597988009453\n",
      "\n",
      "Total benign train accuarcy: 99.708\n",
      "Total benign train loss: 4.750041704333853\n",
      "\n",
      "[ Test epoch: 97 ]\n",
      "\n",
      "Test accuarcy: 92.02\n",
      "Test average loss: 0.004497075166553259\n",
      "Model Saved!\n",
      "0.006213952535676676\n",
      "\n",
      "[ Train epoch: 98 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0038177238311618567\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014119030674919486\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0068549481220543385\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0029866930563002825\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003397261956706643\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03223864361643791\n",
      "\n",
      "Total benign train accuarcy: 99.7\n",
      "Total benign train loss: 4.538963136874372\n",
      "\n",
      "[ Test epoch: 98 ]\n",
      "\n",
      "Test accuarcy: 91.86\n",
      "Test average loss: 0.00466742854937911\n",
      "Model Saved!\n",
      "0.006089673484963142\n",
      "\n",
      "[ Train epoch: 99 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01794252172112465\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007135388441383839\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004072823096066713\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0035880152136087418\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008394657634198666\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01526210829615593\n",
      "\n",
      "Total benign train accuarcy: 99.722\n",
      "Total benign train loss: 4.5407886176908505\n",
      "\n",
      "[ Test epoch: 99 ]\n",
      "\n",
      "Test accuarcy: 91.81\n",
      "Test average loss: 0.004587004747241735\n",
      "Model Saved!\n",
      "0.005967880015263879\n",
      "\n",
      "[ Train epoch: 100 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014328055083751678\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001156147918663919\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007608025800436735\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022114356979727745\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00771479494869709\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027643919456750154\n",
      "\n",
      "Total benign train accuarcy: 99.76\n",
      "Total benign train loss: 4.098097444904852\n",
      "\n",
      "[ Test epoch: 100 ]\n",
      "\n",
      "Test accuarcy: 91.96\n",
      "Test average loss: 0.004544634085893631\n",
      "Model Saved!\n",
      "0.005848522414958601\n",
      "\n",
      "[ Train epoch: 101 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017089759930968285\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011807874543592334\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012318748980760574\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013132184743881226\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014227117644622922\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018295288318768144\n",
      "\n",
      "Total benign train accuarcy: 99.778\n",
      "Total benign train loss: 3.898451483983081\n",
      "\n",
      "[ Test epoch: 101 ]\n",
      "\n",
      "Test accuarcy: 92.11\n",
      "Test average loss: 0.004578466892987489\n",
      "Model Saved!\n",
      "0.005731551966659429\n",
      "\n",
      "[ Train epoch: 102 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001506088417954743\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018561966717243195\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024050434585660696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017378874123096466\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004875844810158014\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03334839269518852\n",
      "\n",
      "Total benign train accuarcy: 99.79\n",
      "Total benign train loss: 3.6101011529099196\n",
      "\n",
      "[ Test epoch: 102 ]\n",
      "\n",
      "Test accuarcy: 92.06\n",
      "Test average loss: 0.004573398185521364\n",
      "Model Saved!\n",
      "0.00561692092732624\n",
      "\n",
      "[ Train epoch: 103 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004695332143455744\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023901958484202623\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009767379611730576\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002014378784224391\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007219234947115183\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.011589262634515762\n",
      "\n",
      "Total benign train accuarcy: 99.866\n",
      "Total benign train loss: 2.598996878688922\n",
      "\n",
      "[ Test epoch: 103 ]\n",
      "\n",
      "Test accuarcy: 92.16\n",
      "Test average loss: 0.004553849621117115\n",
      "Model Saved!\n",
      "0.0055045825087797155\n",
      "\n",
      "[ Train epoch: 104 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003940967842936516\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013213822385296226\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007798321545124054\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024466391187161207\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00023123262508306652\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.016062766313552856\n",
      "\n",
      "Total benign train accuarcy: 99.73\n",
      "Total benign train loss: 4.042401403712574\n",
      "\n",
      "[ Test epoch: 104 ]\n",
      "\n",
      "Test accuarcy: 92.2\n",
      "Test average loss: 0.004434460421279073\n",
      "Model Saved!\n",
      "0.005394490858604121\n",
      "\n",
      "[ Train epoch: 105 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011449326993897557\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0034733833745121956\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02917332388460636\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005112701561301947\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008361026993952692\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002739052986726165\n",
      "\n",
      "Total benign train accuarcy: 99.802\n",
      "Total benign train loss: 3.1954271917347796\n",
      "\n",
      "[ Test epoch: 105 ]\n",
      "\n",
      "Test accuarcy: 92.16\n",
      "Test average loss: 0.0044970519842114295\n",
      "Model Saved!\n",
      "0.0052866010414320385\n",
      "\n",
      "[ Train epoch: 106 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00119401840493083\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0034713083878159523\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0033838581293821335\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004448106046766043\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016084195813164115\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020781687926501036\n",
      "\n",
      "Total benign train accuarcy: 99.856\n",
      "Total benign train loss: 2.685973662770266\n",
      "\n",
      "[ Test epoch: 106 ]\n",
      "\n",
      "Test accuarcy: 92.1\n",
      "Test average loss: 0.004652614056318998\n",
      "Model Saved!\n",
      "0.005180869020603398\n",
      "\n",
      "[ Train epoch: 107 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018379698740318418\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.010130963288247585\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005456336075440049\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010983568616211414\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03225206211209297\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024722774978727102\n",
      "\n",
      "Total benign train accuarcy: 99.822\n",
      "Total benign train loss: 3.375567961309571\n",
      "\n",
      "[ Test epoch: 107 ]\n",
      "\n",
      "Test accuarcy: 92.32\n",
      "Test average loss: 0.004501674835011363\n",
      "Model Saved!\n",
      "0.005077251640191329\n",
      "\n",
      "[ Train epoch: 108 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013299825368449092\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017515006475150585\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.06423679739236832\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018933974206447601\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012040177825838327\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02458796091377735\n",
      "\n",
      "Total benign train accuarcy: 99.81\n",
      "Total benign train loss: 3.3689421031522215\n",
      "\n",
      "[ Test epoch: 108 ]\n",
      "\n",
      "Test accuarcy: 91.99\n",
      "Test average loss: 0.00444396706125699\n",
      "Model Saved!\n",
      "0.004975706607387503\n",
      "\n",
      "[ Train epoch: 109 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008041836321353912\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.009720593690872192\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005696073058061302\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00029599087429232895\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005177503917366266\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0220904890447855\n",
      "\n",
      "Total benign train accuarcy: 99.88\n",
      "Total benign train loss: 2.5709240971700638\n",
      "\n",
      "[ Test epoch: 109 ]\n",
      "\n",
      "Test accuarcy: 92.16\n",
      "Test average loss: 0.004556812223792076\n",
      "Model Saved!\n",
      "0.004876192475239753\n",
      "\n",
      "[ Train epoch: 110 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023239071015268564\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004098023346159607\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019257190870121121\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006955545395612717\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002101293997839093\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020337121095508337\n",
      "\n",
      "Total benign train accuarcy: 99.838\n",
      "Total benign train loss: 2.6820066182190203\n",
      "\n",
      "[ Test epoch: 110 ]\n",
      "\n",
      "Test accuarcy: 92.01\n",
      "Test average loss: 0.004672874977439642\n",
      "Model Saved!\n",
      "0.004778668625734958\n",
      "\n",
      "[ Train epoch: 111 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030844537541270256\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013347845524549484\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.019851556047797203\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006811074446886778\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004752664361149073\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008015877101570368\n",
      "\n",
      "Total benign train accuarcy: 99.836\n",
      "Total benign train loss: 3.036879719380522\n",
      "\n",
      "[ Test epoch: 111 ]\n",
      "\n",
      "Test accuarcy: 92.34\n",
      "Test average loss: 0.004500571686774492\n",
      "Model Saved!\n",
      "0.004683095253220258\n",
      "\n",
      "[ Train epoch: 112 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.036650530993938446\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010991223389282823\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018785828724503517\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.015307590365409851\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003884584584739059\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006048564333468676\n",
      "\n",
      "Total benign train accuarcy: 99.834\n",
      "Total benign train loss: 2.659211162434076\n",
      "\n",
      "[ Test epoch: 112 ]\n",
      "\n",
      "Test accuarcy: 92.5\n",
      "Test average loss: 0.0045499112226068976\n",
      "Model Saved!\n",
      "0.004589433348155853\n",
      "\n",
      "[ Train epoch: 113 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00020553417562041432\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014369134791195393\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007331848610192537\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008307293988764286\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005502432119101286\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.028208190575242043\n",
      "\n",
      "Total benign train accuarcy: 99.82\n",
      "Total benign train loss: 2.7905795661281445\n",
      "\n",
      "[ Test epoch: 113 ]\n",
      "\n",
      "Test accuarcy: 92.37\n",
      "Test average loss: 0.0045547377487644555\n",
      "Model Saved!\n",
      "0.004497644681192735\n",
      "\n",
      "[ Train epoch: 114 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001732884906232357\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009678893839009106\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00276169297285378\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007192209362983704\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009008276392705739\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020643876865506172\n",
      "\n",
      "Total benign train accuarcy: 99.886\n",
      "Total benign train loss: 2.120646444243903\n",
      "\n",
      "[ Test epoch: 114 ]\n",
      "\n",
      "Test accuarcy: 92.53\n",
      "Test average loss: 0.0046390713855624195\n",
      "Model Saved!\n",
      "0.004407691787568881\n",
      "\n",
      "[ Train epoch: 115 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001168632647022605\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031235439237207174\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011177753331139684\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.017686517909169197\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023300503380596638\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01368603017181158\n",
      "\n",
      "Total benign train accuarcy: 99.884\n",
      "Total benign train loss: 2.127203659794759\n",
      "\n",
      "[ Test epoch: 115 ]\n",
      "\n",
      "Test accuarcy: 92.53\n",
      "Test average loss: 0.004637225898355245\n",
      "Model Saved!\n",
      "0.004319537951817503\n",
      "\n",
      "[ Train epoch: 116 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014745522290468216\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005321971606463194\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03833677992224693\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00040417388663627207\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014153318479657173\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006028083618730307\n",
      "\n",
      "Total benign train accuarcy: 99.864\n",
      "Total benign train loss: 2.3350374063666095\n",
      "\n",
      "[ Test epoch: 116 ]\n",
      "\n",
      "Test accuarcy: 92.26\n",
      "Test average loss: 0.00464424303099513\n",
      "Model Saved!\n",
      "0.0042331471927811535\n",
      "\n",
      "[ Train epoch: 117 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015556347789242864\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015330436872318387\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014594960026443005\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002834576414898038\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005228307563811541\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005996093968860805\n",
      "\n",
      "Total benign train accuarcy: 99.862\n",
      "Total benign train loss: 2.347135792588233\n",
      "\n",
      "[ Test epoch: 117 ]\n",
      "\n",
      "Test accuarcy: 92.56\n",
      "Test average loss: 0.004597190939448774\n",
      "Model Saved!\n",
      "0.00414848424892553\n",
      "\n",
      "[ Train epoch: 118 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014551597414538264\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014801833778619766\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007299985736608505\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02148507349193096\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000117786847113166\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004574634076561779\n",
      "\n",
      "Total benign train accuarcy: 99.868\n",
      "Total benign train loss: 2.466833263388253\n",
      "\n",
      "[ Test epoch: 118 ]\n",
      "\n",
      "Test accuarcy: 92.39\n",
      "Test average loss: 0.004674549725931138\n",
      "Model Saved!\n",
      "0.004065514563947019\n",
      "\n",
      "[ Train epoch: 119 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013467739336192608\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010976848425343633\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005998791311867535\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00043840051512233913\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018012287095189095\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010573331965133548\n",
      "\n",
      "Total benign train accuarcy: 99.898\n",
      "Total benign train loss: 1.9007267523666087\n",
      "\n",
      "[ Test epoch: 119 ]\n",
      "\n",
      "Test accuarcy: 92.38\n",
      "Test average loss: 0.004786046876758337\n",
      "Model Saved!\n",
      "0.003984204272668079\n",
      "\n",
      "[ Train epoch: 120 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009999877074733377\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004998477641493082\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001094276667572558\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003862947050947696\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006179061601869762\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000940351455938071\n",
      "\n",
      "Total benign train accuarcy: 99.924\n",
      "Total benign train loss: 1.6147372638442903\n",
      "\n",
      "[ Test epoch: 120 ]\n",
      "\n",
      "Test accuarcy: 92.28\n",
      "Test average loss: 0.004733924009278417\n",
      "Model Saved!\n",
      "0.003904520187214717\n",
      "\n",
      "[ Train epoch: 121 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003972284495830536\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006014702958054841\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003385144053027034\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018374213948845863\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014640465378761292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014752718852832913\n",
      "\n",
      "Total benign train accuarcy: 99.912\n",
      "Total benign train loss: 1.751572491531988\n",
      "\n",
      "[ Test epoch: 121 ]\n",
      "\n",
      "Test accuarcy: 92.38\n",
      "Test average loss: 0.004771489301789552\n",
      "Model Saved!\n",
      "0.0038264297834704228\n",
      "\n",
      "[ Train epoch: 122 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007558410870842636\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019015517318621278\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.028507264330983162\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00101680017542094\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01100910734385252\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013871798291802406\n",
      "\n",
      "Total benign train accuarcy: 99.868\n",
      "Total benign train loss: 2.1517183799514896\n",
      "\n",
      "[ Test epoch: 122 ]\n",
      "\n",
      "Test accuarcy: 92.43\n",
      "Test average loss: 0.004723719234764576\n",
      "Model Saved!\n",
      "0.0037499011878010143\n",
      "\n",
      "[ Train epoch: 123 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025509882252663374\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012048260541632771\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028091466519981623\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009655705653131008\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011981780407950282\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00047217728570103645\n",
      "\n",
      "Total benign train accuarcy: 99.9\n",
      "Total benign train loss: 1.8596235614386387\n",
      "\n",
      "[ Test epoch: 123 ]\n",
      "\n",
      "Test accuarcy: 92.44\n",
      "Test average loss: 0.00469843240827322\n",
      "Model Saved!\n",
      "0.003674903164044994\n",
      "\n",
      "[ Train epoch: 124 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004050843883305788\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00035435831523500383\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001900231814943254\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004767804348375648\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004928451380692422\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003949863603338599\n",
      "\n",
      "Total benign train accuarcy: 99.908\n",
      "Total benign train loss: 1.7406318611647293\n",
      "\n",
      "[ Test epoch: 124 ]\n",
      "\n",
      "Test accuarcy: 92.54\n",
      "Test average loss: 0.004777868244051933\n",
      "Model Saved!\n",
      "0.003601405100764094\n",
      "\n",
      "[ Train epoch: 125 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003316413378342986\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010080737993121147\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00821737851947546\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03126348555088043\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00323013705201447\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007735585677437484\n",
      "\n",
      "Total benign train accuarcy: 99.896\n",
      "Total benign train loss: 2.026322283079935\n",
      "\n",
      "[ Test epoch: 125 ]\n",
      "\n",
      "Test accuarcy: 92.29\n",
      "Test average loss: 0.004731866670399904\n",
      "Model Saved!\n",
      "0.003529376998748812\n",
      "\n",
      "[ Train epoch: 126 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024765029083937407\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014196918345987797\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001680630724877119\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015551518881693482\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013681338168680668\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006388320471160114\n",
      "\n",
      "Total benign train accuarcy: 99.894\n",
      "Total benign train loss: 2.0777013753540814\n",
      "\n",
      "[ Test epoch: 126 ]\n",
      "\n",
      "Test accuarcy: 92.51\n",
      "Test average loss: 0.004635487741790712\n",
      "Model Saved!\n",
      "0.0034587894587738356\n",
      "\n",
      "[ Train epoch: 127 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008709917892701924\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009553900454193354\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004259416367858648\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002156415255740285\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011929344618692994\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00025705978623591363\n",
      "\n",
      "Total benign train accuarcy: 99.924\n",
      "Total benign train loss: 1.6137781327597622\n",
      "\n",
      "[ Test epoch: 127 ]\n",
      "\n",
      "Test accuarcy: 92.66\n",
      "Test average loss: 0.004677481991425156\n",
      "Model Saved!\n",
      "0.003389613669598359\n",
      "\n",
      "[ Train epoch: 128 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006060780957341194\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004067292436957359\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005102244322188199\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01545673981308937\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005508645554073155\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011134002124890685\n",
      "\n",
      "Total benign train accuarcy: 99.942\n",
      "Total benign train loss: 1.508253639931354\n",
      "\n",
      "[ Test epoch: 128 ]\n",
      "\n",
      "Test accuarcy: 92.45\n",
      "Test average loss: 0.004678192261606455\n",
      "Model Saved!\n",
      "0.003321821396206392\n",
      "\n",
      "[ Train epoch: 129 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00024481912259943783\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004409952089190483\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0035679778084158897\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002443374542053789\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 4.062452353537083e-05\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.011197543703019619\n",
      "\n",
      "Total benign train accuarcy: 99.912\n",
      "Total benign train loss: 1.6698329253595148\n",
      "\n",
      "[ Test epoch: 129 ]\n",
      "\n",
      "Test accuarcy: 92.54\n",
      "Test average loss: 0.004775852452218532\n",
      "Model Saved!\n",
      "0.003255384968282264\n",
      "\n",
      "[ Train epoch: 130 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007590728346258402\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010192515328526497\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001521067024441436\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00047150172758847475\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.019283898174762726\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008948878385126591\n",
      "\n",
      "Total benign train accuarcy: 99.914\n",
      "Total benign train loss: 1.7151801582695043\n",
      "\n",
      "[ Test epoch: 130 ]\n",
      "\n",
      "Test accuarcy: 92.29\n",
      "Test average loss: 0.004729652980342508\n",
      "Model Saved!\n",
      "0.0031902772689166186\n",
      "\n",
      "[ Train epoch: 131 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.019399821758270264\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003365605080034584\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000511500402353704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00611130939796567\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018252964364364743\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01566935144364834\n",
      "\n",
      "Total benign train accuarcy: 99.904\n",
      "Total benign train loss: 1.7389334080908156\n",
      "\n",
      "[ Test epoch: 131 ]\n",
      "\n",
      "Test accuarcy: 92.36\n",
      "Test average loss: 0.0046768349481746555\n",
      "Model Saved!\n",
      "0.003126471723538286\n",
      "\n",
      "[ Train epoch: 132 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004112116526812315\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009966777870431542\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004180640447884798\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003693374164868146\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003438943822402507\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.009446117095649242\n",
      "\n",
      "Total benign train accuarcy: 99.886\n",
      "Total benign train loss: 1.7787388420983916\n",
      "\n",
      "[ Test epoch: 132 ]\n",
      "\n",
      "Test accuarcy: 92.34\n",
      "Test average loss: 0.004681903841346502\n",
      "Model Saved!\n",
      "0.0030639422890675204\n",
      "\n",
      "[ Train epoch: 133 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001678825356066227\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005188277922570705\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018676702165976167\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00022674187493976206\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005458837258629501\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001152692479081452\n",
      "\n",
      "Total benign train accuarcy: 99.93\n",
      "Total benign train loss: 1.4752496076471289\n",
      "\n",
      "[ Test epoch: 133 ]\n",
      "\n",
      "Test accuarcy: 92.42\n",
      "Test average loss: 0.004689807615429163\n",
      "Model Saved!\n",
      "0.00300266344328617\n",
      "\n",
      "[ Train epoch: 134 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006916187121532857\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008025015704333782\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00027050302014686167\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00037661337410099804\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017922950210049748\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00033499300479888916\n",
      "\n",
      "Total benign train accuarcy: 99.936\n",
      "Total benign train loss: 1.3435454576792836\n",
      "\n",
      "[ Test epoch: 134 ]\n",
      "\n",
      "Test accuarcy: 92.46\n",
      "Test average loss: 0.004732544588670134\n",
      "Model Saved!\n",
      "0.0029426101744204464\n",
      "\n",
      "[ Train epoch: 135 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009493140387348831\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005292640533298254\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004188440798316151\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00037119793705642223\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004098924342542887\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004657346289604902\n",
      "\n",
      "Total benign train accuarcy: 99.92\n",
      "Total benign train loss: 1.5519287078059278\n",
      "\n",
      "[ Test epoch: 135 ]\n",
      "\n",
      "Test accuarcy: 92.46\n",
      "Test average loss: 0.004699850614741445\n",
      "Model Saved!\n",
      "0.0028837579709320373\n",
      "\n",
      "[ Train epoch: 136 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028426835779100657\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003182342916261405\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002109851222485304\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002794470638036728\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019840023014694452\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00013826547365169972\n",
      "\n",
      "Total benign train accuarcy: 99.932\n",
      "Total benign train loss: 1.3317877533154387\n",
      "\n",
      "[ Test epoch: 136 ]\n",
      "\n",
      "Test accuarcy: 92.56\n",
      "Test average loss: 0.004721364299254492\n",
      "Model Saved!\n",
      "0.0028260828115133966\n",
      "\n",
      "[ Train epoch: 137 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021579654421657324\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002747162012383342\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021085680928081274\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028535870369523764\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006205593817867339\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013606194406747818\n",
      "\n",
      "Total benign train accuarcy: 99.956\n",
      "Total benign train loss: 1.240170677914648\n",
      "\n",
      "[ Test epoch: 137 ]\n",
      "\n",
      "Test accuarcy: 92.43\n",
      "Test average loss: 0.004680376299470663\n",
      "Model Saved!\n",
      "0.0027695611552831286\n",
      "\n",
      "[ Train epoch: 138 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013193517224863172\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004191155021544546\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008451926405541599\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002321870269952342\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004114193143323064\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00117000553291291\n",
      "\n",
      "Total benign train accuarcy: 99.92\n",
      "Total benign train loss: 1.6357475569748203\n",
      "\n",
      "[ Test epoch: 138 ]\n",
      "\n",
      "Test accuarcy: 92.44\n",
      "Test average loss: 0.004769007661566138\n",
      "Model Saved!\n",
      "0.002714169932177466\n",
      "\n",
      "[ Train epoch: 139 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004302998539060354\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005342788062989712\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015699636423960328\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00044372971751727164\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00012198075273772702\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000609770359005779\n",
      "\n",
      "Total benign train accuarcy: 99.914\n",
      "Total benign train loss: 1.518441489453835\n",
      "\n",
      "[ Test epoch: 139 ]\n",
      "\n",
      "Test accuarcy: 92.39\n",
      "Test average loss: 0.004834833175688982\n",
      "Model Saved!\n",
      "0.002659886533533917\n",
      "\n",
      "[ Train epoch: 140 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00047792159602977335\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001660740002989769\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009128921083174646\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030756965279579163\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006745245191268623\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017467614961788058\n",
      "\n",
      "Total benign train accuarcy: 99.946\n",
      "Total benign train loss: 1.1681344442204136\n",
      "\n",
      "[ Test epoch: 140 ]\n",
      "\n",
      "Test accuarcy: 92.55\n",
      "Test average loss: 0.004692782568931579\n",
      "Model Saved!\n",
      "0.0026066888028632384\n",
      "\n",
      "[ Train epoch: 141 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00023799622431397438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008795480243861675\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028505006339401007\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006625461974181235\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010314775863662362\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001149719930253923\n",
      "\n",
      "Total benign train accuarcy: 99.938\n",
      "Total benign train loss: 1.1204907274986908\n",
      "\n",
      "[ Test epoch: 141 ]\n",
      "\n",
      "Test accuarcy: 92.63\n",
      "Test average loss: 0.004763485332950949\n",
      "Model Saved!\n",
      "0.0025545550268059737\n",
      "\n",
      "[ Train epoch: 142 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001115518738515675\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000534030725248158\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00028572947485372424\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005226868088357151\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009254491305910051\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003241842787247151\n",
      "\n",
      "Total benign train accuarcy: 99.934\n",
      "Total benign train loss: 1.3692838925635442\n",
      "\n",
      "[ Test epoch: 142 ]\n",
      "\n",
      "Test accuarcy: 92.52\n",
      "Test average loss: 0.004693480654805899\n",
      "Model Saved!\n",
      "0.0025034639262698543\n",
      "\n",
      "[ Train epoch: 143 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000636924640275538\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009263839456252754\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010861806804314256\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010053144069388509\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004963497049175203\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005862207617610693\n",
      "\n",
      "Total benign train accuarcy: 99.95\n",
      "Total benign train loss: 1.1104737758578267\n",
      "\n",
      "[ Test epoch: 143 ]\n",
      "\n",
      "Test accuarcy: 92.51\n",
      "Test average loss: 0.004837972301244736\n",
      "Model Saved!\n",
      "0.0024533946477444573\n",
      "\n",
      "[ Train epoch: 144 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006810012855567038\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007627002778463066\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00038830775883980095\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00022047711536288261\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008047241135500371\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00032715604174882174\n",
      "\n",
      "Total benign train accuarcy: 99.94\n",
      "Total benign train loss: 1.2462469816964585\n",
      "\n",
      "[ Test epoch: 144 ]\n",
      "\n",
      "Test accuarcy: 92.49\n",
      "Test average loss: 0.004753584198281169\n",
      "Model Saved!\n",
      "0.002404326754789568\n",
      "\n",
      "[ Train epoch: 145 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027494521345943213\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00234621693380177\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005752052646130323\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007941870135255158\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000846354232635349\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014173145173117518\n",
      "\n",
      "Total benign train accuarcy: 99.934\n",
      "Total benign train loss: 1.3502050957285974\n",
      "\n",
      "[ Test epoch: 145 ]\n",
      "\n",
      "Test accuarcy: 92.67\n",
      "Test average loss: 0.004700787480454892\n",
      "Model Saved!\n",
      "0.0023562402196937765\n",
      "\n",
      "[ Train epoch: 146 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00044896305189467967\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006436857511289418\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004710311070084572\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00019054929725825787\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009818498510867357\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010330512886866927\n",
      "\n",
      "Total benign train accuarcy: 99.946\n",
      "Total benign train loss: 1.1559035955215222\n",
      "\n",
      "[ Test epoch: 146 ]\n",
      "\n",
      "Test accuarcy: 92.64\n",
      "Test average loss: 0.004794248393177986\n",
      "Model Saved!\n",
      "0.002309115415299901\n",
      "\n",
      "[ Train epoch: 147 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0036845996510237455\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004946080152876675\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00017834060417953879\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005559362471103668\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0045764511451125145\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00035399841726757586\n",
      "\n",
      "Total benign train accuarcy: 99.952\n",
      "Total benign train loss: 1.0471060615400347\n",
      "\n",
      "[ Test epoch: 147 ]\n",
      "\n",
      "Test accuarcy: 92.5\n",
      "Test average loss: 0.004658745960332453\n",
      "Model Saved!\n",
      "0.002262933106993903\n",
      "\n",
      "[ Train epoch: 148 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004518355999607593\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00021844349976163357\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0034923788625746965\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008096261299215257\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006567531381733716\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003244851541239768\n",
      "\n",
      "Total benign train accuarcy: 99.964\n",
      "Total benign train loss: 1.0265647974774765\n",
      "\n",
      "[ Test epoch: 148 ]\n",
      "\n",
      "Test accuarcy: 92.42\n",
      "Test average loss: 0.0047403807945549485\n",
      "Model Saved!\n",
      "0.002217674444854025\n",
      "\n",
      "[ Train epoch: 149 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00037245324347168207\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00328373652882874\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000550845405086875\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006367554888129234\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003006713232025504\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00042296425090171397\n",
      "\n",
      "Total benign train accuarcy: 99.946\n",
      "Total benign train loss: 1.1817560248673544\n",
      "\n",
      "[ Test epoch: 149 ]\n",
      "\n",
      "Test accuarcy: 92.58\n",
      "Test average loss: 0.004660805030551273\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 150):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(0,150)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1) \n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss') \n",
    "plt.plot(epochs,loss_list) \n",
    "plt.subplot(1,2,2) \n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.plot(epochs, accuracy_list) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_sh",
   "language": "python",
   "name": "conda_sh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
