{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2' if torch.cuda.is_available() else 'cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding =4), #cifar 10 image size : 32x32\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './data', train=True, \n",
    "                download= True, transform = transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = './data', train = False,\n",
    "                download=True, transform= transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=96,\n",
    "                                          shuffle = True, num_workers = 2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=96,\n",
    "                                         shuffle =True, num_workers =2)\n",
    "\n",
    "#num_workers =2 인지 4인지 or batch_size test의 경우는 왜 100인지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    '''expand + depthwise + pointwise'''\n",
    "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
    "        super(Block, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "        planes = expansion * in_planes\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, groups=planes, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride == 1 and in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = out + self.shortcut(x) if self.stride==1 else out\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    # (expansion, out_planes, num_blocks, stride)\n",
    "    cfg = [(1,  16, 1, 1),\n",
    "           (6,  24, 2, 1),  # NOTE: change stride 2 -> 1 for CIFAR10\n",
    "           (6,  32, 3, 2),\n",
    "           (6,  64, 4, 2),\n",
    "           (6,  96, 3, 1),\n",
    "           (6, 160, 3, 2),\n",
    "           (6, 320, 1, 1)]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # NOTE: change conv1 stride 2 -> 1 for CIFAR10\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32)\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.linear = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for expansion, out_planes, num_blocks, stride in self.cfg:\n",
    "            strides = [stride] + [1]*(num_blocks-1)\n",
    "            for stride in strides:\n",
    "                layers.append(Block(in_planes, out_planes, expansion, stride))\n",
    "                in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        # NOTE: change pooling kernel_size 7 -> 4 for CIFAR10\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = MobileNetV2()\n",
    "    x = torch.randn(2,3,32,32)\n",
    "    y = net(x)\n",
    "    print(y.size())\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MobileNetV2()\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda:2':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "learning_rate = 0.045\n",
    "file_name = 'resnet18_cifar10.pt'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.00004)\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list=[]\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        benign_outputs = net(inputs)\n",
    "        loss = criterion(benign_outputs, targets)#예측값과 실제 타깃값\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = benign_outputs.max(1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current benign train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "            print('Current benign train loss:', loss.item())\n",
    "\n",
    "    print('\\nTotal benign train accuarcy:', 100. * correct / total)\n",
    "    print('Total benign train loss:', train_loss)\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        total += targets.size(0)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss += criterion(outputs, targets).item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    accuracy_list.append(100. * correct / total)\n",
    "    print('\\nTest accuarcy:', 100. * correct / total)\n",
    "    loss_list.append(loss)\n",
    "    print('Test average loss:', loss / total)    \n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved!')\n",
    "\n",
    "\n",
    "        \n",
    "#learning rate를 바꾸기\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = param_group['lr']\n",
    "        if epoch <=150 and epoch != 0:\n",
    "            param_group['lr'] = lr * 0.98\n",
    "            \n",
    "        print(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045\n",
      "\n",
      "[ Train epoch: 0 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7916666666666666\n",
      "Current benign train loss: 0.5994411110877991\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7708333333333334\n",
      "Current benign train loss: 0.6851136684417725\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7604166666666666\n",
      "Current benign train loss: 0.5846101641654968\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5793777704238892\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5571503639221191\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7897974848747253\n",
      "\n",
      "Total benign train accuarcy: 77.466\n",
      "Total benign train loss: 336.71338844299316\n",
      "\n",
      "[ Test epoch: 0 ]\n",
      "\n",
      "Test accuarcy: 77.16\n",
      "Test average loss: 0.007147360894083977\n",
      "Model Saved!\n",
      "0.0441\n",
      "\n",
      "[ Train epoch: 1 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6463717818260193\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.4992307126522064\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.5191325545310974\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.45496341586112976\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8020833333333334\n",
      "Current benign train loss: 0.6027831435203552\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7708333333333334\n",
      "Current benign train loss: 0.5782637000083923\n",
      "\n",
      "Total benign train accuarcy: 80.156\n",
      "Total benign train loss: 301.19552731513977\n",
      "\n",
      "[ Test epoch: 1 ]\n",
      "\n",
      "Test accuarcy: 79.99\n",
      "Test average loss: 0.006302534151077271\n",
      "Model Saved!\n",
      "0.043218\n",
      "\n",
      "[ Train epoch: 2 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.43513786792755127\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.39039063453674316\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.4282987117767334\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6655630469322205\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.5240219235420227\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8229166666666666\n",
      "Current benign train loss: 0.5148457288742065\n",
      "\n",
      "Total benign train accuarcy: 81.58\n",
      "Total benign train loss: 277.4291524887085\n",
      "\n",
      "[ Test epoch: 2 ]\n",
      "\n",
      "Test accuarcy: 81.31\n",
      "Test average loss: 0.005705201089382172\n",
      "Model Saved!\n",
      "0.04235364\n",
      "\n",
      "[ Train epoch: 3 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8229166666666666\n",
      "Current benign train loss: 0.5837461352348328\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.38460683822631836\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5479816794395447\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.327260285615921\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8020833333333334\n",
      "Current benign train loss: 0.5798707604408264\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.5678699612617493\n",
      "\n",
      "Total benign train accuarcy: 83.276\n",
      "Total benign train loss: 251.3217300772667\n",
      "\n",
      "[ Test epoch: 3 ]\n",
      "\n",
      "Test accuarcy: 81.28\n",
      "Test average loss: 0.005894938462972641\n",
      "Model Saved!\n",
      "0.0415065672\n",
      "\n",
      "[ Train epoch: 4 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.5214295983314514\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7395833333333334\n",
      "Current benign train loss: 0.7308456897735596\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.4390357434749603\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.49107351899147034\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.410294771194458\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.5161562561988831\n",
      "\n",
      "Total benign train accuarcy: 84.66\n",
      "Total benign train loss: 233.6801343113184\n",
      "\n",
      "[ Test epoch: 4 ]\n",
      "\n",
      "Test accuarcy: 83.64\n",
      "Test average loss: 0.005129495324194431\n",
      "Model Saved!\n",
      "0.040676435856\n",
      "\n",
      "[ Train epoch: 5 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7708333333333334\n",
      "Current benign train loss: 0.5934283137321472\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.45158135890960693\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5454766154289246\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.27850988507270813\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4067523181438446\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8645833333333334\n",
      "Current benign train loss: 0.3767218589782715\n",
      "\n",
      "Total benign train accuarcy: 85.242\n",
      "Total benign train loss: 221.84248872101307\n",
      "\n",
      "[ Test epoch: 5 ]\n",
      "\n",
      "Test accuarcy: 84.73\n",
      "Test average loss: 0.004745226158201695\n",
      "Model Saved!\n",
      "0.039862907138879994\n",
      "\n",
      "[ Train epoch: 6 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.34338387846946716\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.29550233483314514\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.24727129936218262\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.3318844735622406\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.36976587772369385\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7916666666666666\n",
      "Current benign train loss: 0.578151285648346\n",
      "\n",
      "Total benign train accuarcy: 86.22\n",
      "Total benign train loss: 205.84873223304749\n",
      "\n",
      "[ Test epoch: 6 ]\n",
      "\n",
      "Test accuarcy: 83.76\n",
      "Test average loss: 0.005253044174611568\n",
      "Model Saved!\n",
      "0.039065648996102396\n",
      "\n",
      "[ Train epoch: 7 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.18053795397281647\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8229166666666666\n",
      "Current benign train loss: 0.39029374718666077\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.2603219747543335\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.37750616669654846\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7916666666666666\n",
      "Current benign train loss: 0.5891375541687012\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.31779584288597107\n",
      "\n",
      "Total benign train accuarcy: 86.926\n",
      "Total benign train loss: 196.53149349987507\n",
      "\n",
      "[ Test epoch: 7 ]\n",
      "\n",
      "Test accuarcy: 86.41\n",
      "Test average loss: 0.004372632512450218\n",
      "Model Saved!\n",
      "0.03828433601618035\n",
      "\n",
      "[ Train epoch: 8 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.4239005744457245\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.2926149070262909\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8645833333333334\n",
      "Current benign train loss: 0.3701147139072418\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8333333333333334\n",
      "Current benign train loss: 0.4548046290874481\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.39321625232696533\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.35393598675727844\n",
      "\n",
      "Total benign train accuarcy: 87.636\n",
      "Total benign train loss: 184.58769373595715\n",
      "\n",
      "[ Test epoch: 8 ]\n",
      "\n",
      "Test accuarcy: 85.22\n",
      "Test average loss: 0.004587124322354794\n",
      "Model Saved!\n",
      "0.03751864929585674\n",
      "\n",
      "[ Train epoch: 9 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18585658073425293\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8645833333333334\n",
      "Current benign train loss: 0.33401861786842346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.24572546780109406\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4235965311527252\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.37150195240974426\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.41749536991119385\n",
      "\n",
      "Total benign train accuarcy: 88.32\n",
      "Total benign train loss: 175.08711531758308\n",
      "\n",
      "[ Test epoch: 9 ]\n",
      "\n",
      "Test accuarcy: 87.11\n",
      "Test average loss: 0.00421521302908659\n",
      "Model Saved!\n",
      "0.036768276309939604\n",
      "\n",
      "[ Train epoch: 10 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.38022223114967346\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.4101130962371826\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8541666666666666\n",
      "Current benign train loss: 0.41146978735923767\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.2226184755563736\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.3277580440044403\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3326553702354431\n",
      "\n",
      "Total benign train accuarcy: 88.994\n",
      "Total benign train loss: 165.5280474498868\n",
      "\n",
      "[ Test epoch: 10 ]\n",
      "\n",
      "Test accuarcy: 86.4\n",
      "Test average loss: 0.004276232761144638\n",
      "Model Saved!\n",
      "0.03603291078374081\n",
      "\n",
      "[ Train epoch: 11 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.28258341550827026\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.33078643679618835\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.39073899388313293\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.3367672860622406\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4181574285030365\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.25291240215301514\n",
      "\n",
      "Total benign train accuarcy: 89.506\n",
      "Total benign train loss: 156.84256140887737\n",
      "\n",
      "[ Test epoch: 11 ]\n",
      "\n",
      "Test accuarcy: 86.43\n",
      "Test average loss: 0.004288578149676323\n",
      "Model Saved!\n",
      "0.03531225256806599\n",
      "\n",
      "[ Train epoch: 12 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1780461072921753\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.18337593972682953\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.3499586582183838\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.2643987238407135\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.341722697019577\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.32083606719970703\n",
      "\n",
      "Total benign train accuarcy: 89.926\n",
      "Total benign train loss: 152.13199769705534\n",
      "\n",
      "[ Test epoch: 12 ]\n",
      "\n",
      "Test accuarcy: 87.95\n",
      "Test average loss: 0.0038151497304439543\n",
      "Model Saved!\n",
      "0.03460600751670467\n",
      "\n",
      "[ Train epoch: 13 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1775507777929306\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.24105054140090942\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.28630539774894714\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.291910320520401\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.22391843795776367\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.27658775448799133\n",
      "\n",
      "Total benign train accuarcy: 90.178\n",
      "Total benign train loss: 145.35678818821907\n",
      "\n",
      "[ Test epoch: 13 ]\n",
      "\n",
      "Test accuarcy: 87.55\n",
      "Test average loss: 0.004042972841858864\n",
      "Model Saved!\n",
      "0.033913887366370576\n",
      "\n",
      "[ Train epoch: 14 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.16288575530052185\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8645833333333334\n",
      "Current benign train loss: 0.30963659286499023\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.15278233587741852\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.22866229712963104\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.14747801423072815\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.4222841262817383\n",
      "\n",
      "Total benign train accuarcy: 90.892\n",
      "Total benign train loss: 136.83624640107155\n",
      "\n",
      "[ Test epoch: 14 ]\n",
      "\n",
      "Test accuarcy: 88.04\n",
      "Test average loss: 0.003911344373226166\n",
      "Model Saved!\n",
      "0.03323560961904316\n",
      "\n",
      "[ Train epoch: 15 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19342492520809174\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.16338391602039337\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.15370382368564606\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.09937959164381027\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.21082811057567596\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8645833333333334\n",
      "Current benign train loss: 0.34220442175865173\n",
      "\n",
      "Total benign train accuarcy: 91.234\n",
      "Total benign train loss: 131.4782102406025\n",
      "\n",
      "[ Test epoch: 15 ]\n",
      "\n",
      "Test accuarcy: 86.97\n",
      "Test average loss: 0.004377125835418701\n",
      "Model Saved!\n",
      "0.0325708974266623\n",
      "\n",
      "[ Train epoch: 16 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.1948329657316208\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.268580824136734\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.113179050385952\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.369914174079895\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.18349511921405792\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.2983910143375397\n",
      "\n",
      "Total benign train accuarcy: 91.554\n",
      "Total benign train loss: 125.94370122253895\n",
      "\n",
      "[ Test epoch: 16 ]\n",
      "\n",
      "Test accuarcy: 87.85\n",
      "Test average loss: 0.0039046300560235977\n",
      "Model Saved!\n",
      "0.03191947947812905\n",
      "\n",
      "[ Train epoch: 17 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.2420475035905838\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.18470127880573273\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.23172782361507416\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.24165357649326324\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.22808291018009186\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.29693397879600525\n",
      "\n",
      "Total benign train accuarcy: 91.798\n",
      "Total benign train loss: 120.93499401956797\n",
      "\n",
      "[ Test epoch: 17 ]\n",
      "\n",
      "Test accuarcy: 88.62\n",
      "Test average loss: 0.0037787661388516427\n",
      "Model Saved!\n",
      "0.03128108988856647\n",
      "\n",
      "[ Train epoch: 18 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.24321232736110687\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.24235807359218597\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.18254975974559784\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.25099942088127136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.2405022233724594\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15407384932041168\n",
      "\n",
      "Total benign train accuarcy: 92.098\n",
      "Total benign train loss: 115.84752409905195\n",
      "\n",
      "[ Test epoch: 18 ]\n",
      "\n",
      "Test accuarcy: 88.37\n",
      "Test average loss: 0.0037941769614815712\n",
      "Model Saved!\n",
      "0.030655468090795137\n",
      "\n",
      "[ Train epoch: 19 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2040964812040329\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.23088891804218292\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.21016333997249603\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.26186686754226685\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2082231193780899\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.19435878098011017\n",
      "\n",
      "Total benign train accuarcy: 92.562\n",
      "Total benign train loss: 111.33079624921083\n",
      "\n",
      "[ Test epoch: 19 ]\n",
      "\n",
      "Test accuarcy: 88.86\n",
      "Test average loss: 0.003674284607172012\n",
      "Model Saved!\n",
      "0.030042358728979233\n",
      "\n",
      "[ Train epoch: 20 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.2172374278306961\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.17145158350467682\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.3820708990097046\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.2803777754306793\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.16769163310527802\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8854166666666666\n",
      "Current benign train loss: 0.29936739802360535\n",
      "\n",
      "Total benign train accuarcy: 92.828\n",
      "Total benign train loss: 107.15591537952423\n",
      "\n",
      "[ Test epoch: 20 ]\n",
      "\n",
      "Test accuarcy: 88.87\n",
      "Test average loss: 0.0036995536424219606\n",
      "Model Saved!\n",
      "0.029441511554399648\n",
      "\n",
      "[ Train epoch: 21 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.18569791316986084\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1586354821920395\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.15917159616947174\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08159365504980087\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.16234439611434937\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.18342165648937225\n",
      "\n",
      "Total benign train accuarcy: 92.97\n",
      "Total benign train loss: 104.2991619631648\n",
      "\n",
      "[ Test epoch: 21 ]\n",
      "\n",
      "Test accuarcy: 89.23\n",
      "Test average loss: 0.0036349095806479455\n",
      "Model Saved!\n",
      "0.028852681323311653\n",
      "\n",
      "[ Train epoch: 22 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08884235471487045\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.23727212846279144\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.18681783974170685\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.20112168788909912\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3225864768028259\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1287442147731781\n",
      "\n",
      "Total benign train accuarcy: 93.328\n",
      "Total benign train loss: 98.35650854930282\n",
      "\n",
      "[ Test epoch: 22 ]\n",
      "\n",
      "Test accuarcy: 88.69\n",
      "Test average loss: 0.00393668874502182\n",
      "Model Saved!\n",
      "0.02827562769684542\n",
      "\n",
      "[ Train epoch: 23 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14405834674835205\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1502489596605301\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.16436222195625305\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1803719401359558\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.10780896991491318\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.139191672205925\n",
      "\n",
      "Total benign train accuarcy: 93.586\n",
      "Total benign train loss: 95.24680918455124\n",
      "\n",
      "[ Test epoch: 23 ]\n",
      "\n",
      "Test accuarcy: 89.73\n",
      "Test average loss: 0.0035357487730681898\n",
      "Model Saved!\n",
      "0.027710115142908512\n",
      "\n",
      "[ Train epoch: 24 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12029705196619034\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17617543041706085\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.15078698098659515\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.11992364376783371\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.15794633328914642\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.16968925297260284\n",
      "\n",
      "Total benign train accuarcy: 93.828\n",
      "Total benign train loss: 91.61122206225991\n",
      "\n",
      "[ Test epoch: 24 ]\n",
      "\n",
      "Test accuarcy: 89.14\n",
      "Test average loss: 0.003615760679543018\n",
      "Model Saved!\n",
      "0.027155912840050343\n",
      "\n",
      "[ Train epoch: 25 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15451763570308685\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.2273067682981491\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.17487840354442596\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.20068062841892242\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.18794147670269012\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2363968938589096\n",
      "\n",
      "Total benign train accuarcy: 94.044\n",
      "Total benign train loss: 86.32784808799624\n",
      "\n",
      "[ Test epoch: 25 ]\n",
      "\n",
      "Test accuarcy: 89.67\n",
      "Test average loss: 0.0035867846930399535\n",
      "Model Saved!\n",
      "0.026612794583249336\n",
      "\n",
      "[ Train epoch: 26 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10197295993566513\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3101065158843994\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11903348565101624\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1945999711751938\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11999189108610153\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05375013127923012\n",
      "\n",
      "Total benign train accuarcy: 94.124\n",
      "Total benign train loss: 84.8666037209332\n",
      "\n",
      "[ Test epoch: 26 ]\n",
      "\n",
      "Test accuarcy: 89.79\n",
      "Test average loss: 0.0036178580589592457\n",
      "Model Saved!\n",
      "0.02608053869158435\n",
      "\n",
      "[ Train epoch: 27 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0550115592777729\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.11930370330810547\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.21738030016422272\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08739302307367325\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1623895913362503\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1350117325782776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign train accuarcy: 94.456\n",
      "Total benign train loss: 82.5999387409538\n",
      "\n",
      "[ Test epoch: 27 ]\n",
      "\n",
      "Test accuarcy: 89.65\n",
      "Test average loss: 0.0035725535579025744\n",
      "Model Saved!\n",
      "0.02555892791775266\n",
      "\n",
      "[ Train epoch: 28 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12966492772102356\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9166666666666666\n",
      "Current benign train loss: 0.36640694737434387\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.15393789112567902\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.15407820045948029\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10627421736717224\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.14830122888088226\n",
      "\n",
      "Total benign train accuarcy: 94.726\n",
      "Total benign train loss: 79.4878012649715\n",
      "\n",
      "[ Test epoch: 28 ]\n",
      "\n",
      "Test accuarcy: 89.63\n",
      "Test average loss: 0.00368459479957819\n",
      "Model Saved!\n",
      "0.025047749359397607\n",
      "\n",
      "[ Train epoch: 29 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.2046654373407364\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.10116613656282425\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.16992461681365967\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0784890428185463\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1291598081588745\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.14976850152015686\n",
      "\n",
      "Total benign train accuarcy: 95.014\n",
      "Total benign train loss: 74.62663853354752\n",
      "\n",
      "[ Test epoch: 29 ]\n",
      "\n",
      "Test accuarcy: 89.44\n",
      "Test average loss: 0.0037948942601680755\n",
      "Model Saved!\n",
      "0.024546794372209652\n",
      "\n",
      "[ Train epoch: 30 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20344330370426178\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19485895335674286\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17206047475337982\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10313918441534042\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1203412115573883\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1922859400510788\n",
      "\n",
      "Total benign train accuarcy: 95.03\n",
      "Total benign train loss: 73.1001024954021\n",
      "\n",
      "[ Test epoch: 30 ]\n",
      "\n",
      "Test accuarcy: 89.81\n",
      "Test average loss: 0.003687850034236908\n",
      "Model Saved!\n",
      "0.02405585848476546\n",
      "\n",
      "[ Train epoch: 31 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.18728578090667725\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.15710915625095367\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.2033233791589737\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.12170261144638062\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1280766725540161\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08299780637025833\n",
      "\n",
      "Total benign train accuarcy: 95.304\n",
      "Total benign train loss: 68.46560343913734\n",
      "\n",
      "[ Test epoch: 31 ]\n",
      "\n",
      "Test accuarcy: 89.19\n",
      "Test average loss: 0.003930989031493664\n",
      "Model Saved!\n",
      "0.02357474131507015\n",
      "\n",
      "[ Train epoch: 32 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1390984207391739\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08762306720018387\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05480113998055458\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.072227343916893\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09261489659547806\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8958333333333334\n",
      "Current benign train loss: 0.2630320191383362\n",
      "\n",
      "Total benign train accuarcy: 95.408\n",
      "Total benign train loss: 67.08359502255917\n",
      "\n",
      "[ Test epoch: 32 ]\n",
      "\n",
      "Test accuarcy: 89.75\n",
      "Test average loss: 0.0037168041039258243\n",
      "Model Saved!\n",
      "0.023103246488768745\n",
      "\n",
      "[ Train epoch: 33 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.08210697025060654\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0824374184012413\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.24279676377773285\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08068541437387466\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.11441206187009811\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.15296074748039246\n",
      "\n",
      "Total benign train accuarcy: 95.478\n",
      "Total benign train loss: 65.75012656860054\n",
      "\n",
      "[ Test epoch: 33 ]\n",
      "\n",
      "Test accuarcy: 90.46\n",
      "Test average loss: 0.0036695955902338027\n",
      "Model Saved!\n",
      "0.02264118155899337\n",
      "\n",
      "[ Train epoch: 34 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1401379406452179\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.16430380940437317\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11789000034332275\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06473071128129959\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.08721911162137985\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07877129316329956\n",
      "\n",
      "Total benign train accuarcy: 95.784\n",
      "Total benign train loss: 61.49308530241251\n",
      "\n",
      "[ Test epoch: 34 ]\n",
      "\n",
      "Test accuarcy: 90.38\n",
      "Test average loss: 0.003697971774637699\n",
      "Model Saved!\n",
      "0.022188357927813502\n",
      "\n",
      "[ Train epoch: 35 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.056028664112091064\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07451914995908737\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06936623156070709\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04418168589472771\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09477221965789795\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.11579384654760361\n",
      "\n",
      "Total benign train accuarcy: 95.916\n",
      "Total benign train loss: 59.22269633598626\n",
      "\n",
      "[ Test epoch: 35 ]\n",
      "\n",
      "Test accuarcy: 89.68\n",
      "Test average loss: 0.004075527217239141\n",
      "Model Saved!\n",
      "0.021744590769257232\n",
      "\n",
      "[ Train epoch: 36 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.06979639083147049\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.12088712304830551\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06670965999364853\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0758342370390892\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.09563352912664413\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.13553711771965027\n",
      "\n",
      "Total benign train accuarcy: 96.054\n",
      "Total benign train loss: 57.69264607410878\n",
      "\n",
      "[ Test epoch: 36 ]\n",
      "\n",
      "Test accuarcy: 90.0\n",
      "Test average loss: 0.003915676742698998\n",
      "Model Saved!\n",
      "0.021309698953872087\n",
      "\n",
      "[ Train epoch: 37 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10315918922424316\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08907955139875412\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09791142493486404\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.09197509288787842\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.11946254968643188\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.17880673706531525\n",
      "\n",
      "Total benign train accuarcy: 96.33\n",
      "Total benign train loss: 53.974509679712355\n",
      "\n",
      "[ Test epoch: 37 ]\n",
      "\n",
      "Test accuarcy: 89.8\n",
      "Test average loss: 0.0039580545656383035\n",
      "Model Saved!\n",
      "0.020883504974794645\n",
      "\n",
      "[ Train epoch: 38 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11971175670623779\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14794036746025085\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.14890556037425995\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.13318201899528503\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08265630155801773\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07323222607374191\n",
      "\n",
      "Total benign train accuarcy: 96.406\n",
      "Total benign train loss: 52.73865839652717\n",
      "\n",
      "[ Test epoch: 38 ]\n",
      "\n",
      "Test accuarcy: 90.5\n",
      "Test average loss: 0.003771910061687231\n",
      "Model Saved!\n",
      "0.020465834875298752\n",
      "\n",
      "[ Train epoch: 39 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10344457626342773\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.14396749436855316\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04623566195368767\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.10200311988592148\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.1467694789171219\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0938156470656395\n",
      "\n",
      "Total benign train accuarcy: 96.478\n",
      "Total benign train loss: 51.97492185700685\n",
      "\n",
      "[ Test epoch: 39 ]\n",
      "\n",
      "Test accuarcy: 90.45\n",
      "Test average loss: 0.0038189109057188034\n",
      "Model Saved!\n",
      "0.020056518177792776\n",
      "\n",
      "[ Train epoch: 40 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06819875538349152\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.07890798896551132\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.039613451808691025\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05166324973106384\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08319136500358582\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.10459720343351364\n",
      "\n",
      "Total benign train accuarcy: 96.604\n",
      "Total benign train loss: 49.83373965322971\n",
      "\n",
      "[ Test epoch: 40 ]\n",
      "\n",
      "Test accuarcy: 90.28\n",
      "Test average loss: 0.00383880971968174\n",
      "Model Saved!\n",
      "0.01965538781423692\n",
      "\n",
      "[ Train epoch: 41 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09604137390851974\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07273659110069275\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.12899969518184662\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09415038675069809\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.14533235132694244\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09989070147275925\n",
      "\n",
      "Total benign train accuarcy: 96.652\n",
      "Total benign train loss: 47.55254076421261\n",
      "\n",
      "[ Test epoch: 41 ]\n",
      "\n",
      "Test accuarcy: 90.28\n",
      "Test average loss: 0.00382145821377635\n",
      "Model Saved!\n",
      "0.01926228005795218\n",
      "\n",
      "[ Train epoch: 42 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.25224068760871887\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07938993722200394\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04332287609577179\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04248353838920593\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11485021561384201\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0468057356774807\n",
      "\n",
      "Total benign train accuarcy: 96.77\n",
      "Total benign train loss: 45.70853874087334\n",
      "\n",
      "[ Test epoch: 42 ]\n",
      "\n",
      "Test accuarcy: 90.14\n",
      "Test average loss: 0.003969028957188129\n",
      "Model Saved!\n",
      "0.018877034456793135\n",
      "\n",
      "[ Train epoch: 43 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.11271507292985916\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.14743709564208984\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08915448933839798\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08302339166402817\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.0986265167593956\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.040824245661497116\n",
      "\n",
      "Total benign train accuarcy: 96.984\n",
      "Total benign train loss: 45.04292960930616\n",
      "\n",
      "[ Test epoch: 43 ]\n",
      "\n",
      "Test accuarcy: 90.36\n",
      "Test average loss: 0.0038062773682177066\n",
      "Model Saved!\n",
      "0.018499493767657273\n",
      "\n",
      "[ Train epoch: 44 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1532890349626541\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08462198823690414\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11700817942619324\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09193501621484756\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06620714068412781\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.16638050973415375\n",
      "\n",
      "Total benign train accuarcy: 97.036\n",
      "Total benign train loss: 42.50642199162394\n",
      "\n",
      "[ Test epoch: 44 ]\n",
      "\n",
      "Test accuarcy: 90.87\n",
      "Test average loss: 0.003730386423319578\n",
      "Model Saved!\n",
      "0.018129503892304128\n",
      "\n",
      "[ Train epoch: 45 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05508287623524666\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.13304756581783295\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01509623322635889\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.09864719957113266\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04636518284678459\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.12899209558963776\n",
      "\n",
      "Total benign train accuarcy: 97.326\n",
      "Total benign train loss: 40.23623766750097\n",
      "\n",
      "[ Test epoch: 45 ]\n",
      "\n",
      "Test accuarcy: 90.97\n",
      "Test average loss: 0.003593875783495605\n",
      "Model Saved!\n",
      "0.017766913814458045\n",
      "\n",
      "[ Train epoch: 46 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05905107036232948\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.045149803161621094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07613439112901688\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.0896991416811943\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07607883960008621\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03956752270460129\n",
      "\n",
      "Total benign train accuarcy: 97.344\n",
      "Total benign train loss: 38.75413051666692\n",
      "\n",
      "[ Test epoch: 46 ]\n",
      "\n",
      "Test accuarcy: 90.23\n",
      "Test average loss: 0.004120476227253676\n",
      "Model Saved!\n",
      "0.017411575538168883\n",
      "\n",
      "[ Train epoch: 47 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07732325047254562\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.059025123715400696\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10218551009893417\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1367303729057312\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10723105818033218\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.09463244676589966\n",
      "\n",
      "Total benign train accuarcy: 97.452\n",
      "Total benign train loss: 37.055822825524956\n",
      "\n",
      "[ Test epoch: 47 ]\n",
      "\n",
      "Test accuarcy: 90.83\n",
      "Test average loss: 0.003866127447411418\n",
      "Model Saved!\n",
      "0.017063344027405506\n",
      "\n",
      "[ Train epoch: 48 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.14720293879508972\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08235424757003784\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01916343718767166\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05357297882437706\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.16254812479019165\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.055547136813402176\n",
      "\n",
      "Total benign train accuarcy: 97.556\n",
      "Total benign train loss: 35.59228977188468\n",
      "\n",
      "[ Test epoch: 48 ]\n",
      "\n",
      "Test accuarcy: 90.86\n",
      "Test average loss: 0.004018586445599794\n",
      "Model Saved!\n",
      "0.016722077146857396\n",
      "\n",
      "[ Train epoch: 49 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03859004005789757\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0226229727268219\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0678151473402977\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.029873475432395935\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10936913639307022\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15440867841243744\n",
      "\n",
      "Total benign train accuarcy: 97.592\n",
      "Total benign train loss: 34.76517956517637\n",
      "\n",
      "[ Test epoch: 49 ]\n",
      "\n",
      "Test accuarcy: 91.03\n",
      "Test average loss: 0.00402781851887703\n",
      "Model Saved!\n",
      "0.016387635603920248\n",
      "\n",
      "[ Train epoch: 50 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07013987749814987\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10817784816026688\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06591476500034332\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04611242935061455\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020082050934433937\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05402080714702606\n",
      "\n",
      "Total benign train accuarcy: 97.712\n",
      "Total benign train loss: 33.457265061326325\n",
      "\n",
      "[ Test epoch: 50 ]\n",
      "\n",
      "Test accuarcy: 90.8\n",
      "Test average loss: 0.0040962527088820935\n",
      "Model Saved!\n",
      "0.016059882891841844\n",
      "\n",
      "[ Train epoch: 51 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07249685376882553\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03393000736832619\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.08982759714126587\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03515439108014107\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0897589698433876\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04929422214627266\n",
      "\n",
      "Total benign train accuarcy: 97.756\n",
      "Total benign train loss: 32.55361217726022\n",
      "\n",
      "[ Test epoch: 51 ]\n",
      "\n",
      "Test accuarcy: 91.0\n",
      "Test average loss: 0.003882776619307697\n",
      "Model Saved!\n",
      "0.01573868523400501\n",
      "\n",
      "[ Train epoch: 52 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0481107197701931\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04833905026316643\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.039462748914957047\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0470905564725399\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04619695618748665\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05150653421878815\n",
      "\n",
      "Total benign train accuarcy: 97.842\n",
      "Total benign train loss: 30.761870520189404\n",
      "\n",
      "[ Test epoch: 52 ]\n",
      "\n",
      "Test accuarcy: 90.83\n",
      "Test average loss: 0.003999880863865837\n",
      "Model Saved!\n",
      "0.015423911529324909\n",
      "\n",
      "[ Train epoch: 53 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04334774985909462\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04547505080699921\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.16905461251735687\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07280167192220688\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.054339755326509476\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017979180440306664\n",
      "\n",
      "Total benign train accuarcy: 98.006\n",
      "Total benign train loss: 29.428000607527792\n",
      "\n",
      "[ Test epoch: 53 ]\n",
      "\n",
      "Test accuarcy: 91.22\n",
      "Test average loss: 0.0040492832347750665\n",
      "Model Saved!\n",
      "0.01511543329873841\n",
      "\n",
      "[ Train epoch: 54 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.0856839120388031\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03898173198103905\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06319034844636917\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06061772629618645\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02095755934715271\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0830802395939827\n",
      "\n",
      "Total benign train accuarcy: 98.102\n",
      "Total benign train loss: 27.90725934598595\n",
      "\n",
      "[ Test epoch: 54 ]\n",
      "\n",
      "Test accuarcy: 90.86\n",
      "Test average loss: 0.004045514826476574\n",
      "Model Saved!\n",
      "0.014813124632763642\n",
      "\n",
      "[ Train epoch: 55 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024332212284207344\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06654810160398483\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.021384602412581444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0702233836054802\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.13589757680892944\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03813358023762703\n",
      "\n",
      "Total benign train accuarcy: 98.004\n",
      "Total benign train loss: 28.973197107203305\n",
      "\n",
      "[ Test epoch: 55 ]\n",
      "\n",
      "Test accuarcy: 91.11\n",
      "Test average loss: 0.0040965871058404445\n",
      "Model Saved!\n",
      "0.01451686214010837\n",
      "\n",
      "[ Train epoch: 56 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.11307605355978012\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02926436811685562\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.028580976650118828\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06262052804231644\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0369386188685894\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016648609191179276\n",
      "\n",
      "Total benign train accuarcy: 98.22\n",
      "Total benign train loss: 26.11013103206642\n",
      "\n",
      "[ Test epoch: 56 ]\n",
      "\n",
      "Test accuarcy: 90.97\n",
      "Test average loss: 0.004206505988538265\n",
      "Model Saved!\n",
      "0.014226524897306202\n",
      "\n",
      "[ Train epoch: 57 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03639686852693558\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.022889142856001854\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04460641369223595\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03810267895460129\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02092675119638443\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1095905527472496\n",
      "\n",
      "Total benign train accuarcy: 98.27\n",
      "Total benign train loss: 24.517317733960226\n",
      "\n",
      "[ Test epoch: 57 ]\n",
      "\n",
      "Test accuarcy: 91.29\n",
      "Test average loss: 0.004245821607112885\n",
      "Model Saved!\n",
      "0.013941994399360077\n",
      "\n",
      "[ Train epoch: 58 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03153902292251587\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06694488972425461\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.09248668700456619\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014275404624640942\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05084184929728508\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017402343451976776\n",
      "\n",
      "Total benign train accuarcy: 98.358\n",
      "Total benign train loss: 23.7296131872572\n",
      "\n",
      "[ Test epoch: 58 ]\n",
      "\n",
      "Test accuarcy: 91.02\n",
      "Test average loss: 0.004365651004388928\n",
      "Model Saved!\n",
      "0.013663154511372875\n",
      "\n",
      "[ Train epoch: 59 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.1133982464671135\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06906250864267349\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9270833333333334\n",
      "Current benign train loss: 0.1683153510093689\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02502604015171528\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05070884898304939\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.07671986520290375\n",
      "\n",
      "Total benign train accuarcy: 98.326\n",
      "Total benign train loss: 23.700438286177814\n",
      "\n",
      "[ Test epoch: 59 ]\n",
      "\n",
      "Test accuarcy: 91.03\n",
      "Test average loss: 0.004426867315173149\n",
      "Model Saved!\n",
      "0.013389891421145416\n",
      "\n",
      "[ Train epoch: 60 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04417366907000542\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.021862918511033058\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.08364376425743103\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.029126355424523354\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03742457553744316\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03924484923481941\n",
      "\n",
      "Total benign train accuarcy: 98.548\n",
      "Total benign train loss: 20.99088679905981\n",
      "\n",
      "[ Test epoch: 60 ]\n",
      "\n",
      "Test accuarcy: 91.31\n",
      "Test average loss: 0.0042744603879749776\n",
      "Model Saved!\n",
      "0.013122093592722508\n",
      "\n",
      "[ Train epoch: 61 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.019926821812987328\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06896078586578369\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012366440147161484\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03001791052520275\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05740588530898094\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03953247144818306\n",
      "\n",
      "Total benign train accuarcy: 98.616\n",
      "Total benign train loss: 20.85781209054403\n",
      "\n",
      "[ Test epoch: 61 ]\n",
      "\n",
      "Test accuarcy: 91.28\n",
      "Test average loss: 0.004304530847817659\n",
      "Model Saved!\n",
      "0.012859651720868058\n",
      "\n",
      "[ Train epoch: 62 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.019258549436926842\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02268783561885357\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.035872142761945724\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07945773005485535\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007876274175941944\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.031816575676202774\n",
      "\n",
      "Total benign train accuarcy: 98.58\n",
      "Total benign train loss: 20.09790446248371\n",
      "\n",
      "[ Test epoch: 62 ]\n",
      "\n",
      "Test accuarcy: 91.01\n",
      "Test average loss: 0.004408739590132609\n",
      "Model Saved!\n",
      "0.012602458686450697\n",
      "\n",
      "[ Train epoch: 63 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012248988263309002\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0236512478441\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.048123106360435486\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06422200053930283\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0037309660110622644\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.027979204431176186\n",
      "\n",
      "Total benign train accuarcy: 98.684\n",
      "Total benign train loss: 19.776321786630433\n",
      "\n",
      "[ Test epoch: 63 ]\n",
      "\n",
      "Test accuarcy: 91.04\n",
      "Test average loss: 0.004586912792176008\n",
      "Model Saved!\n",
      "0.012350409512721683\n",
      "\n",
      "[ Train epoch: 64 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.028352728113532066\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01195820514112711\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08706594258546829\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0066404021345078945\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.012769843451678753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.0942264199256897\n",
      "\n",
      "Total benign train accuarcy: 98.738\n",
      "Total benign train loss: 18.66335031040944\n",
      "\n",
      "[ Test epoch: 64 ]\n",
      "\n",
      "Test accuarcy: 91.06\n",
      "Test average loss: 0.00438095081821084\n",
      "Model Saved!\n",
      "0.012103401322467249\n",
      "\n",
      "[ Train epoch: 65 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0042295437306165695\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.015659110620617867\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008144238032400608\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04272519424557686\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.016180826351046562\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04680236056447029\n",
      "\n",
      "Total benign train accuarcy: 98.716\n",
      "Total benign train loss: 18.666447824332863\n",
      "\n",
      "[ Test epoch: 65 ]\n",
      "\n",
      "Test accuarcy: 91.64\n",
      "Test average loss: 0.004293401382863522\n",
      "Model Saved!\n",
      "0.011861333296017903\n",
      "\n",
      "[ Train epoch: 66 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001825828105211258\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011668391525745392\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02951989881694317\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011676126159727573\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9583333333333334\n",
      "Current benign train loss: 0.10332854837179184\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.031901709735393524\n",
      "\n",
      "Total benign train accuarcy: 98.89\n",
      "Total benign train loss: 16.67290457128547\n",
      "\n",
      "[ Test epoch: 66 ]\n",
      "\n",
      "Test accuarcy: 91.64\n",
      "Test average loss: 0.004309868504106998\n",
      "Model Saved!\n",
      "0.011624106630097544\n",
      "\n",
      "[ Train epoch: 67 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010914367623627186\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04242663085460663\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.032556865364313126\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0405060239136219\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12399359792470932\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.020116768777370453\n",
      "\n",
      "Total benign train accuarcy: 98.77\n",
      "Total benign train loss: 17.39519435929833\n",
      "\n",
      "[ Test epoch: 67 ]\n",
      "\n",
      "Test accuarcy: 91.49\n",
      "Test average loss: 0.004365223110467196\n",
      "Model Saved!\n",
      "0.011391624497495593\n",
      "\n",
      "[ Train epoch: 68 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07265908271074295\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05589020624756813\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0658368244767189\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02632533572614193\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.019260423257946968\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07426586002111435\n",
      "\n",
      "Total benign train accuarcy: 98.996\n",
      "Total benign train loss: 14.906827467028052\n",
      "\n",
      "[ Test epoch: 68 ]\n",
      "\n",
      "Test accuarcy: 91.26\n",
      "Test average loss: 0.004353921973705292\n",
      "Model Saved!\n",
      "0.011163792007545682\n",
      "\n",
      "[ Train epoch: 69 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007346408907324076\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00940907932817936\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04028988629579544\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009605859406292439\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018252607434988022\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004157414194196463\n",
      "\n",
      "Total benign train accuarcy: 99.0\n",
      "Total benign train loss: 14.725695962144528\n",
      "\n",
      "[ Test epoch: 69 ]\n",
      "\n",
      "Test accuarcy: 91.31\n",
      "Test average loss: 0.004656079053878784\n",
      "Model Saved!\n",
      "0.010940516167394767\n",
      "\n",
      "[ Train epoch: 70 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013148891739547253\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.019703004509210587\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.05269171670079231\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00773818651214242\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004359724465757608\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04174002632498741\n",
      "\n",
      "Total benign train accuarcy: 99.074\n",
      "Total benign train loss: 14.201097157900222\n",
      "\n",
      "[ Test epoch: 70 ]\n",
      "\n",
      "Test accuarcy: 91.28\n",
      "Test average loss: 0.004541240590997041\n",
      "Model Saved!\n",
      "0.010721705844046872\n",
      "\n",
      "[ Train epoch: 71 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04606996104121208\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007388854864984751\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004796197172254324\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.023821791633963585\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.038953687995672226\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011183492839336395\n",
      "\n",
      "Total benign train accuarcy: 99.002\n",
      "Total benign train loss: 14.159031338931527\n",
      "\n",
      "[ Test epoch: 71 ]\n",
      "\n",
      "Test accuarcy: 91.51\n",
      "Test average loss: 0.004393257859349251\n",
      "Model Saved!\n",
      "0.010507271727165934\n",
      "\n",
      "[ Train epoch: 72 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.058066364377737045\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.026147743687033653\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008111941628158092\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.026573913171887398\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013122341595590115\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018316417932510376\n",
      "\n",
      "Total benign train accuarcy: 99.242\n",
      "Total benign train loss: 11.806193107389845\n",
      "\n",
      "[ Test epoch: 72 ]\n",
      "\n",
      "Test accuarcy: 91.56\n",
      "Test average loss: 0.004462854494899512\n",
      "Model Saved!\n",
      "0.010297126292622616\n",
      "\n",
      "[ Train epoch: 73 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.011619326658546925\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008174902759492397\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017799461260437965\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007443403825163841\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01764165237545967\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06662017107009888\n",
      "\n",
      "Total benign train accuarcy: 99.108\n",
      "Total benign train loss: 13.29976866953075\n",
      "\n",
      "[ Test epoch: 73 ]\n",
      "\n",
      "Test accuarcy: 91.5\n",
      "Test average loss: 0.00460786971822381\n",
      "Model Saved!\n",
      "0.010091183766770163\n",
      "\n",
      "[ Train epoch: 74 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004788063932210207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04685394465923309\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.06374365836381912\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.027760891243815422\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00931574683636427\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0043543558567762375\n",
      "\n",
      "Total benign train accuarcy: 99.272\n",
      "Total benign train loss: 11.193892689363565\n",
      "\n",
      "[ Test epoch: 74 ]\n",
      "\n",
      "Test accuarcy: 91.7\n",
      "Test average loss: 0.004496869300305843\n",
      "Model Saved!\n",
      "0.009889360091434759\n",
      "\n",
      "[ Train epoch: 75 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013799436390399933\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.021024765446782112\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017650028690695763\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.08820790797472\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06303040683269501\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027013765648007393\n",
      "\n",
      "Total benign train accuarcy: 99.098\n",
      "Total benign train loss: 12.791880733915605\n",
      "\n",
      "[ Test epoch: 75 ]\n",
      "\n",
      "Test accuarcy: 91.68\n",
      "Test average loss: 0.004475565619021654\n",
      "Model Saved!\n",
      "0.009691572889606063\n",
      "\n",
      "[ Train epoch: 76 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02367660589516163\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06405437737703323\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.027083272114396095\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0047658332623541355\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005040018819272518\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.0573861189186573\n",
      "\n",
      "Total benign train accuarcy: 99.262\n",
      "Total benign train loss: 11.102679195464589\n",
      "\n",
      "[ Test epoch: 76 ]\n",
      "\n",
      "Test accuarcy: 91.46\n",
      "Test average loss: 0.004614852382242679\n",
      "Model Saved!\n",
      "0.009497741431813941\n",
      "\n",
      "[ Train epoch: 77 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004647164139896631\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005141813773661852\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008655000478029251\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05011160671710968\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03157686069607735\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005095984321087599\n",
      "\n",
      "Total benign train accuarcy: 99.17\n",
      "Total benign train loss: 12.219989839592017\n",
      "\n",
      "[ Test epoch: 77 ]\n",
      "\n",
      "Test accuarcy: 91.77\n",
      "Test average loss: 0.004564145528525114\n",
      "Model Saved!\n",
      "0.009307786603177663\n",
      "\n",
      "[ Train epoch: 78 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022400927264243364\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.020227888599038124\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005878149997442961\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00521823251619935\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.029229028150439262\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9479166666666666\n",
      "Current benign train loss: 0.09881440550088882\n",
      "\n",
      "Total benign train accuarcy: 99.326\n",
      "Total benign train loss: 10.170460194698535\n",
      "\n",
      "[ Test epoch: 78 ]\n",
      "\n",
      "Test accuarcy: 91.64\n",
      "Test average loss: 0.00437555621843785\n",
      "Model Saved!\n",
      "0.009121630871114108\n",
      "\n",
      "[ Train epoch: 79 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014131882227957249\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009552222676575184\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05607287213206291\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022966128308326006\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024278469383716583\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017018059268593788\n",
      "\n",
      "Total benign train accuarcy: 99.338\n",
      "Total benign train loss: 10.219553329370683\n",
      "\n",
      "[ Test epoch: 79 ]\n",
      "\n",
      "Test accuarcy: 91.83\n",
      "Test average loss: 0.004421981048770249\n",
      "Model Saved!\n",
      "0.008939198253691825\n",
      "\n",
      "[ Train epoch: 80 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017836494371294975\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008213050663471222\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02057228796184063\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0038891418371349573\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001895303837954998\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014052800834178925\n",
      "\n",
      "Total benign train accuarcy: 99.418\n",
      "Total benign train loss: 8.938761337078176\n",
      "\n",
      "[ Test epoch: 80 ]\n",
      "\n",
      "Test accuarcy: 91.78\n",
      "Test average loss: 0.004594592829048633\n",
      "Model Saved!\n",
      "0.008760414288617988\n",
      "\n",
      "[ Train epoch: 81 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01598306931555271\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0949239656329155\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007869423367083073\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002973282942548394\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020515299402177334\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0044829705730080605\n",
      "\n",
      "Total benign train accuarcy: 99.384\n",
      "Total benign train loss: 9.035297990572872\n",
      "\n",
      "[ Test epoch: 81 ]\n",
      "\n",
      "Test accuarcy: 91.89\n",
      "Test average loss: 0.004609170074015856\n",
      "Model Saved!\n",
      "0.008585206002845628\n",
      "\n",
      "[ Train epoch: 82 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002298356732353568\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008158566430211067\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0036413592752069235\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.03159184381365776\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.03134346753358841\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006348971277475357\n",
      "\n",
      "Total benign train accuarcy: 99.532\n",
      "Total benign train loss: 7.661457125534071\n",
      "\n",
      "[ Test epoch: 82 ]\n",
      "\n",
      "Test accuarcy: 91.99\n",
      "Test average loss: 0.004518260022252798\n",
      "Model Saved!\n",
      "0.008413501882788716\n",
      "\n",
      "[ Train epoch: 83 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.044626493006944656\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.04893118143081665\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006390969734638929\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01349656656384468\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0305990781635046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01731792464852333\n",
      "\n",
      "Total benign train accuarcy: 99.454\n",
      "Total benign train loss: 7.969180293905083\n",
      "\n",
      "[ Test epoch: 83 ]\n",
      "\n",
      "Test accuarcy: 91.76\n",
      "Test average loss: 0.004663613673299551\n",
      "Model Saved!\n",
      "0.008245231845132941\n",
      "\n",
      "[ Train epoch: 84 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008065938018262386\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.028194352984428406\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00347808375954628\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006747792009264231\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.02085311897099018\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.07376326620578766\n",
      "\n",
      "Total benign train accuarcy: 99.416\n",
      "Total benign train loss: 8.915303981659235\n",
      "\n",
      "[ Test epoch: 84 ]\n",
      "\n",
      "Test accuarcy: 91.64\n",
      "Test average loss: 0.004641268918663263\n",
      "Model Saved!\n",
      "0.008080327208230282\n",
      "\n",
      "[ Train epoch: 85 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004155792761594057\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017674589529633522\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02921384572982788\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011953775538131595\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06783445924520493\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01683286391198635\n",
      "\n",
      "Total benign train accuarcy: 99.526\n",
      "Total benign train loss: 7.706033364200266\n",
      "\n",
      "[ Test epoch: 85 ]\n",
      "\n",
      "Test accuarcy: 91.79\n",
      "Test average loss: 0.00469043084345758\n",
      "Model Saved!\n",
      "0.007918720664065676\n",
      "\n",
      "[ Train epoch: 86 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006183389923535287\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01735171675682068\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009134690277278423\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003208008361980319\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0035103261470794678\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004905106034129858\n",
      "\n",
      "Total benign train accuarcy: 99.546\n",
      "Total benign train loss: 7.120281498937402\n",
      "\n",
      "[ Test epoch: 86 ]\n",
      "\n",
      "Test accuarcy: 91.72\n",
      "Test average loss: 0.00462306347861886\n",
      "Model Saved!\n",
      "0.0077603462507843625\n",
      "\n",
      "[ Train epoch: 87 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018468379275873303\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005621356423944235\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05775919556617737\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005468450952321291\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.036563094705343246\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002097528427839279\n",
      "\n",
      "Total benign train accuarcy: 99.524\n",
      "Total benign train loss: 7.11032422221615\n",
      "\n",
      "[ Test epoch: 87 ]\n",
      "\n",
      "Test accuarcy: 91.9\n",
      "Test average loss: 0.004662469496158883\n",
      "Model Saved!\n",
      "0.007605139325768675\n",
      "\n",
      "[ Train epoch: 88 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.06312340497970581\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0033596830908209085\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.011711335740983486\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0051078652031719685\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005163500551134348\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.026196695864200592\n",
      "\n",
      "Total benign train accuarcy: 99.586\n",
      "Total benign train loss: 6.581910127744777\n",
      "\n",
      "[ Test epoch: 88 ]\n",
      "\n",
      "Test accuarcy: 91.75\n",
      "Test average loss: 0.004795142618007958\n",
      "Model Saved!\n",
      "0.007453036539253301\n",
      "\n",
      "[ Train epoch: 89 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006776060909032822\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010044613853096962\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001765263150446117\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028969196137040854\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024936283007264137\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020477110520005226\n",
      "\n",
      "Total benign train accuarcy: 99.58\n",
      "Total benign train loss: 6.444636892643757\n",
      "\n",
      "[ Test epoch: 89 ]\n",
      "\n",
      "Test accuarcy: 91.91\n",
      "Test average loss: 0.00472134371122811\n",
      "Model Saved!\n",
      "0.007303975808468235\n",
      "\n",
      "[ Train epoch: 90 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013759034918621182\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024528512731194496\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02565043978393078\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012759608216583729\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002146575367078185\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015189973637461662\n",
      "\n",
      "Total benign train accuarcy: 99.602\n",
      "Total benign train loss: 6.227078565323609\n",
      "\n",
      "[ Test epoch: 90 ]\n",
      "\n",
      "Test accuarcy: 91.57\n",
      "Test average loss: 0.004727410288900137\n",
      "Model Saved!\n",
      "0.00715789629229887\n",
      "\n",
      "[ Train epoch: 91 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018206214532256126\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031370592769235373\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0038222584407776594\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.024424046277999878\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.020180774852633476\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00016751534712966532\n",
      "\n",
      "Total benign train accuarcy: 99.616\n",
      "Total benign train loss: 5.944929777062498\n",
      "\n",
      "[ Test epoch: 91 ]\n",
      "\n",
      "Test accuarcy: 91.77\n",
      "Test average loss: 0.004737083780579269\n",
      "Model Saved!\n",
      "0.007014738366452893\n",
      "\n",
      "[ Train epoch: 92 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007842857390642166\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013777338899672031\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017196210101246834\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005906935315579176\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00548556400462985\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010443776845932007\n",
      "\n",
      "Total benign train accuarcy: 99.682\n",
      "Total benign train loss: 5.280054863105761\n",
      "\n",
      "[ Test epoch: 92 ]\n",
      "\n",
      "Test accuarcy: 91.84\n",
      "Test average loss: 0.004701658508554101\n",
      "Model Saved!\n",
      "0.006874443599123835\n",
      "\n",
      "[ Train epoch: 93 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009497720166109502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.022937847301363945\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007569491281174123\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008499237708747387\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.0171156357973814\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.05148015543818474\n",
      "\n",
      "Total benign train accuarcy: 99.684\n",
      "Total benign train loss: 5.194018018082716\n",
      "\n",
      "[ Test epoch: 93 ]\n",
      "\n",
      "Test accuarcy: 92.0\n",
      "Test average loss: 0.004823242438584566\n",
      "Model Saved!\n",
      "0.006736954727141358\n",
      "\n",
      "[ Train epoch: 94 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009312839829362929\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002975914627313614\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006938381120562553\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014144486049190164\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001346150878816843\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010482808575034142\n",
      "\n",
      "Total benign train accuarcy: 99.712\n",
      "Total benign train loss: 4.668219120176218\n",
      "\n",
      "[ Test epoch: 94 ]\n",
      "\n",
      "Test accuarcy: 92.21\n",
      "Test average loss: 0.00467888027420413\n",
      "Model Saved!\n",
      "0.006602215632598531\n",
      "\n",
      "[ Train epoch: 95 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005892504006624222\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04018298536539078\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.04055223986506462\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009732712060213089\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007696714252233505\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030648859683424234\n",
      "\n",
      "Total benign train accuarcy: 99.702\n",
      "Total benign train loss: 4.998426871316042\n",
      "\n",
      "[ Test epoch: 95 ]\n",
      "\n",
      "Test accuarcy: 91.94\n",
      "Test average loss: 0.004766344136395492\n",
      "Model Saved!\n",
      "0.00647017131994656\n",
      "\n",
      "[ Train epoch: 96 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020604177843779325\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.016194676980376244\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01748955436050892\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024718863423913717\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00021456641843542457\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.010714842937886715\n",
      "\n",
      "Total benign train accuarcy: 99.684\n",
      "Total benign train loss: 4.97772532507588\n",
      "\n",
      "[ Test epoch: 96 ]\n",
      "\n",
      "Test accuarcy: 92.07\n",
      "Test average loss: 0.00466872355529922\n",
      "Model Saved!\n",
      "0.006340767893547629\n",
      "\n",
      "[ Train epoch: 97 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004657692916225642\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0034219741355627775\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012705331901088357\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.025870390236377716\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008839020156301558\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.018090445548295975\n",
      "\n",
      "Total benign train accuarcy: 99.704\n",
      "Total benign train loss: 4.756399426958524\n",
      "\n",
      "[ Test epoch: 97 ]\n",
      "\n",
      "Test accuarcy: 91.86\n",
      "Test average loss: 0.004917196499556303\n",
      "Model Saved!\n",
      "0.006213952535676676\n",
      "\n",
      "[ Train epoch: 98 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002395555842667818\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011938014067709446\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0038204470183700323\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010646588634699583\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0026959909591823816\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00618737144395709\n",
      "\n",
      "Total benign train accuarcy: 99.742\n",
      "Total benign train loss: 4.195532132944209\n",
      "\n",
      "[ Test epoch: 98 ]\n",
      "\n",
      "Test accuarcy: 91.81\n",
      "Test average loss: 0.00475212207462755\n",
      "Model Saved!\n",
      "0.006089673484963142\n",
      "\n",
      "[ Train epoch: 99 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007008470594882965\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006732701440341771\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002805540105327964\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008285409770905972\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0029930099844932556\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.022581808269023895\n",
      "\n",
      "Total benign train accuarcy: 99.714\n",
      "Total benign train loss: 4.297746442374773\n",
      "\n",
      "[ Test epoch: 99 ]\n",
      "\n",
      "Test accuarcy: 91.95\n",
      "Test average loss: 0.004738702502846717\n",
      "Model Saved!\n",
      "0.005967880015263879\n",
      "\n",
      "[ Train epoch: 100 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0052376012317836285\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.008323915302753448\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009963911725208163\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0034531690180301666\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016174634220078588\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009181853383779526\n",
      "\n",
      "Total benign train accuarcy: 99.754\n",
      "Total benign train loss: 3.7381452376648667\n",
      "\n",
      "[ Test epoch: 100 ]\n",
      "\n",
      "Test accuarcy: 92.14\n",
      "Test average loss: 0.004755291379895062\n",
      "Model Saved!\n",
      "0.005848522414958601\n",
      "\n",
      "[ Train epoch: 101 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000829144089948386\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004947547800838947\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008711616974323988\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.012960194610059261\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008841378730721772\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002422100631520152\n",
      "\n",
      "Total benign train accuarcy: 99.794\n",
      "Total benign train loss: 3.7684157186886296\n",
      "\n",
      "[ Test epoch: 101 ]\n",
      "\n",
      "Test accuarcy: 91.89\n",
      "Test average loss: 0.004852468542009592\n",
      "Model Saved!\n",
      "0.005731551966659429\n",
      "\n",
      "[ Train epoch: 102 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.016071457415819168\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.010803193785250187\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.015025760047137737\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010603420669212937\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021002565044909716\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004163023550063372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign train accuarcy: 99.744\n",
      "Total benign train loss: 4.0819605120050255\n",
      "\n",
      "[ Test epoch: 102 ]\n",
      "\n",
      "Test accuarcy: 91.91\n",
      "Test average loss: 0.004789640228636563\n",
      "Model Saved!\n",
      "0.00561692092732624\n",
      "\n",
      "[ Train epoch: 103 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021982600446790457\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006016060360707343\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001737138838507235\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00036216495209373534\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009504581685177982\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00038419660995714366\n",
      "\n",
      "Total benign train accuarcy: 99.818\n",
      "Total benign train loss: 3.1640615621436154\n",
      "\n",
      "[ Test epoch: 103 ]\n",
      "\n",
      "Test accuarcy: 91.99\n",
      "Test average loss: 0.004756844952702522\n",
      "Model Saved!\n",
      "0.0055045825087797155\n",
      "\n",
      "[ Train epoch: 104 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014846795238554478\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002545594936236739\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008879079483449459\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.008325141854584217\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008830443024635315\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003656210610643029\n",
      "\n",
      "Total benign train accuarcy: 99.802\n",
      "Total benign train loss: 3.33864484327205\n",
      "\n",
      "[ Test epoch: 104 ]\n",
      "\n",
      "Test accuarcy: 92.15\n",
      "Test average loss: 0.004826341266185045\n",
      "Model Saved!\n",
      "0.005394490858604121\n",
      "\n",
      "[ Train epoch: 105 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011828317074105144\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00010695186210796237\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009257248020730913\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00046823793672956526\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0047722081653773785\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022294651716947556\n",
      "\n",
      "Total benign train accuarcy: 99.838\n",
      "Total benign train loss: 2.6707442681654356\n",
      "\n",
      "[ Test epoch: 105 ]\n",
      "\n",
      "Test accuarcy: 91.86\n",
      "Test average loss: 0.004830395836010575\n",
      "Model Saved!\n",
      "0.0052866010414320385\n",
      "\n",
      "[ Train epoch: 106 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002636250341311097\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003254370531067252\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008122934959828854\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014996047830209136\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00045764833339489996\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002438924740999937\n",
      "\n",
      "Total benign train accuarcy: 99.846\n",
      "Total benign train loss: 2.8421135617463733\n",
      "\n",
      "[ Test epoch: 106 ]\n",
      "\n",
      "Test accuarcy: 92.0\n",
      "Test average loss: 0.005047593629360199\n",
      "Model Saved!\n",
      "0.005180869020603398\n",
      "\n",
      "[ Train epoch: 107 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015489611541852355\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.008431638590991497\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.02673192135989666\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009270245209336281\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005826628766953945\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003210381546523422\n",
      "\n",
      "Total benign train accuarcy: 99.81\n",
      "Total benign train loss: 3.053945092688082\n",
      "\n",
      "[ Test epoch: 107 ]\n",
      "\n",
      "Test accuarcy: 91.82\n",
      "Test average loss: 0.004914840769767761\n",
      "Model Saved!\n",
      "0.005077251640191329\n",
      "\n",
      "[ Train epoch: 108 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017532847821712494\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013014470459893346\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010070985881611705\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00028335762908682227\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0026051520835608244\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010518500348553061\n",
      "\n",
      "Total benign train accuarcy: 99.818\n",
      "Total benign train loss: 2.810220015609957\n",
      "\n",
      "[ Test epoch: 108 ]\n",
      "\n",
      "Test accuarcy: 92.07\n",
      "Test average loss: 0.005043795337900519\n",
      "Model Saved!\n",
      "0.004975706607387503\n",
      "\n",
      "[ Train epoch: 109 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005873297923244536\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00499211298301816\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.033085811883211136\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.027631960809230804\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.01921822689473629\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.015644781291484833\n",
      "\n",
      "Total benign train accuarcy: 99.788\n",
      "Total benign train loss: 3.3321048171055736\n",
      "\n",
      "[ Test epoch: 109 ]\n",
      "\n",
      "Test accuarcy: 92.22\n",
      "Test average loss: 0.004917302653566003\n",
      "Model Saved!\n",
      "0.004876192475239753\n",
      "\n",
      "[ Train epoch: 110 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006411140784621239\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.013992507010698318\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005322980578057468\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008793089655227959\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.029941285029053688\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021880550775676966\n",
      "\n",
      "Total benign train accuarcy: 99.81\n",
      "Total benign train loss: 3.3992531550538843\n",
      "\n",
      "[ Test epoch: 110 ]\n",
      "\n",
      "Test accuarcy: 91.99\n",
      "Test average loss: 0.004989572176337242\n",
      "Model Saved!\n",
      "0.004778668625734958\n",
      "\n",
      "[ Train epoch: 111 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004904698580503464\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002320090075954795\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01845245249569416\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003116248408332467\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.017584191635251045\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006431236397475004\n",
      "\n",
      "Total benign train accuarcy: 99.816\n",
      "Total benign train loss: 3.0918284899380524\n",
      "\n",
      "[ Test epoch: 111 ]\n",
      "\n",
      "Test accuarcy: 92.09\n",
      "Test average loss: 0.005000196430087089\n",
      "Model Saved!\n",
      "0.004683095253220258\n",
      "\n",
      "[ Train epoch: 112 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028152994345873594\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008039571694098413\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00013329398643691093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.028421292081475258\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014678057050332427\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013138880021870136\n",
      "\n",
      "Total benign train accuarcy: 99.816\n",
      "Total benign train loss: 3.044656044578005\n",
      "\n",
      "[ Test epoch: 112 ]\n",
      "\n",
      "Test accuarcy: 92.23\n",
      "Test average loss: 0.005079602562636137\n",
      "Model Saved!\n",
      "0.004589433348155853\n",
      "\n",
      "[ Train epoch: 113 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009759750100784004\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0067822798155248165\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020974238868802786\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005108620040118694\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003748978255316615\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.012644373811781406\n",
      "\n",
      "Total benign train accuarcy: 99.846\n",
      "Total benign train loss: 2.9373774398700334\n",
      "\n",
      "[ Test epoch: 113 ]\n",
      "\n",
      "Test accuarcy: 91.94\n",
      "Test average loss: 0.004848267971258611\n",
      "Model Saved!\n",
      "0.004497644681192735\n",
      "\n",
      "[ Train epoch: 114 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005314102862030268\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008874617633409798\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002557359868660569\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002601576561573893\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018383994465693831\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017325207591056824\n",
      "\n",
      "Total benign train accuarcy: 99.878\n",
      "Total benign train loss: 2.3171507106417266\n",
      "\n",
      "[ Test epoch: 114 ]\n",
      "\n",
      "Test accuarcy: 91.97\n",
      "Test average loss: 0.004946866409480572\n",
      "Model Saved!\n",
      "0.004407691787568881\n",
      "\n",
      "[ Train epoch: 115 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005499019171111286\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00026575528318062425\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014742473140358925\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004181633237749338\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007222903426736593\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0036864608991891146\n",
      "\n",
      "Total benign train accuarcy: 99.882\n",
      "Total benign train loss: 2.1504080730155692\n",
      "\n",
      "[ Test epoch: 115 ]\n",
      "\n",
      "Test accuarcy: 92.05\n",
      "Test average loss: 0.004940517162159085\n",
      "Model Saved!\n",
      "0.004319537951817503\n",
      "\n",
      "[ Train epoch: 116 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009169552940875292\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006190304993651807\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006241986411623657\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005895423819310963\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002569082658737898\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00029468300635926425\n",
      "\n",
      "Total benign train accuarcy: 99.892\n",
      "Total benign train loss: 2.1499448187605594\n",
      "\n",
      "[ Test epoch: 116 ]\n",
      "\n",
      "Test accuarcy: 92.05\n",
      "Test average loss: 0.004888641655817628\n",
      "Model Saved!\n",
      "0.0042331471927811535\n",
      "\n",
      "[ Train epoch: 117 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008503506542183459\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00027827301528304815\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007088209968060255\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.014198534190654755\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010106886038556695\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010390164097771049\n",
      "\n",
      "Total benign train accuarcy: 99.91\n",
      "Total benign train loss: 1.8853666751965648\n",
      "\n",
      "[ Test epoch: 117 ]\n",
      "\n",
      "Test accuarcy: 92.06\n",
      "Test average loss: 0.0050341558542568235\n",
      "Model Saved!\n",
      "0.00414848424892553\n",
      "\n",
      "[ Train epoch: 118 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.013700186274945736\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00026989009347744286\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013712429208680987\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.013941138982772827\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.028053773567080498\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004811466205865145\n",
      "\n",
      "Total benign train accuarcy: 99.872\n",
      "Total benign train loss: 2.457658870094747\n",
      "\n",
      "[ Test epoch: 118 ]\n",
      "\n",
      "Test accuarcy: 92.03\n",
      "Test average loss: 0.00500454291254282\n",
      "Model Saved!\n",
      "0.004065514563947019\n",
      "\n",
      "[ Train epoch: 119 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00021941371960565448\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009521638858132064\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004738407209515572\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018484484171494842\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006729899323545396\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027544156182557344\n",
      "\n",
      "Total benign train accuarcy: 99.88\n",
      "Total benign train loss: 2.1017858571503893\n",
      "\n",
      "[ Test epoch: 119 ]\n",
      "\n",
      "Test accuarcy: 91.99\n",
      "Test average loss: 0.004986004988104105\n",
      "Model Saved!\n",
      "0.003984204272668079\n",
      "\n",
      "[ Train epoch: 120 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.012195800431072712\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007308288477361202\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002782569790724665\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006973524577915668\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001072289072908461\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014677993021905422\n",
      "\n",
      "Total benign train accuarcy: 99.882\n",
      "Total benign train loss: 1.9517096291310736\n",
      "\n",
      "[ Test epoch: 120 ]\n",
      "\n",
      "Test accuarcy: 92.04\n",
      "Test average loss: 0.005052489128708839\n",
      "Model Saved!\n",
      "0.003904520187214717\n",
      "\n",
      "[ Train epoch: 121 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006985632353462279\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017147678881883621\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006280598696321249\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003970812540501356\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005939111579209566\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005101758288219571\n",
      "\n",
      "Total benign train accuarcy: 99.88\n",
      "Total benign train loss: 1.9995800970791606\n",
      "\n",
      "[ Test epoch: 121 ]\n",
      "\n",
      "Test accuarcy: 92.05\n",
      "Test average loss: 0.004983931414037943\n",
      "Model Saved!\n",
      "0.0038264297834704228\n",
      "\n",
      "[ Train epoch: 122 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006640367791987956\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013759512221440673\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007029273547232151\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001886035461211577\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004943636595271528\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009098207228817046\n",
      "\n",
      "Total benign train accuarcy: 99.91\n",
      "Total benign train loss: 1.6866145821477403\n",
      "\n",
      "[ Test epoch: 122 ]\n",
      "\n",
      "Test accuarcy: 91.87\n",
      "Test average loss: 0.004982683895528316\n",
      "Model Saved!\n",
      "0.0037499011878010143\n",
      "\n",
      "[ Train epoch: 123 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002070000162348151\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005818380042910576\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00030949953361414373\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006032497622072697\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0038270337972790003\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.013345359824597836\n",
      "\n",
      "Total benign train accuarcy: 99.92\n",
      "Total benign train loss: 1.6900621073727962\n",
      "\n",
      "[ Test epoch: 123 ]\n",
      "\n",
      "Test accuarcy: 92.01\n",
      "Test average loss: 0.0050192414515186105\n",
      "Model Saved!\n",
      "0.003674903164044994\n",
      "\n",
      "[ Train epoch: 124 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003113878658041358\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016060015186667442\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012959017185494304\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004054004792124033\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015486893244087696\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.012261319905519485\n",
      "\n",
      "Total benign train accuarcy: 99.892\n",
      "Total benign train loss: 1.793244994842098\n",
      "\n",
      "[ Test epoch: 124 ]\n",
      "\n",
      "Test accuarcy: 91.98\n",
      "Test average loss: 0.005070363232307136\n",
      "Model Saved!\n",
      "0.003601405100764094\n",
      "\n",
      "[ Train epoch: 125 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007221120875328779\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 9.005015454022214e-05\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017716395668685436\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005179791245609522\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006404649466276169\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009722509421408176\n",
      "\n",
      "Total benign train accuarcy: 99.894\n",
      "Total benign train loss: 1.703071776246361\n",
      "\n",
      "[ Test epoch: 125 ]\n",
      "\n",
      "Test accuarcy: 92.13\n",
      "Test average loss: 0.004992026070694555\n",
      "Model Saved!\n",
      "0.003529376998748812\n",
      "\n",
      "[ Train epoch: 126 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006775771616958082\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005331654683686793\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016035228036344051\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 4.844837530981749e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00013684219447895885\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031245232094079256\n",
      "\n",
      "Total benign train accuarcy: 99.908\n",
      "Total benign train loss: 1.744233097833785\n",
      "\n",
      "[ Test epoch: 126 ]\n",
      "\n",
      "Test accuarcy: 92.07\n",
      "Test average loss: 0.004991147369518876\n",
      "Model Saved!\n",
      "0.0034587894587738356\n",
      "\n",
      "[ Train epoch: 127 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003725465794559568\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003243178827688098\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004166127648204565\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010777643183246255\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005538180121220648\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014120535925030708\n",
      "\n",
      "Total benign train accuarcy: 99.888\n",
      "Total benign train loss: 1.8850626402854687\n",
      "\n",
      "[ Test epoch: 127 ]\n",
      "\n",
      "Test accuarcy: 92.02\n",
      "Test average loss: 0.005114301210641861\n",
      "Model Saved!\n",
      "0.003389613669598359\n",
      "\n",
      "[ Train epoch: 128 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021230983547866344\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0032732945401221514\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021039070561528206\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007838520221412182\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004591824021190405\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 4.9772501370171085e-05\n",
      "\n",
      "Total benign train accuarcy: 99.888\n",
      "Total benign train loss: 1.798093122730279\n",
      "\n",
      "[ Test epoch: 128 ]\n",
      "\n",
      "Test accuarcy: 91.92\n",
      "Test average loss: 0.005090504704415798\n",
      "Model Saved!\n",
      "0.003321821396206392\n",
      "\n",
      "[ Train epoch: 129 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002795318141579628\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001143410219810903\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010603544069454074\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0037542434874922037\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00330748432315886\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008831957238726318\n",
      "\n",
      "Total benign train accuarcy: 99.916\n",
      "Total benign train loss: 1.7480117684590368\n",
      "\n",
      "[ Test epoch: 129 ]\n",
      "\n",
      "Test accuarcy: 92.04\n",
      "Test average loss: 0.005091509365290403\n",
      "Model Saved!\n",
      "0.003255384968282264\n",
      "\n",
      "[ Train epoch: 130 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00027927503106184304\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001727017923258245\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003830009372904897\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00036475525121204555\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000538396998308599\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009678206406533718\n",
      "\n",
      "Total benign train accuarcy: 99.924\n",
      "Total benign train loss: 1.5074561698638718\n",
      "\n",
      "[ Test epoch: 130 ]\n",
      "\n",
      "Test accuarcy: 92.01\n",
      "Test average loss: 0.004998890043160645\n",
      "Model Saved!\n",
      "0.0031902772689166186\n",
      "\n",
      "[ Train epoch: 131 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0027983803302049637\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006982150953263044\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006531404331326485\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004366793145891279\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002282944740727544\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000736437039449811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign train accuarcy: 99.902\n",
      "Total benign train loss: 1.7466491548220802\n",
      "\n",
      "[ Test epoch: 131 ]\n",
      "\n",
      "Test accuarcy: 92.14\n",
      "Test average loss: 0.0049902642597444355\n",
      "Model Saved!\n",
      "0.003126471723538286\n",
      "\n",
      "[ Train epoch: 132 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007022250443696976\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005514013464562595\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 5.0347342039458454e-05\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 5.8463934692554176e-05\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012007096083834767\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005163908354006708\n",
      "\n",
      "Total benign train accuarcy: 99.896\n",
      "Total benign train loss: 1.7110426323961292\n",
      "\n",
      "[ Test epoch: 132 ]\n",
      "\n",
      "Test accuarcy: 92.23\n",
      "Test average loss: 0.0049173246661492155\n",
      "Model Saved!\n",
      "0.0030639422890675204\n",
      "\n",
      "[ Train epoch: 133 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008262222982011735\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012207415886223316\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 4.69800979772117e-05\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004983521648682654\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008177780546247959\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9791666666666666\n",
      "Current benign train loss: 0.019723394885659218\n",
      "\n",
      "Total benign train accuarcy: 99.91\n",
      "Total benign train loss: 1.623716750753374\n",
      "\n",
      "[ Test epoch: 133 ]\n",
      "\n",
      "Test accuarcy: 92.29\n",
      "Test average loss: 0.005000378676876425\n",
      "Model Saved!\n",
      "0.00300266344328617\n",
      "\n",
      "[ Train epoch: 134 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002867473813239485\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003482319414615631\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0062275961972773075\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003994562430307269\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.012525670230388641\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00115190667565912\n",
      "\n",
      "Total benign train accuarcy: 99.922\n",
      "Total benign train loss: 1.5827730268865707\n",
      "\n",
      "[ Test epoch: 134 ]\n",
      "\n",
      "Test accuarcy: 92.28\n",
      "Test average loss: 0.004949389835447073\n",
      "Model Saved!\n",
      "0.0029426101744204464\n",
      "\n",
      "[ Train epoch: 135 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000509079487528652\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001885674544610083\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009457007981836796\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002599218627437949\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0029532492626458406\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010128309950232506\n",
      "\n",
      "Total benign train accuarcy: 99.922\n",
      "Total benign train loss: 1.4593033800265403\n",
      "\n",
      "[ Test epoch: 135 ]\n",
      "\n",
      "Test accuarcy: 92.35\n",
      "Test average loss: 0.00492833606377244\n",
      "Model Saved!\n",
      "0.0028837579709320373\n",
      "\n",
      "[ Train epoch: 136 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00035744652268476784\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001844804733991623\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009611926507204771\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015267505077645183\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.011551381088793278\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003047073259949684\n",
      "\n",
      "Total benign train accuarcy: 99.904\n",
      "Total benign train loss: 1.487006460865814\n",
      "\n",
      "[ Test epoch: 136 ]\n",
      "\n",
      "Test accuarcy: 92.26\n",
      "Test average loss: 0.004965730376914144\n",
      "Model Saved!\n",
      "0.0028260828115133966\n",
      "\n",
      "[ Train epoch: 137 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000662313133943826\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002343941479921341\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007145256386138499\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0041469489224255085\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00031523159123025835\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004622451087925583\n",
      "\n",
      "Total benign train accuarcy: 99.938\n",
      "Total benign train loss: 1.239006046367649\n",
      "\n",
      "[ Test epoch: 137 ]\n",
      "\n",
      "Test accuarcy: 92.31\n",
      "Test average loss: 0.004956085206009447\n",
      "Model Saved!\n",
      "0.0027695611552831286\n",
      "\n",
      "[ Train epoch: 138 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00038536576903425157\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003393446793779731\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00040449397056363523\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0034867199137806892\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004450805950909853\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00046754651702940464\n",
      "\n",
      "Total benign train accuarcy: 99.95\n",
      "Total benign train loss: 1.2411920632002875\n",
      "\n",
      "[ Test epoch: 138 ]\n",
      "\n",
      "Test accuarcy: 92.27\n",
      "Test average loss: 0.0049989720728248355\n",
      "Model Saved!\n",
      "0.002714169932177466\n",
      "\n",
      "[ Train epoch: 139 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006025959737598896\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013778515858575702\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0033196385484188795\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007339121657423675\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005365048069506884\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001985556213185191\n",
      "\n",
      "Total benign train accuarcy: 99.932\n",
      "Total benign train loss: 1.387158989902673\n",
      "\n",
      "[ Test epoch: 139 ]\n",
      "\n",
      "Test accuarcy: 92.34\n",
      "Test average loss: 0.004943679231405258\n",
      "Model Saved!\n",
      "0.002659886533533917\n",
      "\n",
      "[ Train epoch: 140 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005855731666088104\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009412543731741607\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00010250541527057067\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00026413018349558115\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011633015237748623\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002988426713272929\n",
      "\n",
      "Total benign train accuarcy: 99.906\n",
      "Total benign train loss: 1.4797085290192626\n",
      "\n",
      "[ Test epoch: 140 ]\n",
      "\n",
      "Test accuarcy: 92.09\n",
      "Test average loss: 0.005039642818644643\n",
      "Model Saved!\n",
      "0.0026066888028632384\n",
      "\n",
      "[ Train epoch: 141 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0001614814536878839\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004294523096177727\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012001696741208434\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017396464245393872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012675182661041617\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002873469493351877\n",
      "\n",
      "Total benign train accuarcy: 99.928\n",
      "Total benign train loss: 1.3281545714307867\n",
      "\n",
      "[ Test epoch: 141 ]\n",
      "\n",
      "Test accuarcy: 92.08\n",
      "Test average loss: 0.004933653945475817\n",
      "Model Saved!\n",
      "0.0025545550268059737\n",
      "\n",
      "[ Train epoch: 142 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009676226763986051\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00652665039524436\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017330331029370427\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002295485930517316\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010096613550558686\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00015468613128177822\n",
      "\n",
      "Total benign train accuarcy: 99.948\n",
      "Total benign train loss: 1.1466890568808594\n",
      "\n",
      "[ Test epoch: 142 ]\n",
      "\n",
      "Test accuarcy: 92.16\n",
      "Test average loss: 0.004975595613569021\n",
      "Model Saved!\n",
      "0.0025034639262698543\n",
      "\n",
      "[ Train epoch: 143 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00034052730188705027\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007530744769610465\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010284304153174162\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003544554638210684\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003240268852096051\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030985509511083364\n",
      "\n",
      "Total benign train accuarcy: 99.936\n",
      "Total benign train loss: 1.2657022220701037\n",
      "\n",
      "[ Test epoch: 143 ]\n",
      "\n",
      "Test accuarcy: 92.14\n",
      "Test average loss: 0.005020680339238606\n",
      "Model Saved!\n",
      "0.0024533946477444573\n",
      "\n",
      "[ Train epoch: 144 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015431485371664166\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018604261567816138\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001324296579696238\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007751027587801218\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00016828346997499466\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010780709562823176\n",
      "\n",
      "Total benign train accuarcy: 99.944\n",
      "Total benign train loss: 1.0888811052282108\n",
      "\n",
      "[ Test epoch: 144 ]\n",
      "\n",
      "Test accuarcy: 92.26\n",
      "Test average loss: 0.004980639852532476\n",
      "Model Saved!\n",
      "0.002404326754789568\n",
      "\n",
      "[ Train epoch: 145 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003973971586674452\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002591669326648116\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00030521428561769426\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002598359016701579\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012532341061159968\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00038546789437532425\n",
      "\n",
      "Total benign train accuarcy: 99.944\n",
      "Total benign train loss: 1.2280594829280744\n",
      "\n",
      "[ Test epoch: 145 ]\n",
      "\n",
      "Test accuarcy: 92.21\n",
      "Test average loss: 0.004967676437069895\n",
      "Model Saved!\n",
      "0.0023562402196937765\n",
      "\n",
      "[ Train epoch: 146 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003947403747588396\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016440405743196607\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008394013275392354\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006650034920312464\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00020094304636586457\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007118536159396172\n",
      "\n",
      "Total benign train accuarcy: 99.936\n",
      "Total benign train loss: 1.2160958143758762\n",
      "\n",
      "[ Test epoch: 146 ]\n",
      "\n",
      "Test accuarcy: 92.16\n",
      "Test average loss: 0.004982958074532508\n",
      "Model Saved!\n",
      "0.002309115415299901\n",
      "\n",
      "[ Train epoch: 147 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00042872154153883457\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 9.961036266759038e-05\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014358916087076068\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015572867123410106\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004939024220220745\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9895833333333334\n",
      "Current benign train loss: 0.01294731255620718\n",
      "\n",
      "Total benign train accuarcy: 99.932\n",
      "Total benign train loss: 1.2327988733413804\n",
      "\n",
      "[ Test epoch: 147 ]\n",
      "\n",
      "Test accuarcy: 92.26\n",
      "Test average loss: 0.0049822855073958635\n",
      "Model Saved!\n",
      "0.002262933106993903\n",
      "\n",
      "[ Train epoch: 148 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004137112118769437\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 7.132838072720915e-05\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001322734635323286\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005914388224482536\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005174374091438949\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003743298293557018\n",
      "\n",
      "Total benign train accuarcy: 99.93\n",
      "Total benign train loss: 1.2244949088417343\n",
      "\n",
      "[ Test epoch: 148 ]\n",
      "\n",
      "Test accuarcy: 92.23\n",
      "Test average loss: 0.0049786387871950865\n",
      "Model Saved!\n",
      "0.002217674444854025\n",
      "\n",
      "[ Train epoch: 149 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003401038411539048\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00046728760935366154\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025976274628192186\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00019836040155496448\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017400666838511825\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00011324343358865008\n",
      "\n",
      "Total benign train accuarcy: 99.952\n",
      "Total benign train loss: 1.026337985200371\n",
      "\n",
      "[ Test epoch: 149 ]\n",
      "\n",
      "Test accuarcy: 92.18\n",
      "Test average loss: 0.004973914697021246\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 150):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(0,150)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1) \n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss') \n",
    "plt.plot(epochs,loss_list) \n",
    "plt.subplot(1,2,2) \n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.plot(epochs, accuracy_list) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_sh",
   "language": "python",
   "name": "conda_sh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
